# Reviews: AI4StudentActionRecognition
---

## I. Pros
1. Cách tiếp cận bài toán hợp lý: Vì nhóm sử dụng phương pháp dựa trên khung xương, thay vì xử lý ảnh RGB thuần tuý -> giảm chiều dữ liệu, mô hình nhẹ hơn, tăng tính riêng tư (không cần lưu trữ mặt chi tiết của học sinh), tăng khả năng tổng quát hoá (không bị chi phối, ảnh hưởng bởi màu áo, phông nền.v.v).
2. Mô hình AI: Đề tài thực hiện so sánh thực nghiệm giữa 4 kiến trúc nổi bật: OpenPose, AlphaPose, MediaPipe và HRNet. Việc chọn HRNet (High-Resolution Net) làm mô hình cuối cùng cho thấy nhóm ưu tiên độ chính xác trong việc giữ lại các đặc trưng không gian (spatial features) chi tiết -> điều này rất quan trọng trong môi trường lớp học đông người nơi các chi tiết khớp xương dễ bị lẫn.
3. Chú trọng vào tiền xử lý dữ liệu: Nhóm đã đề cập và thực hiện rất nhiều phương pháp xử lý nhiễu đầu vào (ảnh mờ, rung) bằng các thuật toán kinh điển (Laplacian, Canny) -> giảm thiểu sự ảnh hưởng từ camera khi chất lượng hình ảnh không ổn định.

---
## II. Cons
1. Kiến trúc mô hình DNN cho dữ liệu chuỗi là quá đơn giản vì báo cáo đề cập sử dụng dữ liệu chuỗi tọa độ khớp X(t) theo thời gian, nhưng lại sử dụng mạng DNN (Deep Neural Network - mạng nơ-ron sâu truyền thẳng) để phân loại hành động. Vấn đề là DNN không có bộ nhớ về chuỗi thời gian (temporal dependency). Hành động "ghi chép" hay "ngủ gật" là một chuỗi các cử động liên tiếp. Nếu chỉ dùng DNN trên từng khung hình (hoặc vector gộp đơn giản), mô hình sẽ rất dễ nhầm lẫn giữa các trạng thái tĩnh (ví dụ: cúi đầu nhìn sách và cúi đầu ngủ). -> Sử dụng LSTM, GRU hoặc Transformer để bắt được ngữ cảnh thời gian.
2. Độ chính xác thực tế (Real-world Accuracy) đáng lo ngại. Kết quả Accuracy đạt 80.58% với HRNet trên tập kiểm thử. Tuy nhiên, trong môi trường AI thực tế (production), con số này là khá thấp, đặc biệt là với bài toán phân loại hành vi con người (thường acc > 90%). Ma trận nhầm lẫn (Confusion Matrix) cho thấy sự nhầm lẫn đáng kể giữa hành động "Looking" (Nhìn bảng) và "Boring" (Chán nản/Gục đầu). Điều này dễ hiểu vì sự khác biệt về tọa độ xương cổ/đầu giữa hai hành động này là rất nhỏ nếu không có thông tin ngữ cảnh.
3. Tập dữ liệu (Dataset) còn hạn chế: Với 8.800 ảnh cho 4 lớp hành động, đây là tập dữ liệu nhỏ đối với bài toán Deep Learning. Việc này dễ dẫn đến hiện tượng Overfitting (quá khớp), tức là mô hình học vẹt các tư thế trong tập huấn luyện nhưng sẽ sai lệch lớn khi gặp học sinh có tạng người lạ hoặc góc ngồi khác trong thực tế.

--- 
## III. Blind Spots
- Vấn đề che khuất: Lớp học tại Việt Nam thường rất đông (30-40 học sinh), bàn ghế san sát nhau. Camera góc cao chắc chắn sẽ gặp tình trạng học sinh ngồi trước che khuất học sinh ngồi sau. Báo cáo có nhắc đến "kỹ thuật trung bình trượt" để làm mịn dữ liệu bị mất, nhưng đây chỉ là giải pháp cho nhiễu tín hiệu. Khi một học sinh bị che mất 50% cơ thể (ví dụ: thân dưới và 1 tay), HRNet sẽ suy luận sai lệch nghiêm trọng. Đề tài chưa có giải pháp chuyên sâu cho Crowd Pose Estimation (ước lượng tư thế đám đông).
- Khoảng cách ngữ nghĩa: Đề tài mặc định: *Nhìn lên bảng = Tích cực; Thực tế: Một học sinh nhìn chằm chằm lên bảng có thể đang "mơ màng" (daydreaming), trong khi một học sinh cúi đầu có thể đang tập trung giải bài toán khó. Hệ thống AI này chỉ đánh giá được hành vi vật lý (physical behavior) chứ chưa thực sự chạm tới trạng thái nhận thức (cognitive state). Việc dán nhãn "Thái độ" dựa trên hành vi vật lý đơn thuần là một sự quy chụp rủi ro.*
- Sự chống chế: Học sinh rất thông minh. Nếu biết camera chấm điểm thái độ dựa trên việc "nhìn thẳng", các em sẽ học cách... nhìn thẳng vào bảng nhưng tâm trí để chỗ khác, hoặc ngủ nhưng tay vẫn chống cằm (để giả vờ nghe giảng). Mô hình hiện tại hoàn toàn mù tịt trước các hành vi "đối phó" (gaming the system) này.

---
## IV. Critical question
1. Trong báo cáo, nhóm tác giả sử dụng mạng DNN để phân loại hành động dựa trên dữ liệu khung xương. Tuy nhiên, các hành động như 'ghi chép' hay 'ngủ gật' có tính chất chuỗi thời gian (temporal) rất mạnh. Tại sao nhóm lại chọn DNN (vốn mạnh về dữ liệu tĩnh/phi cấu trúc) thay vì các kiến trúc chuyên biệt cho chuỗi thời gian như LSTM, GRU, hay ST-GCN (Spatial Temporal Graph Convolutional Networks)? Việc thiếu vắng yếu tố thời gian có phải là nguyên nhân khiến sự nhầm lẫn giữa các hành động có tư thế tĩnh tương đồng (ví dụ: cúi đầu chép bài vs. cúi đầu ngủ) còn cao không?. 
2. "Môi trường lớp học thực tế tại Việt Nam có mật độ học sinh rất cao, dẫn đến hiện tượng che khuất (Occlusion) nghiêm trọng, đặc biệt là với các bàn cuối lớp. Mô hình HRNet tuy mạnh về độ phân giải nhưng vẫn cần nhìn thấy các điểm keypoints. Nhóm nghiên cứu có cơ chế cụ thể nào (ví dụ: cơ chế Attention, hay Pose Refinement) để xử lý các trường hợp Missing Joints (mất điểm khớp) do che khuất, hay hệ thống sẽ mặc định bỏ qua/nhận diện sai các học sinh này, dẫn đến sai lệch trong báo cáo thống kê tổng thể?". 
3. Đề tài đang sử dụng một phép suy diễn bắc cầu: Camera thấy Hành động → Suy ra Thái độ. Tuy nhiên, trong khoa học tâm lý giáo dục, hành vi bên ngoài không phải lúc nào cũng đồng nhất với thái độ bên trong (ví dụ: nhìn bảng nhưng mất tập trung). Nhóm nghiên cứu có thực hiện bước đối sánh (cross-validation) nào với các phương pháp đánh giá truyền thống (như giáo viên đánh giá thực tế, hoặc kết quả bài kiểm tra ngay sau giờ học) để chứng minh rằng 'Điểm thái độ' do AI chấm thực sự tương quan dương (positive correlation) với hiệu quả học tập thực tế của học sinh không, hay chỉ là đo lường sự 'ngồi ngoan'?". 
4. Trong một tiết học 45 phút, học sinh không bao giờ giữ nguyên một tư thế. Sẽ có rất nhiều trạng thái chuyển tiếp (Transition states), ví dụ: đang quay xuống mượn bút, đang vươn vai, hay đang nhặt đồ rơi. Mạng DNN hiện tại phân loại từng khung hình độc lập, nghĩa là những giây 'nhặt đồ' đó có thể bị nhận diện nhầm thành 'Gục xuống bàn' (Boring). Hệ thống có cơ chế Làm mịn (Smoothing) hay Lọc nhiễu (Noise filtering) theo thời gian để loại bỏ các hành động ngẫu nhiên này không, hay sẽ tính hết vào báo cáo cuối cùng?". 