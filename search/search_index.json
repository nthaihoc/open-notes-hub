{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#opennoteshub","title":"\u2618\ufe0f OpenNotesHub","text":"<p>\ud83c\udf35 \"Be kind. Be curious. Be courageous\"</p> <p>\ud83c\udf3e \"What I cannot create, I do not understand\"</p> <p> </p> <p> </p>"},{"location":"#about-me","title":"\ud83d\udc40 About Me","text":"<p>\ud83d\udc4b Xin ch\u00e0o! T\u00f4i l\u00e0 Nguy\u1ec5n Th\u00e1i H\u1ecdc - k\u1ef9 s\u01b0 nghi\u00ean c\u1ee9u Tr\u00ed tu\u1ec7 nh\u00e2n t\u1ea1o (AI Researcher) t\u1ea1i Vi\u1ec7n Khoa h\u1ecdc &amp; C\u00f4ng ngh\u1ec7 \u1ee8ng d\u1ee5ng (IAST), tr\u1ef1c thu\u1ed9c Tr\u01b0\u1eddng \u0110\u1ea1i h\u1ecdc C\u00f4ng ngh\u1ec7 Th\u00f4ng tin &amp; Truy\u1ec1n th\u00f4ng (ICTU). T\u00f4i b\u1eaft \u0111\u1ea7u theo h\u1ecdc ch\u01b0\u01a1ng tr\u00ecnh k\u1ef9 s\u01b0 chuy\u00ean ngh\u00e0nh Khoa h\u1ecdc d\u1eef li\u1ec7u &amp; Tr\u00ed tu\u1ec7 nh\u00e2n t\u1ea1o (Data Science &amp; Artificial Intelligence) t\u1ea1i ICTU v\u00e0o n\u0103m 2020 v\u00e0 t\u1ed1t nghi\u1ec7p v\u00e0o n\u0103m 2025. Ni\u1ec1m \u0111am m\u00ea v\u1edbi AI c\u1ee7a t\u00f4i ch\u1ec9 th\u1ef1c s\u1ef1 b\u00f9ng n\u1ed5 v\u00e0o cu\u1ed1i n\u0103m th\u1ee9 ba \u0111\u1ea1i h\u1ecdc, khi t\u00f4i b\u1eaft \u0111\u1ea7u ti\u1ebfp c\u1eadn s\u00e2u h\u01a1n c\u00e1c m\u00f4n h\u1ecdc chuy\u00ean ngh\u00e0nh.</p> <p>\ud83c\udfe3 Th\u00e1ng 08/2024, t\u00f4i tham gia nghi\u00ean c\u1ee9u t\u1ea1i Vi\u1ec7n IAST v\u1edbi vai tr\u00f2 th\u1ef1c t\u1eadp sinh th\u1ecb gi\u00e1c m\u00e1y t\u00ednh (Computer Vision Intern). T\u1ea1i \u0111\u00e2y, t\u00f4i v\u1eeba c\u1ee7ng c\u1ed1 ki\u1ebfn th\u1ee9c n\u1ec1n t\u1ea3ng v\u1eeba tr\u1ef1c ti\u1ebfp nghi\u00ean c\u1ee9u v\u00e0 ph\u00e1t tri\u1ec3n m\u1ed9t s\u1ed1 \u1ee9ng d\u1ee5ng AI trong l\u0129nh v\u1ef1c ch\u0103m s\u00f3c s\u1ee9c kh\u1ecfe (healthcare) v\u00e0 gi\u00e1o d\u1ee5c (education). Hi\u1ec7n t\u1ea1i, t\u00f4i \u0111ang t\u1eadp trung v\u00e0o vi\u1ec7c nghi\u00ean c\u1ee9u v\u00e0 ph\u00e1t tri\u1ec3n c\u00e1c \u1ee9ng d\u1ee5ng Machine Learning v\u00e0 Computer Vision nh\u1eb1m gi\u1ea3i quy\u1ebft c\u00e1c b\u00e0i to\u00e1n th\u1ef1c ti\u1ec5n trong l\u0129nh v\u1ef1c ch\u0103m s\u00f3c s\u1ee9c kh\u1ecfe v\u00e0 gi\u00e1o d\u1ee5c tr\u1ef1c tuy\u1ebfn.</p> <p>B\u00ean c\u1ea1nh \u0111\u00f3, t\u00f4i c\u0169ng l\u00e0m vi\u1ec7c v\u1edbi c\u00e1c m\u00f4 h\u00ecnh ng\u00f4n ng\u1eef l\u1edbn (Large Language Models) v\u00e0 m\u00f4 h\u00ecnh k\u1ebft h\u1ee3p gi\u1eefa ng\u00f4n ng\u1eef v\u00e0 th\u1ecb gi\u00e1c (Vision-Language Models) v\u1edbi m\u1ee5c ti\u00eau n\u00e2ng cao ch\u1ea5t l\u01b0\u1ee3ng v\u00e0 hi\u1ec7u qu\u1ea3 cho c\u00e1c gi\u1ea3i ph\u00e1p c\u00f4ng ngh\u1ec7 \u1ee9ng d\u1ee5ng trong \u0111\u1eddi s\u1ed1ng. B\u00ean c\u1ea1nh \u0111\u00f3, t\u00f4i c\u0169ng quan t\u00e2m v\u00e0 c\u00f3 s\u1edf th\u00edch nghi\u00ean c\u1ee9u \u1edf m\u1ed9t s\u1ed1 l\u0129nh v\u1ef1c nh\u01b0:</p> <ul> <li> <p>\u1ee8ng d\u1ee5ng MLOps, DLOps, LLMOps \u0111\u1ec3 t\u1ed1i \u01b0u h\u00f3a quy tr\u00ecnh ph\u00e1t tri\u1ec3n, tri\u1ec3n khai v\u00e0 v\u1eadn h\u00e0nh c\u00e1c m\u00f4 h\u00ecnh AI.</p> </li> <li> <p>Nghi\u00ean c\u1ee9u c\u00e1c k\u1ef9 thu\u1eadt AI ti\u00ean ti\u1ebfn nh\u01b0 x\u1eed l\u00fd h\u00ecnh \u1ea3nh 3D, xe t\u1ef1 l\u00e1i v\u00e0 x\u1eed l\u00fd d\u1eef li\u1ec7u l\u1edbn.</p> </li> </ul>"},{"location":"#opennoteshub_1","title":"\ud83e\udde0 OpenNotesHub","text":"<p>[OpenNotesHub] l\u00e0 m\u1ed9t kh\u00f4ng gian nh\u1ecf m\u00e0 t\u00f4i t\u1ea1o ra ch\u1ee7 y\u1ebfu l\u00e0 \u0111\u1ec3 t\u1eadp h\u1ee3p nhi\u1ec1u ghi ch\u00fa v\u00e0 t\u00e0i li\u1ec7u ph\u1ee5c v\u1ee5 cho m\u1ee5c \u0111\u00edch h\u1ecdc t\u1eadp, nghi\u00ean c\u1ee9u v\u00e0 chia s\u1ebb ki\u1ebfn th\u1ee9c. Trong \u0111\u00f3 ch\u1ee9a m\u1ed9t s\u1ed1 th\u00e0nh ph\u1ea7n sau: </p> <ul> <li> <p>[Research Logs] - T\u1ed5ng h\u1ee3p c\u00e1c t\u00e0i li\u1ec7u, ghi ch\u00fa v\u00e0 k\u1ebft qu\u1ea3 th\u1ef1c nghi\u1ec7m li\u00ean quan \u0111\u1ebfn ph\u01b0\u01a1ng ph\u00e1p v\u00e0 k\u1ef9 thu\u1eadt nghi\u00ean c\u1ee9u trong qu\u00e1 tr\u00ecnh l\u00e0m vi\u1ec7c.</p> </li> <li> <p>[Course Notes] - S\u1eafp x\u1ebfp v\u00e0 t\u1ed5ng h\u1ee3p l\u1ea1i nh\u1eefng ghi ch\u00fa trong su\u1ed1t qu\u00e1 tr\u00ecnh nghi\u00ean c\u1ee9u v\u00e0 h\u1ecdc t\u1eadp, sau \u0111\u00f3 bi\u00ean so\u1ea1n l\u1ea1i th\u00e0nh nh\u1eefng kh\u00f3a h\u1ecdc ng\u1eafn g\u1ecdn, d\u1ec5 ti\u1ebfp c\u1eadn.</p> </li> <li> <p>[Knowledge Base] - Bao g\u1ed3m c\u00e1c ki\u1ebfn th\u1ef1c n\u1ec1n t\u1ea3ng v\u00e0 t\u00e0i li\u1ec7u tham kh\u1ea3o \u1edf nhi\u1ec1u l\u0129nh v\u1ef1c kh\u00e1c nhau, \u0111\u01b0\u1ee3c h\u1ec7 th\u1ed1ng h\u00f3a h\u1ed7 tr\u1ee3 cho vi\u1ec7c h\u1ecdc t\u1eadp v\u00e0 nghi\u00ean c\u1ee9u.</p> </li> </ul> <p>\ud83d\ude80 T\u00f4i hy v\u1ecdng n\u01a1i \u0111\u00e2y s\u1ebd tr\u1edf th\u00e0nh m\u1ed9t ngu\u1ed3n t\u00e0i nguy\u00ean h\u1eefu \u00edch \u2013 n\u01a1i b\u1ea1n c\u00f3 th\u1ec3 t\u00ecm th\u1ea5y \u0111i\u1ec1u m\u00ecnh \u0111ang t\u00ecm ki\u1ebfm, ho\u1eb7c \u0111\u01a1n gi\u1ea3n l\u00e0 c\u00f9ng t\u00f4i h\u1ecdc th\u00eam \u0111i\u1ec1u m\u1edbi m\u1ed7i ng\u00e0y.</p>"},{"location":"#contact","title":"\u260e\ufe0f Contact","text":"<p>B\u1ea1n c\u00f3 th\u1ec3 xem th\u00eam th\u00f4ng tin ho\u1eb7c k\u1ebft n\u1ed1i v\u1edbi t\u00f4i qua nh\u1eefng n\u1ec1n t\u1ea3ng d\u01b0\u1edbi d\u00e2y:</p> K\u00eanh Li\u00ean k\u1ebft \u2709\ufe0f Email thaihoc.ictu@gmail.com \ud83d\udcac Facebook facebook.com/nthaihoc02 \ud83c\udf10 Website nthaihoc.github.io/about-me"},{"location":"courses/","title":"Course Notes","text":""},{"location":"courses/#course-notes","title":"\ud83c\udf93 Course Notes","text":"<p>\u2728 \"Don\u2019t wait for opportunity. Create it.\"</p> <p>\ud83c\udf3c \"You don\u2019t have to be great to start, but you have to start to be great.\"</p> <p> </p> <p> </p>"},{"location":"courses/#tong-quan","title":"\u2733\ufe0f T\u1ed5ng quan","text":"<p>Trong su\u1ed1t h\u00e0nh tr\u00ecnh h\u1ecdc t\u1eadp v\u00e0 nghi\u00ean c\u1ee9u v\u1ec1 tr\u00ed tu\u1ec7 nh\u00e2n t\u1ea1o, t\u00f4i \u0111\u00e3 kh\u00f4ng ng\u1eebng t\u1ed5ng h\u1ee3p, ghi ch\u00fa v\u00e0 di\u1ec5n gi\u1ea3i l\u1ea1i nh\u1eefng ki\u1ebfn th\u1ee9c c\u0103n b\u1ea3n theo g\u00f3c nh\u00ecn v\u00e0 c\u00e1ch hi\u1ec3u c\u1ee7a ri\u00eang m\u00ecnh. Kh\u00f4ng d\u1eebng l\u1ea1i \u1edf vi\u1ec7c l\u01b0u tr\u1eef c\u00e1 nh\u00e2n, t\u00f4i \u0111\u00e3 ch\u1ee7 \u0111\u1ed9ng h\u1ec7 th\u1ed1ng h\u00f3a nh\u1eefng n\u1ed9i dung n\u00e0y th\u00e0nh c\u00e1c kh\u00f3a h\u1ecdc ng\u1eafn g\u1ecdn, d\u1ec5 ti\u1ebfp c\u1eadn - v\u1edbi hai m\u1ee5c ti\u00eau ch\u00ednh: M\u1ed9t l\u00e0 t\u1ea1o n\u00ean m\u1ed9t kh\u00f4ng gian h\u1ecdc t\u1eadp c\u00e1 nh\u00e2n linh ho\u1ea1t, n\u01a1i t\u00f4i c\u00f3 th\u1ec3 \u00f4n luy\u1ec7n v\u00e0 c\u1ee7ng c\u1ed1 l\u1ea1i n\u1ec1n t\u1ea3ng ki\u1ebfn th\u1ee9c b\u1ea5t c\u1ee9 l\u00fac n\u00e0o; Hai l\u00e0 chia s\u1ebb nh\u1eefng g\u00ec m\u00ecnh bi\u1ebft \u0111\u1ebfn c\u1ed9ng \u0111\u1ed3ng, \u0111\u1eb7c bi\u1ec7t l\u00e0 nh\u1eefng ng\u01b0\u1eddi m\u1edbi b\u1eaft \u0111\u1ea7u, v\u1edbi hy v\u1ecdng g\u00f3p ph\u1ea7n lan t\u1ecfa tri th\u1ee9c v\u00e0 kh\u01a1i d\u1eady ni\u1ec1m y\u00eau th\u00edch v\u1edbi l\u0129nh v\u1ef1c \u0111\u1ea7y ti\u1ec1m n\u0103ng n\u00e0y.</p>"},{"location":"courses/#danh-sach-khoa-hoc","title":"\ud83c\udf52 Danh s\u00e1ch kh\u00f3a h\u1ecdc","text":"Ch\u00fa th\u00edch <ul> <li> \u0110\u00e3 ho\u00e0n th\u00e0nh</li> <li> \u0110ang ph\u00e1t tri\u1ec3n</li> <li> Ch\u01b0a b\u1eaft \u0111\u1ea7u</li> </ul> No. Course Name Status Description 01 Applied Machine Learning  [Link] (-) Cung c\u1ea5p c\u00e1c ki\u1ebfn th\u00fac n\u1ec1n t\u1ea3ng v\u1ec1 c\u00e1c k\u1ef9 thu\u1eadt v\u00e0 thu\u1eadt to\u00e1n quan tr\u1ecdng trong Machine Learning.  (-) H\u01b0\u1edbng d\u1eabn tri\u1ec3n khai, x\u00e2y d\u1ef1ng v\u00e0 hu\u1ea5n luy\u1ec7n c\u00e1c m\u00f4 h\u00ecnh t\u1eeb \u0111\u1ea7u t\u1edbi cu\u1ed1i. 02 Computer Vision Foundations (-) Tr\u00ecnh b\u00e0y c\u00e1c ki\u1ebfn th\u1ee9c c\u1ed1t l\u00f5i v\u1ec1 Deep Learning, v\u1edbi tr\u1ecdng t\u00e2m l\u00e0 x\u1eed l\u00fd \u1ea3nh v\u00e0 th\u1ecb gi\u00e1c m\u00e1y t\u00ednh.  (-) Gi\u1ea3i th\u00edch nguy\u00ean l\u00fd ho\u1ea1t \u0111\u1ed9ng c\u1ee7a c\u00e1c ki\u1ebfn tr\u00fac m\u1ea1ng n\u01a1-ron t\u00edch ch\u1eadp (CNN), c\u00e1c k\u1ef9 thu\u1eadt ti\u1ec1n x\u1eed l\u00fd \u1ea3nh, v\u00e0 m\u1ed9t s\u1ed1 t\u00e1c v\u1ee5 ph\u1ed5 bi\u1ebfn. 03 Large Language Models for Beginner (-) Gi\u1edbi thi\u1ec7u t\u1ed5ng quan v\u1ec1 c\u00e1c m\u00f4 h\u00ecnh ng\u00f4n ng\u1eef l\u1edbn (LLMs), bao g\u1ed3m c\u00e1ch th\u1ee9c ho\u1ea1t \u0111\u1ed9ng, ki\u1ebfn tr\u00fac c\u01a1 b\u1ea3n v\u00e0 c\u00e1c \u1ee9ng d\u1ee5ng ti\u00eau bi\u1ec3u.  (-) Ph\u00e2n t\u00edch c\u00e1c kh\u00e1i ni\u1ec7m nh\u01b0 attention, transformer, embedding c\u00f9ng v\u1edbi quy tr\u00ecnh hu\u1ea5n luy\u1ec7n v\u00e0 s\u1eed d\u1ee5ng m\u00f4 h\u00ecnh.  (-) Ph\u00f9 h\u1ee3p cho ng\u01b0\u1eddi m\u1edbi b\u1eaft \u0111\u1ea7u l\u00e0m quen v\u1edbi l\u0129nh v\u1ef1c x\u1eed l\u00fd ng\u00f4n ng\u1eef t\u1ef1 nhi\u00ean."},{"location":"courses/#ong-gop-gop-y","title":"\ud83d\udcec \u0110\u00f3ng g\u00f3p &amp; G\u00f3p \u00fd","text":"<p>T\u1ea5t c\u1ea3 n\u1ed9i dung tr\u00ean website n\u00e0y l\u00e0 k\u1ebft qu\u1ea3 c\u1ee7a qu\u00e1 tr\u00ecnh t\u1ef1 h\u1ecdc, nghi\u00ean c\u1ee9u v\u00e0 t\u1ed5ng h\u1ee3p d\u01b0\u1edbi g\u00f3c nh\u00ecn c\u00e1 nh\u00e2n. Do \u0111\u00f3, kh\u00f4ng th\u1ec3 tr\u00e1nh kh\u1ecfi nh\u1eefng thi\u1ebfu s\u00f3t ho\u1eb7c c\u00e1ch di\u1ec5n \u0111\u1ea1t c\u00f2n h\u1ea1n ch\u1ebf. T\u00f4i lu\u00f4n mong mu\u1ed1n c\u1ea3i thi\u1ec7n v\u00e0 m\u1edf r\u1ed9ng n\u1ed9i dung t\u1ea1i \u0111\u00e2y \u0111\u1ec3 ph\u1ee5c v\u1ee5 t\u1ed1t h\u01a1n cho c\u1ed9ng \u0111\u1ed3ng.</p> <p>N\u1ebfu b\u1ea1n c\u00f3 g\u00f3p \u00fd, c\u00e2u h\u1ecfi, ho\u1eb7c \u0111\u1ec1 xu\u1ea5t n\u00e0o gi\u00fap c\u1ea3i thi\u1ec7n ch\u1ea5t l\u01b0\u1ee3ng n\u1ed9i dung, h\u00e3y chia s\u1ebb v\u1edbi t\u00f4i qua m\u1ed9t trong c\u00e1c c\u00e1ch d\u01b0\u1edbi \u0111\u00e2y:</p> <ul> <li>Email: thaihoc.ictu@gmail.com</li> <li>T\u1ea1o Issue t\u1ea1i: github.com/nthaihoc/open-notes/issues</li> <li>G\u1eedi Pull Request t\u1ea1i: github.com/nthaihoc/open-notes/pulls</li> </ul> <p>M\u1ecdi \u0111\u00f3ng g\u00f3p, d\u00f9 nh\u1ecf nh\u1ea5t, \u0111\u1ec1u v\u00f4 c\u00f9ng qu\u00fd gi\u00e1. C\u1ea3m \u01a1n b\u1ea1n \u0111\u00e3 \u0111\u1ed3ng h\u00e0nh!</p>"},{"location":"courses/applied-machine-learning/","title":"Applied Machine Learning (AML)","text":"\ud83d\udc0e Applied    Machine    Learning    (AML)  <p>\ud83c\udf1f \"Success is not an accident. It\u2019s hard work, learning, and persistence.\"</p> <p>\ud83d\ude80 \"Start where you are. Use what you have. Do what you can.\"</p> <p> </p>"},{"location":"courses/applied-machine-learning/#course-introduction","title":"Course Introduction","text":"<p>M\u00f4 t\u1ea3. Applied Machine Learning (AML) \u0111\u01b0\u1ee3c ghi ch\u00fa v\u00e0 t\u1ed5ng h\u1ee3p theo \u0111\u1ecbnh d\u1ea1ng m\u1ed9t kh\u00f3a h\u1ecdc, nh\u1eb1m cung c\u1ea5p cho ng\u01b0\u1eddi h\u1ecdc c\u00e1i nh\u00ecn t\u1ed5ng quan v\u00e0 to\u00e0n di\u1ec7n v\u1ec1 l\u0129nh v\u1ef1c Machine Learning (ML) - t\u1eeb l\u00fd thuy\u1ebft c\u1ed1t l\u00f5i \u0111\u1ebfn th\u1ef1c h\u00e0nh tri\u1ec3n khai. To\u00e0n b\u1ed9 n\u1ed9i dung t\u1eadp trung v\u00e0o c\u00e1c k\u1ef9 thu\u1eadt v\u00e0 thu\u1eadt to\u00e1n n\u1ec1n t\u1ea3ng, gi\u00fap b\u1ea1n n\u1eafm v\u1eefng c\u00e1ch th\u1ee9c thu th\u1eadp d\u1eef li\u1ec7u, ti\u1ec1n x\u1eed l\u00fd, v\u00e0 x\u00e2y d\u1ef1ng c\u00e1c m\u00f4 h\u00ecnh h\u1ecdc m\u00e1y m\u1ed9t c\u00e1ch b\u00e0i b\u1ea3n v\u00e0 c\u00f3 h\u1ec7 th\u1ed1ng. Kh\u00f3a h\u1ecdc kh\u00f4ng ch\u1ec9 ch\u00fa tr\u1ecdng v\u00e0o ki\u1ebfn th\u1ee9c l\u00fd thuy\u1ebft m\u00e0 c\u00f2n h\u01b0\u1edbng d\u1eabn ng\u01b0\u1eddi h\u1ecdc t\u1eebng b\u01b0\u1edbc tri\u1ec3n khai, hu\u1ea5n luy\u1ec7n v\u00e0 \u0111\u00e1nh gi\u00e1 m\u00f4 h\u00ecnh ML t\u1eeb \u0111\u1ea7u \u0111\u1ebfn cu\u1ed1i, qua c\u00e1c b\u00e0i t\u1eadp th\u1ef1c h\u00e0nh v\u00e0 d\u1ef1 \u00e1n th\u1ef1c t\u1ebf.</p> <p>\u0110\u1ed1i t\u01b0\u1ee3ng. Kh\u00f3a h\u1ecdc ph\u00f9 h\u1ee3p v\u1edbi ng\u01b0\u1eddi m\u1edbi b\u1eaft \u0111\u1ea7u l\u00e0m quen v\u1edbi Tr\u00ed tu\u1ec7 Nh\u00e2n t\u1ea1o v\u00e0 H\u1ecdc m\u00e1y. Ngo\u00e0i ra, nh\u1eefng ng\u01b0\u1eddi \u0111\u00e3 c\u00f3 ki\u1ebfn th\u1ee9c n\u1ec1n t\u1ea3ng c\u0169ng c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng t\u00e0i li\u1ec7u n\u00e0y nh\u01b0 m\u1ed9t ngu\u1ed3n tham kh\u1ea3o h\u1ec7 th\u1ed1ng v\u00e0 th\u1ef1c ti\u1ec5n.</p> <p>C\u1ea5u tr\u00fac kh\u00f3a h\u1ecdc. Kh\u00f3a h\u1ecdc \u0111\u01b0\u1ee3c t\u1ed5ng h\u1ee3p v\u00e0 chia nh\u1ecf th\u00e0nh 5 Module ch\u00ednh - t\u1eeb n\u1ec1n t\u1ea3ng l\u00fd thuy\u1ebft cho \u0111\u1ebfn th\u1ef1c h\u00e0nh tri\u1ec3n khai to\u00e0n b\u1ed9 h\u1ec7 th\u1ed1ng ML trong th\u1ef1c t\u1ebf. C\u1ee5 th\u1ec3:</p> <ul> <li>Module 01. Introduction to ML &amp; Development Environment (T\u1ed5ng quan v\u1ec1 H\u1ecdc m\u00e1y v\u00e0 M\u00f4i tr\u01b0\u1eddng ph\u00e1t tri\u1ec3n)</li> <li>Module 02. Data Preprocessing &amp; Exploratory Data Analysis (Ti\u1ec1n x\u1eed l\u00fd v\u00e0 Kh\u00e1m ph\u00e1 d\u1eef li\u1ec7u)</li> <li>Module 03. Supervised Learning Algorithms (C\u00e1c thu\u1eadt to\u00e1n h\u1ecdc c\u00f3 gi\u00e1m s\u00e1t)</li> <li>Module 04. Unsupervised Learning Algorithms (C\u00e1c thu\u1eadt to\u00e1n h\u1ecdc kh\u00f4ng gi\u00e1m s\u00e1t)</li> <li>Module 5: ML Pipelines &amp; Deployment (\u0110\u01b0\u1eddng \u1ed1ng ML v\u00e0 Tri\u1ec3n khai h\u1ec7 th\u1ed1ng)</li> </ul> <p>Chi ti\u1ebft n\u1ed9i dung b\u00e0i h\u1ecdc c\u1ee7a t\u1eebng Module \u0111\u01b0\u1ee3c m\u00f4 t\u1ea3 chi ti\u1ebft trong [syllabus]</p> <p>Li\u00ean k\u1ebft nhanh: To\u00e0n b\u1ed9 n\u1ed9i dung kh\u00f3a h\u1ecdc bao g\u1ed3m ghi ch\u00fa b\u00e0i h\u1ecdc (notes), m\u00e3 ch\u01b0\u01a1ng tr\u00ecnh (code) v\u00e0 t\u00e0i li\u1ec7u tham kh\u1ea3o (materials) \u0111\u01b0\u1ee3c t\u1ed5ng h\u1ee3p v\u00e0 c\u00f3 th\u1ec3 truy c\u1eadp nhanh t\u1ea1i nh\u1eefng \u0111\u1ecba ch\u1ec9 sau:</p> <ul> <li>Lecture notes</li> <li>Code for Course</li> <li>Materials for Course</li> </ul>"},{"location":"courses/applied-machine-learning/#what-will-you-learn","title":"What will you learn?","text":"<p>Sau khi \u0111\u1ecdc xong to\u00e0n b\u1ed9 kh\u00f3a h\u1ecdc n\u00e0y, b\u1ea1n c\u00f3 th\u1ec3 thu th\u1eadp \u0111\u01b0\u1ee3c nh\u1eefng tri th\u1ee9c d\u01b0\u1edbi \u0111\u00e2y: </p> <ul> <li> <p>N\u1eafm v\u1eefng c\u00e1c thu\u1eadt to\u00e1n h\u1ecdc m\u00e1y c\u01a1 b\u1ea3n nh\u01b0 Linear Regression, Support Vector Machine, Decision Trees, K-mean Clustering,v.v.</p> </li> <li> <p>Th\u00e0nh th\u1ea1o quy tr\u00ecnh x\u00e2y d\u1ef1ng m\u00f4 h\u00ecnh ML t\u1eeb d\u1eef li\u1ec7u th\u00f4 \u0111\u1ebfn \u0111\u00e1nh gi\u00e1 k\u1ebft qu\u1ea3.</p> </li> <li> <p>Hi\u1ec3u v\u00e0 \u00e1p d\u1ee5ng k\u1ef9 thu\u1eadt thu th\u1eadp, ti\u1ec1n x\u1eed l\u00fd v\u00e0 tr\u1ef1c quan h\u00f3a d\u1eef li\u1ec7u.</p> </li> <li> <p>Th\u1ef1c h\u00e0nh tri\u1ec3n khai m\u00f4 h\u00ecnh b\u1eb1ng Python v\u00e0 c\u00e1c th\u01b0 vi\u1ec7n nh\u01b0: Scikit-learn, Numpy, Pandas, Matplotlib, Seaborn,v.v.</p> </li> <li> <p>\u00c1p d\u1ee5ng m\u00f4 h\u00ecnh v\u00e0o c\u00e1c b\u00e0i to\u00e1n th\u1ef1c t\u1ebf qua mini-projects v\u00e0 case studies.</p> </li> </ul>"},{"location":"courses/applied-machine-learning/#requirements","title":"Requirements","text":"<p>\u0110\u1ec3 c\u00f3 th\u1ec3 ti\u1ebfp c\u1eadn n\u1ed9i dung c\u1ee7a to\u00e0n b\u1ed9 kh\u00f3a h\u1ecdc m\u1ed9t c\u00e1ch d\u1ec5 d\u00e0ng, ng\u01b0\u1eddi \u0111\u1ecdc c\u1ea7n c\u00f3 s\u1eb5n m\u1ed9t s\u1ed1 ki\u1ebfn th\u1ee9c n\u1ec1n t\u1ea3ng nh\u01b0:</p> <ul> <li> <p>L\u1eadp tr\u00ecnh Python c\u01a1 b\u1ea3n: Th\u00e0nh th\u1ea1o c\u00e1c c\u1ea5u tr\u00fac d\u1eef li\u1ec7u c\u01a1 b\u1ea3n, v\u00f2ng l\u1eb7p, h\u00e0m v\u00e0 thao t\u00e1c x\u1eed l\u00fd d\u1eef li\u1ec7u v\u1edbi th\u01b0 vi\u1ec7n nh\u01b0 numpy v\u00e0 pandas.</p> </li> <li> <p>To\u00e1n h\u1ecdc n\u1ec1n t\u1ea3ng: C\u00f3 ki\u1ebfn th\u1ee9c c\u01a1 b\u1ea3n v\u1ec1 \u0111\u1ea1i s\u1ed1 tuy\u1ebfn t\u00ednh, gi\u1ea3i th\u00edch v\u00e0 x\u00e1c su\u1ea5t th\u1ed1ng k\u00ea.</p> </li> <li> <p>K\u1ef9 n\u0103ng t\u1ef1 h\u1ecdc v\u00e0 gi\u1ea3i quy\u1ebft v\u1ea5n \u0111\u1ec1: S\u1eb5n s\u00e0ng ti\u1ebfp c\u1eadn t\u00e0i li\u1ec7u h\u1ecdc thu\u1eadt, nghi\u00ean c\u1ee9u thu\u1eadt to\u00e1n, v\u00e0 th\u1eed nghi\u1ec7m m\u00f4 h\u00ecnh trong m\u00f4i tr\u01b0\u1eddng th\u1ef1c t\u1ebf.</p> </li> </ul>"},{"location":"courses/applied-machine-learning/#syllabus","title":"Syllabus","text":"Dealine Module Lecture Description Module 01. Introduction to ML &amp; Development Environment Lecture 01. Overview to Machine Learning theory  [notes] [code] <li>Kh\u00e1i ni\u1ec7m &amp; vai tr\u00f2 th\u1ef1c ti\u1ec5n <li>Ph\u00e2n lo\u1ea1i: Gi\u00e1m s\u00e1t; Kh\u00f4ng gi\u00e1m s\u00e1t; T\u0103ng c\u01b0\u1eddng <li>Th\u00e1ch th\u1ee9c tri\u1ec3n khai m\u00f4 h\u00ecnh Lecture 02. Roadmap for Building ML Systems theory <li>C\u00e1c b\u01b0\u1edbc x\u00e2y d\u1ef1ng h\u1ec7 th\u1ed1ng <li> Y\u1ebfu t\u1ed1 \u1ea3nh h\u01b0\u1edfng: d\u1eef li\u1ec7u, m\u00f4 h\u00ecnh, hi\u1ec7u n\u0103ng <li> MLOps &amp; v\u00f2ng \u0111\u1eddi m\u00f4 h\u00ecnh Lecture 03. Using Python &amp; ML Libraries practice <li>Python cho khoa h\u1ecdc d\u1eef li\u1ec7u <li>Jupyter, Anaconda, Colab <li>Th\u01b0 vi\u1ec7n c\u01a1 b\u1ea3n: NumPy, pandas, matplotlib, scikit-learn Module 02. Data Preprocessing &amp; Exploratory Data Analysis Lecture 04. Essential Concepts in Data Preprocessing <li>Vai tr\u00f2 ti\u1ec1n x\u1eed l\u00fd <li>K\u1ef9 thu\u1eadt: l\u00e0m s\u1ea1ch; ch\u1ecdn; bi\u1ebfn; t\u1ea1o \u0111\u1eb7c tr\u01b0ng <li>L\u1ef1a ch\u1ecdn ph\u00f9 h\u1ee3p &amp; l\u1ed7i th\u01b0\u1eddng g\u1eb7p Lecture 05. Data Cleaning &amp; Missing Value Handling <li>Vai tr\u00f2 l\u00e0m s\u1ea1ch d\u1eef li\u1ec7u <li>X\u1eed l\u00fd d\u01b0 th\u1eeba, tr\u00f9ng l\u1eb7p, ngo\u1ea1i l\u1ec7 <li>Chi\u1ebfn l\u01b0\u1ee3c x\u1eed l\u00fd gi\u00e1 tr\u1ecb thi\u1ebfu Lecture 06. Feature Selection Techniques <li>L\u1ee3i \u00edch ch\u1ecdn \u0111\u1eb7c tr\u01b0ng <li> So s\u00e1nh c\u00e1c ph\u01b0\u01a1ng ph\u00e1p <li>Th\u1ef1c h\u00e0nh RFE &amp; tinh ch\u1ec9nh <li> \u0110\u00e1nh gi\u00e1 hi\u1ec7u qu\u1ea3 m\u00f4 h\u00ecnh Lecture 07. Data Transformation Techniques <li>K\u1ef9 thu\u1eadt bi\u1ebfn \u0111\u1ed5i d\u1eef li\u1ec7u <li>Chu\u1ea9n h\u00f3a, r\u1eddi r\u1ea1c h\u00f3a, x\u1eed l\u00fd ngo\u1ea1i l\u1ec7 <li>M\u00e3 h\u00f3a &amp; bi\u1ebfn \u0111\u1ed5i ph\u00e2n ph\u1ed1i <li>T\u1ea1o \u0111\u1eb7c tr\u01b0ng m\u1edbi Module 03. Supervised Learning Algorithms Lecture 08. Linear Models in Machine Learning <li>Linear &amp; Logistic Regression <li>Gradient Descent, Normal Equation <li>Regularization: Ridge, Lasso, Elastic Net <li>Softmax Regression cho ph\u00e2n lo\u1ea1i \u0111a l\u1edbp Lecture 09. Support Vector Machines <li>Linear SVM: Hard vs. Soft Margin <li>Kernel Trick cho b\u00e0i to\u00e1n phi tuy\u1ebfn <li>Polynomial &amp; Gaussian RBF Kernel <li>B\u00e0i to\u00e1n \u0111\u1ed1i ng\u1eabu (Dual Problem) Lecture 10. Decision Trees <li>C\u1ea5u tr\u00fac v\u00e0 tr\u1ef1c quan h\u00f3a c\u00e2y <li>CART &amp; \u0111\u1ed9 ph\u1ee9c t\u1ea1p hu\u1ea5n luy\u1ec7n <li>Gini vs. Entropy <li>Si\u00eau tham s\u1ed1 &amp; ki\u1ec3m so\u00e1t overfitting <li>H\u1ed3i quy &amp; ph\u00e2n lo\u1ea1i v\u1edbi c\u00e2y quy\u1ebft \u0111\u1ecbnh Lecture 11. Ensemble Learning &amp; Random Forests <li>Nguy\u00ean l\u00fd h\u1ecdc t\u1ed5 h\u1ee3p (Voting, Averaging) <li>Bagging, Pasting &amp; OOB Evaluation <li>Random Forest &amp; Extra-Trees <li>Feature Importance t\u1eeb c\u00e2y ng\u1eabu nhi\u00ean <li>Boosting: AdaBoost, Gradient Boosting <li>Stacking &amp; k\u1ef9 thu\u1eadt k\u1ebft h\u1ee3p m\u00f4 h\u00ecnh Lecture 12. Dimensionality Reduction &amp; Latent Variables <li>Hi\u1ec3u l\u1eddi nguy\u1ec1n chi\u1ec1u (Curse of Dimensionality) <li>PCA: t\u1ed1i \u0111a ph\u01b0\u01a1ng sai, t\u1ed1i thi\u1ec3u l\u1ed7i <li>Probabilistic PCA &amp; Factor Analysis <li>Kernel PCA &amp; nonlinear manifold learning <li>ICA, Autoencoder &amp; latent representations Module 04. Unsupervised Learning Algorithms Lecture 13. Clustering &amp; Unsupervised Pattern Discovery <li>K-means v\u00e0 gi\u1edbi h\u1ea1n c\u1ee7a n\u00f3 <li>DBSCAN v\u00e0 c\u00e1c thu\u1eadt to\u00e1n kh\u00e1c <li>Ch\u1ecdn s\u1ed1 c\u1ee5m t\u1ed1i \u01b0u, Semi-supervised clustering Lecture 14. Mixture Models &amp; Expectation Maximization <li>Gaussian Mixture Models (GMM) <li>Maximum Likelihood cho mixture models <li>Thu\u1eadt to\u00e1n EM: nguy\u00ean l\u00fd v\u00e0 tr\u1ef1c quan <li>Mixtures of Bernoulli, Bayesian linear regression Module 5: ML Pipelines &amp; Deployment Lecture 15: Pipelines &amp; Hyperparameter Tuning <li>scikit-learn pipelines <li>Cross-validation <li>GridSearchCV; RandomizedSearchCV <li>Feature selection t\u00edch h\u1ee3p <li>\u0110\u00e1nh gi\u00e1 &amp; t\u1ed1i \u01b0u m\u00f4 h\u00ecnh Lecture 16. Model Deployment &amp; Inference Optimization <li>Hi\u1ec3u l\u1ea7m ph\u1ed5 bi\u1ebfn khi tri\u1ec3n khai <li>Batch vs Online prediction <li>K\u1ebft h\u1ee3p batch v\u00e0 streaming pipeline <li>T\u1ed1i \u01b0u m\u00f4 h\u00ecnh: pruning, quantization, distillation"},{"location":"courses/applied-machine-learning/#materials","title":"Materials","text":"<p>ph\u1ea7n n\u00e0y t\u1ed5ng Ph\u1ea7n n\u00e0y t\u1ed5ng h\u1ee3p to\u00e0n b\u1ed9 t\u00e0i li\u1ec7u \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong su\u1ed1t kh\u00f3a h\u1ecdc, t\u00e0i li\u1ec7u \u0111\u1ecdc th\u00eam v\u00e0 li\u00ean k\u1ebft tham kh\u1ea3o. Ngo\u00e0i ra, b\u1ea1n c\u0169ng s\u1ebd t\u00ecm th\u1ea5y c\u00e1c ngu\u1ed3n h\u1ecdc t\u1eadp m\u1edf r\u1ed9ng gi\u00fap c\u1ee7ng c\u1ed1 v\u00e0 \u0111\u00e0o s\u00e2u ki\u1ebfn th\u1ee9c.</p> <p>Lecture 01. Overview to Machine Learning:</p> <ul> <li>Book: Machine Learning c\u01a1 b\u1ea3n - V\u0169 H\u1eefu Ti\u1ec7p - Ch\u01b0\u01a1ng 1</li> <li>Book: Design Machine Learning Systems - Chip Huyen</li> </ul>"},{"location":"courses/large-language-models/","title":"Large Language Models (LLMs)","text":""},{"location":"courses/large-language-models/lessson/lesson-03-attention_mechanisms/","title":"Lesson 03: Attention Mechanisms Knowledge Base","text":""},{"location":"courses/large-language-models/lessson/lesson-03-attention_mechanisms/#types-for-attention-mechanisms","title":"Types for attention mechanisms","text":"<p>Ch\u00fang ta s\u1ebd t\u00ecm hi\u1ec3u v\u00e0 tri\u1ec3n khai b\u1ed1n bi\u1ebfn th\u1ec3 kh\u00e1c nhau c\u1ee7a c\u01a1 ch\u1ebf attention, nh\u1eefng bi\u1ebfn th\u1ec3 attention n\u00e0y \u0111\u01b0\u1ee3c x\u00e2y d\u1ef1ng d\u1ef1a tr\u00ean nhau v\u1edbi c\u00e1c m\u1ee5c ti\u00eau kh\u00e1c bi\u1ec7t.</p> Type Description Simplified self-attention (attention \u0111\u01a1n gi\u1ea3n) \u0110\u00e2y l\u00e0 k\u1ef9 thu\u1eadt self-attention \u0111\u01a1n gi\u1ea3n \u0111\u1ec3 gi\u1edbi thi\u1ec7u \u00fd t\u01b0\u1edfng t\u1ed5ng qu\u00e1t Self-attention (attention t\u1ef1 h\u1ecdc) Self-attention v\u1edbi c\u00e1c tr\u1ecdng s\u1ed1 c\u00f3 th\u1ec3 hu\u1ea5n luy\u1ec7n, l\u00e0 c\u01a1 s\u1edf c\u1ee7a c\u01a1 ch\u1ebf \u0111\u01b0\u1ee3c d\u00f9ng trong c\u00e1c LLM. Causal attention (attention nh\u00e2n qu\u1ea3) M\u1ed9t d\u1ea1ng self-attention \u0111\u01b0\u1ee3c d\u00f9ng trong LLM, cho ph\u00e9p m\u00f4 h\u00ecnh ch\u1ec9 xem x\u00e9t c\u00e1c \u0111\u1ea7u v\u00e0o hi\u1ec7n t\u1ea1i v\u00e0 tr\u01b0\u1edbc \u0111\u00f3 trong m\u1ed9t chu\u1ed7i, \u0111\u1ea3m b\u1ea3o th\u1ee9 t\u1ef1 th\u1eddi gian trong qu\u00e1 tr\u00ecnh sinh v\u0103n b\u1ea3n Multi-head-attention (attention \u0111a \u0111\u1ea7u) M\u1edf r\u1ed9ng self-attention v\u00e0 causal attention, cho ph\u00e9p m\u00f4 h\u00ecnh \u0111\u1ed3ng th\u1eddi ch\u00fa \u00fd \u0111\u1ebfn th\u00f4ng tin t\u1eeb nhi\u1ec1u kh\u00f4ng gian bi\u1ec3u di\u1ec5n kh\u00e1c nhau <p>B\u1eaft \u0111\u1ea7u t\u1eeb phi\u00ean b\u1ea3n simplified self-attention gi\u00fap ch\u00fang ta h\u00ecnh dung \u0111\u01b0\u1ee3c kh\u00e1i ni\u1ec7m c\u01a1 b\u1ea3n nh\u1ea5t, tr\u01b0\u1edbc khi th\u00eam c\u00e1c tr\u1ecdng s\u1ed1 c\u00f3 th\u1ec3 hu\u1ea5n luy\u1ec7n \u1edf phi\u00ea b\u1ea3n self-attention. C\u01a1 ch\u1ebf causal attention th\u00eam m\u1ed9t mask v\u00f2a self-attention, cho ph\u00e9p LLM sinh t\u1eebng t\u1eeb m\u1ed9t. Cu\u1ed1i c\u00f9ng, multi-head attention t\u1ed5 ch\u1ee9c c\u01a1 ch\u1ebf attention th\u00e0nh nhi\u1ec1u head, gi\u00fap m\u00f4 h\u00ecnh n\u1eafm b\u1eaft nhi\u1ec1u kh\u00eda c\u1ea1nh kh\u00e1c nhau c\u1ee7a d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o c\u00f9ng l\u00fac.</p>"},{"location":"courses/large-language-models/lessson/lesson-03-attention_mechanisms/#the-birth-of-attention-mechanism","title":"The birth of attention mechanism","text":"<p>Tr\u01b0\u1edbc khi \u0111i s\u00e2u v\u00e0o c\u01a1 ch\u1ebf self-attention, tr\u00e1i tim c\u1ee7a c\u00e1c m\u00f4 h\u00ecnh LLM hi\u1ec7n nay, c\u1ea7n xem x\u00e9t v\u1ea5n \u0111\u1ec1 c\u1ee7a c\u00e1c ki\u1ebfn tr\u00fac tr\u01b0\u1edbc \u0111\u00e2y m\u00e0 kh\u00f4ng c\u00f3 c\u01a1 ch\u1ebf attention. Gi\u1ea3 s\u1eed ch\u00fang ta mu\u1ed1n x\u00e2y d\u1ef1ng m\u1ed9t mo h\u00ecnh d\u1ecbch ng\u00f4n ng\u1eef, m\u1ee5c ti\u00eau l\u00e0 d\u1ecbch v\u0103n b\u1ea3n t\u1eeb m\u1ed9t ng\u00f4n ng\u1eef n\u00e0y sang m\u1ed9t ng\u00f4n ng\u1eef kh\u00e1c. Ch\u00fang ta kh\u00f4ng th\u1ec3 d\u1ecbch t\u1eebng t\u1eeb m\u1ed9t c\u00e1ch tr\u1ef1c ti\u1ebfp (word-by-word) do c\u1ea5u tr\u00fac ng\u1eef ph\u00e1p kh\u00e1c nhau gi\u1eefa ng\u00f4n ng\u1eef ngu\u1ed3n v\u00e0 ng\u00f4n ng\u1eef \u0111\u00edch.</p> <p>V\u00ed d\u1ee5:</p> <ul> <li>C\u00e2u g\u1ed1c ti\u1ebfng Vi\u1ec7t: \"B\u1ea1n c\u00f3 th\u1ec3 gi\u00fap t\u00f4i d\u1ecbch c\u00e2u n\u00e0y \u0111\u01b0\u1ee3c kh\u00f4ng\". </li> <li>D\u1ecbch t\u1eebng t\u1eeb tr\u1ef1c ti\u1ebfp: \"You can help me translate this sentence\" -&gt; c\u00e2u n\u00e0y sai ng\u1eef ph\u00e1p tr\u1ea7m tr\u1ecdng.</li> <li>D\u1ecbch ch\u00ednh x\u00e1c: M\u1ed9t s\u1ed1 t\u1eeb trong c\u00e2u d\u1ecbch c\u1ea7n tham chi\u1ebfu \u0111\u1ebfn c\u00e1c t\u1eeb xu\u1ea5t hi\u1ec7n tr\u01b0\u1edbc ho\u1eb7c sau trong c\u00e2u g\u1ed1c, \u0111\u00f2i h\u1ecfi hi\u1ec3u  ng\u1eef c\u1ea3nh v\u00e0 c\u1ea5u tr\u00fac ng\u1eef ph\u00e1p ch\u1ee9 kh\u00f4ng th\u1ec3 d\u1ecbch theo t\u1eebng t\u1eeb ri\u00eang l\u1ebb.</li> </ul> <p>\u0110\u1ec3 gi\u1ea3i quy\u1ebft v\u1ea5n \u0111\u1ec1 n\u00e0y, th\u01b0\u1eddng s\u1eed d\u1ee5ng m\u1ea1ng n\u01a1-ron s\u00e2u v\u1edbi hai th\u00e0nh ph\u1ea7n l\u00e0 encoder v\u00e0 decoder. Encoder \u0111\u1ecdc v\u00e0 x\u1eed l\u00fd to\u00e0n b\u1ed9 v\u0103n b\u1ea3n \u0111\u1ea7u v\u00e0o, trong khi decoder d\u1ef1a tr\u00ean th\u00f4ng tin t\u1eeb encoder \u0111\u1ec3 t\u1ea1o ra v\u0103n b\u1ea3n \u0111\u00edch. Tr\u01b0\u1edbc khi c\u00f3 transformer, RNN l\u00e0 ki\u1ebfn tr\u00fac encoder-decoder ph\u1ed5 bi\u1ebfn nh\u1ea5t cho d\u1ecbch ng\u00f4n ng\u1eef. RNN l\u00e0 lo\u1ea1i m\u1ea1ng n\u01a1-ron m\u00e0 \u0111\u1ea7u ra c\u1ee7a b\u01b0\u1edbc tr\u01b0\u1edbc \u0111\u01b0\u1ee3c l\u00e0m \u0111\u1ea7u v\u00e0o c\u1ee7a b\u01b0\u1edbc hi\u1ec7n t\u1ea1i, r\u1ea5t ph\u00f9 h\u1ee3p cho d\u1eef li\u1ec7u tu\u1ea7n t\u1ef1 nh\u01b0 v\u0103n b\u1ea3n hay gi\u1ecdng n\u00f3i. </p> <p>Trong encoder-decoder c\u1ee7a RNN, v\u0103n b\u1ea3n \u0111\u1ea7u v\u00e0o \u0111\u01b0\u1ee3c \u0111\u01b0a v\u00e0o encoder, x\u1eed l\u00fd tu\u1ea7n t\u1ef1, encoder c\u1eadp nh\u1eadt hidden state t\u1ea1i m\u1ed7i b\u01b0\u1edbc, c\u1ed1 g\u1eafng n\u00e9n to\u00e0n b\u1ed9 \u00fd ngh\u0129a c\u1ee7a c\u00e2u \u0111\u1ea7u v\u00e0o trong hidden state cu\u1ed1i c\u00f9ng. Decoder s\u1eed d\u1ee5ng hidden state cu\u1ed1i c\u00f9ng n\u00e0y \u0111\u1ec3 b\u1eaft \u0111\u1ea7u t\u1ea1o t\u1eebng c\u00e2u d\u1ecbch, t\u1eebng t\u1eeb m\u1ed9t, v\u00e0 c\u0169ng c\u1eadp nh\u1eadt hidden state t\u1ea1i m\u1ed7i b\u01b0\u1edbc \u0111\u1ec3 gi\u1eef ng\u1eef c\u1ea3nh c\u1ea7n thi\u1ebft cho vi\u1ec7c d\u1ef1 \u0111o\u00e1n t\u1eeb ti\u1ebfp theo. Tuy nhi\u00ean h\u1ea1n ch\u1ebf l\u1edbn c\u1ee7a encoder-decoder RNN l\u00e0:</p> <ul> <li>Khi \u0111ang decode, RNN kh\u00f4ng th\u1ec3 truy c\u1eadp tr\u1ef1c ti\u1ebfp c\u00e1c nh\u00f3m hidden state tr\u01b0\u1edbc \u0111\u00f3 c\u1ee7a encoder.</li> <li>Decoder ch\u1ec9 d\u1ef1a v\u00e0o hidden state hi\u1ec7n t\u1ea1i, v\u1ed1n ph\u1ea3i ch\u1ee9a to\u00e0n b\u1ed9 th\u00f4ng tin quan tr\u1ecdng c\u1ee7a c\u1ea3 m\u1ed9t chu\u1ed7i. \u0110i\u1ec1u n\u00e0y c\u00f3 th\u1ec3 g\u00e2y m\u1ea5t ng\u1eef c\u1ea3nh, \u0111\u1eb7c bi\u1ec7t v\u1edbi c\u00e1c c\u00e2u d\u00e0i ho\u1eb7c c\u00f3 nhi\u1ec1u ph\u1ee5 thu\u1ed9c ph\u1ee9c t\u1ea1p.</li> </ul> <p>Nh\u1eefng h\u1ea1n ch\u1ebf n\u00e0y c\u1ee7a RNN l\u00e0 c\u01a1 s\u1edf, \u0111\u1ed9ng l\u1ef1c \u0111\u1ec3 gi\u1ea3i th\u00edch cho s\u1ef1 ra \u0111\u1eddi c\u1ee7a transformer v\u00e0 attention trong LLM.</p>"},{"location":"courses/large-language-models/lessson/lesson-03-attention_mechanisms/#bahdanau-attention","title":"Bahdanau attention","text":"<p>M\u1eb7c d\u00f9 RNN ho\u1ea1t \u0111\u1ed9ng kh\u00e1 t\u1ed1t khi d\u1ecbch nh\u1eefng c\u00e2u ng\u1eafn, nh\u01b0ng ch\u00fang l\u1ea1i kh\u00f4ng hi\u1ec7u qu\u1ea3 v\u1edbi c\u00e1c v\u0103n b\u1ea3n d\u00e0i v\u00ec ch\u00fang kh\u00f4ng c\u00f3 kh\u1ea3 n\u0103ng truy c\u1eadp tr\u1ef1c ti\u1ebfp v\u00e0o nh\u1eefng t\u1eeb tr\u01b0\u1edbc \u0111\u00f3 trong \u0111\u1ea7u v\u00e0o. M\u1ed9t \u0111i\u1ec3m h\u1ea1n ch\u1ebf l\u1edbn c\u1ee7a ph\u01b0\u01a1ng ph\u00e1p n\u00e0y l\u00e0 RNN ph\u1ea3i ghi nh\u1edb to\u00e0n b\u1ed9 \u0111\u1ea7u v\u00e0o \u0111\u00e3 \u0111\u01b0\u1ee3c m\u00e3 h\u00f3a trong m\u1ed9t tr\u1ea1ng th\u00e1i \u1ea9n duy nh\u1ea5t tr\u01b0\u1edbc khi truy\u1ec1n n\u00f3 cho b\u1ed9 gi\u1ea3i m\u00e3.</p> <p>Ch\u00ednh v\u00ec v\u1eady, v\u00e0o n\u0103m 2014 c\u01a1 ch\u1ebf attention Bahdanau cho RNN xu\u1ea5t hi\u1ec7n. C\u01a1 ch\u1ebf n\u00e0y \u0111i\u1ec1u ch\u1ec9nh ki\u1ebfn tr\u00fac RNN encoder-decoder sao cho b\u1ed9 gi\u1ea3i m\u00e3 c\u00f3 th\u1ec3 truy c\u1eadp ch\u1ecdn l\u1ecdc c\u00e1c ph\u1ea7n kh\u00e1c nhau c\u1ee7a chu\u1ed7i \u0111\u1ea7u v\u00e0o t\u1ea1i m\u1ed7i b\u01b0\u1edbc sinh \u0111\u1ea7u ra. Khi sinh ra m\u1ed9t t\u1eeb trong \u0111\u1ea7u ra, m\u00f4 h\u00ecnh c\u00f3 c\u00e1ch \u0111\u1ec3 truy c\u1eadp v\u00e0o t\u1ea5t c\u1ea3 c\u00e1c t\u1eeb \u0111\u1ea7u v\u00e0o. \u0110\u1ed9 d\u00e0y c\u1ee7a \u0111\u01b0\u1eddng ch\u1ea5m th\u1ec3 hi\u1ec7n m\u1ee9c \u0111\u1ed9 quan tr\u1ecdng c\u1ee7a t\u1eeb \u0111\u1ea7u v\u00e0o \u0111\u1ed1i v\u1edbi t\u1eeb \u0111\u1ea7u ra t\u01b0\u01a1ng \u1ee9ng. \u0110i\u1ec1u n\u00e0y c\u00f3 ngh\u0129a l\u00e0 m\u1ed9t s\u1ed1 t\u1eeb \u0111\u1ea7u v\u00e0o s\u1ebd quan tr\u1ecdng h\u01a1n nh\u1eefng t\u1eeb kh\u00e1c cho vi\u1ec7c sinh ra m\u1ed9t t\u1eeb \u0111\u1ea7u ra nh\u1ea5t \u0111\u1ecbnh. \u0110\u1ed9 quan tr\u1ecdng \u0111\u01b0\u1ee3c x\u00e1c \u0111\u1ecbnh b\u1edfi c\u00e1c tr\u1ecdng s\u1ed1 attention s\u1ebd \u0111\u01b0\u1ee3c \u0111\u1ec1 c\u1eadp \u1edf ph\u1ea7n ti\u1ebfp theo.</p> <p>Ch\u1ec9 ba n\u0103m sau, c\u00e1c nh\u00e0 nghi\u00ean c\u1ee9u \u0111\u00e3 ph\u00e1t hi\u1ec7n ra r\u1eb1ng ki\u1ebfn tr\u00fac RNN kh\u00f4ng c\u00f2n c\u1ea7n thi\u1ebft \u0111\u1ec3 x\u00e2y d\u1ef1ng m\u1ea1ng n\u01a1-ron s\u00e2u cho x\u1eed l\u00fd ng\u00f4n ng\u1eef t\u1ef1 nhi\u00ean. H\u1ecd \u0111\u00e3 \u0111\u1ec1 xu\u1ea5t ki\u1ebfn tr\u00fac Transformer bao g\u1ed3m m\u1ed9t c\u01a1 ch\u1ebf self-attention l\u1ea5y c\u1ea3m h\u1ee9ng t\u1eeb c\u01a1 ch\u1ebf attention Bahdanau. Self-attention l\u00e0 m\u1ed9t c\u01a1 ch\u1ebf cho ph\u00e9p m\u1ed7i v\u1ecb tr\u00ed trong chu\u1ed7i \u0111\u1ea7u v\u00e0o c\u00f3 th\u1ec3 xem x\u00e9t m\u1ee9c \u0111\u1ed9 li\u00ean quan c\u1ee7a t\u1ea5t c\u1ea3 c\u00e1c v\u1ecb tr\u00ed kh\u00e1c trong c\u00f9ng chu\u1ed7i khi t\u00ednh to\u00e1n bi\u1ec3u di\u1ec5n c\u1ee7a chu\u1ed7i \u0111\u00f3. Self-attention l\u00e0 m\u1ed9t th\u00e0nh ph\u1ea7n c\u1ed1t l\u00f5i c\u1ee7a c\u00e1c m\u00f4 h\u00ecnh ng\u00f4n ng\u1eef l\u1edbn hi\u1ec7n \u0111\u1ea1i d\u1ef1a tr\u00ean ki\u1ebfn tr\u00fac Transformer, ch\u1eb3ng h\u1ea1n nh\u01b0 d\u00f2ng GPT.</p>"},{"location":"courses/large-language-models/lessson/lesson-03-attention_mechanisms/#concept-of-self-attention","title":"Concept of self-attention","text":"<p>Trong self-attention, ch\u1eef \u201cself\u201d \u00e1m ch\u1ec9 kh\u1ea3 n\u0103ng c\u1ee7a c\u01a1 ch\u1ebf n\u00e0y trong vi\u1ec7c t\u00ednh to\u00e1n c\u00e1c tr\u1ecdng s\u1ed1 attention b\u1eb1ng c\u00e1ch thi\u1ebft l\u1eadp m\u1ed1i li\u00ean h\u1ec7 gi\u1eefa nh\u1eefng v\u1ecb tr\u00ed kh\u00e1c nhau trong c\u00f9ng m\u1ed9t chu\u1ed7i \u0111\u1ea7u v\u00e0o. C\u01a1 ch\u1ebf n\u00e0y cho ph\u00e9p m\u00f4 h\u00ecnh \u0111\u00e1nh gi\u00e1 v\u00e0 h\u1ecdc \u0111\u01b0\u1ee3c c\u00e1c m\u1ed1i quan h\u1ec7, s\u1ef1 ph\u1ee5 thu\u1ed9c gi\u1eefa c\u00e1c th\u00e0nh ph\u1ea7n c\u1ee7a ch\u00ednh chu\u1ed7i \u0111\u00f3, ch\u1eb3ng h\u1ea1n nh\u01b0 gi\u1eefa c\u00e1c t\u1eeb trong m\u1ed9t c\u00e2u ho\u1eb7c gi\u1eefa c\u00e1c pixel trong m\u1ed9t h\u00ecnh \u1ea3nh.</p> <p>\u0110i\u1ec1u n\u00e0y tr\u00e1i ng\u01b0\u1ee3c v\u1edbi attention truy\u1ec1n th\u1ed1ng, n\u01a1i tr\u1ecdng t\u00e2m l\u00e0 m\u1ed1i quan h\u1ec7 gi\u1eefa c\u00e1c ph\u1ea7n t\u1eed thu\u1ed9c hai chu\u1ed7i kh\u00e1c nhau. V\u00ed d\u1ee5, trong m\u00f4 h\u00ecnh sequence-to-sequence, attention \u0111\u01b0\u1ee3c t\u00ednh to\u00e1n gi\u1eefa m\u1ed9t chu\u1ed7i \u0111\u1ea7u v\u00e0o v\u00e0 chu\u1ed7i \u0111\u1ea7u ra t\u01b0\u01a1ng \u1ee9ng.</p>"},{"location":"courses/large-language-models/lessson/lesson-03-attention_mechanisms/#a-simple-self-attention-mechanism","title":"A simple self-attention mechanism","text":"<p>\u0110\u00e2y l\u00e0 bi\u1ebfn th\u1ec3 \u0111\u01a1n gi\u1ea3n c\u1ee7a self-attention, kh\u00f4ng c\u00f3 b\u1ea5t k\u1ef3 tr\u1ecdng s\u1ed1 hu\u1ea5n luy\u1ec7n n\u00e0o, nh\u01b0 \u0111\u01b0\u1ee3c m\u00f4 t\u1ea3 trong h\u00ecnh 3.1. M\u1ee5c ti\u00eau l\u00e0 minh ho\u1ea1 m\u1ed9t s\u1ed1 kh\u00e1i ni\u1ec7m ch\u00ednh trong self-attention tr\u01b0\u1edbc khi th\u00eam c\u00e1c tr\u1ecdng s\u1ed1 c\u00f3 th\u1ec3 hu\u1ea5n luy\u1ec7n. </p> <p></p> <p>H\u00ecnh 3.1 M\u00f4 t\u1ea3 m\u1ee5c ti\u00eau c\u1ee7a self-attention trong vi\u1ec7c t\u00ednh to\u00e1n m\u1ed9t vector ng\u1eef c\u1ea3nh cho m\u1ed7i ph\u1ea7n t\u1eeb \u0111\u1ea7u v\u00e0o, b\u1eb1ng c\u00e1ch k\u1ebft h\u1ee3p th\u00f4ng tin t\u1eeb t\u1ea5t c\u1ea3 c\u00e1c ph\u1ea7n t\u1eeb \u0111\u1ea7u v\u00e0o kh\u00e1c. Trong v\u00ed d\u1ee5 n\u00e0y, ch\u00fang ta \u0111ang t\u00ednh vector ng\u1eef c\u1ea3nh \\(z^{(2)}\\). M\u1ee9c \u0111\u1ed9 quan tr\u1ecdng hay s\u1ef1 \u0111\u00f3ng g\u00f3p c\u1ee7a t\u1eebng ph\u1ea7n t\u1eed \u0111\u1ea7u v\u00e0o trong vi\u1ec7c t\u00ednh \\(z^{(2)}\\) \u0111\u01b0\u1ee3c x\u00e1c \u0111\u1ecbnh b\u1edfi c\u00e1c tr\u1ecdng s\u1ed1 attention \\(\\alpha_{21}\\) \u0111\u1ebfn \\(\\alpha_{2T}\\). Khi t\u00ednh \\(z^{(2)}\\) c\u00e1c tr\u1ecdng s\u1ed1 attention \u0111\u01b0\u1ee3c t\u00ednh to\u00e1n d\u1ef1a tr\u00ean ph\u1ea7n t\u1eeb \u0111\u1ea7u v\u00e0o \\(x^{(2)}\\) v\u00e0 t\u1ea5t c\u1ea3 c\u00e1c ph\u1ea7n t\u1eeb \u0111\u1ea7u v\u00e0o kh\u00e1c.</p> <p>H\u00ecnh 3.1 minh h\u1ecda m\u1ed9t chu\u1ed7i \u0111\u1ea7u v\u00e0o k\u00fd hi\u1ec7u l\u00e0 \\(x\\), g\u1ed3m \\(T\\) ph\u1ea7n t\u1eed t\u1eeb \\(x^{(1)}\\) \u0111\u1ebfn \\(x^{(T)}\\). Chu\u1ed7i n\u00e0y th\u01b0\u1eddng bi\u1ec3u di\u1ec5n v\u0103n b\u1ea3n \u0111\u00e3 \u0111\u01b0\u1ee3c bi\u1ebfn \u0111\u1ed5i th\u00e0nh c\u00e1c token embedding. Ch\u1eb3ng h\u1ea1n, v\u1edbi c\u00e2u \u201cThe quick brown fox jumps high\u201d, m\u1ed7i ph\u1ea7n t\u1eed trong chu\u1ed7i, nh\u01b0 \\(x^{(1)}\\), t\u01b0\u01a1ng \u1ee9ng v\u1edbi m\u1ed9t vector embedding d-chi\u1ec1u \u0111\u1ea1i di\u1ec7n cho m\u1ed9t token c\u1ee5 th\u1ec3 (v\u00ed d\u1ee5: t\u1eeb \u201cThe\u201d). Trong v\u00ed d\u1ee5 n\u00e0y, ta gi\u1ea3 s\u1eed c\u00e1c vector \u0111\u1ea7u v\u00e0o l\u00e0 embedding ba chi\u1ec1u (xem ch\u00fa th\u00edch I trong h\u00ecnh).</p> <p>Trong self-attention, m\u1ee5c ti\u00eau l\u00e0 t\u00ednh to\u00e1n c\u00e1c vector ng\u1eef c\u1ea3nh \\(z^{(i)}\\) cho m\u1ed7i ph\u1ea7n t\u1eed \\(x^{(i)}\\) trong chu\u1ed7i \u0111\u1ea7u v\u00e0o. Vector ng\u1eef c\u1ea3nh c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c hi\u1ec3u l\u00e0 m\u1ed9t embedding \u0111\u01b0\u1ee3c l\u00e0m gi\u00e0u, b\u1edfi n\u00f3 kh\u00f4ng ch\u1ec9 ch\u1ee9a th\u00f4ng tin v\u1ec1 \\(x^{(i)}\\) m\u00e0 c\u00f2n k\u1ebft h\u1ee3p th\u00f4ng tin t\u1eeb t\u1ea5t c\u1ea3 c\u00e1c ph\u1ea7n t\u1eed \\(x^{(j)}\\) kh\u00e1c trong c\u00f9ng chu\u1ed7i.</p> <p>\u0110\u1ec3 minh h\u1ecda, h\u00e3y x\u00e9t vector embedding c\u1ee7a ph\u1ea7n t\u1eed th\u1ee9 hai \\(x^{(2)}\\) (t\u01b0\u01a1ng \u1ee9ng v\u1edbi token \u201cquick\u201d) v\u00e0 vector ng\u1eef c\u1ea3nh t\u01b0\u01a1ng \u1ee9ng \\(z^{(2)}\\). Vector ng\u1eef c\u1ea3nh n\u00e0y l\u00e0 m\u1ed9t embedding ch\u1ee9a th\u00f4ng tin v\u1ec1 \\(x^{(2)}\\) \u0111\u1ed3ng th\u1eddi g\u00f3i g\u1ecdn c\u1ea3 th\u00f4ng tin t\u1eeb c\u00e1c ph\u1ea7n t\u1eed kh\u00e1c, t\u1eeb \\(x^{(1)}\\) \u0111\u1ebfn \\(x^{(T)}\\).</p> <p>Vector ng\u1eef c\u1ea3nh gi\u1eef vai tr\u00f2 quan tr\u1ecdng trong self-attention. Nhi\u1ec7m v\u1ee5 c\u1ee7a ch\u00fang l\u00e0 t\u1ea1o ra nh\u1eefng bi\u1ec3u di\u1ec5n l\u00e0m gi\u00e0u cho t\u1eebng ph\u1ea7n t\u1eed trong chu\u1ed7i b\u1eb1ng c\u00e1ch k\u1ebft h\u1ee3p th\u00f4ng tin t\u1eeb t\u1ea5t c\u1ea3 c\u00e1c ph\u1ea7n t\u1eed c\u00f2n l\u1ea1i. \u0110\u00e2y l\u00e0 y\u1ebfu t\u1ed1 then ch\u1ed1t trong c\u00e1c m\u00f4 h\u00ecnh ng\u00f4n ng\u1eef l\u1edbn, v\u1ed1n c\u1ea7n n\u1eafm b\u1eaft \u0111\u01b0\u1ee3c m\u1ed1i quan h\u1ec7 v\u00e0 m\u1ee9c \u0111\u1ed9 li\u00ean quan gi\u1eefa c\u00e1c t\u1eeb trong m\u1ed9t c\u00e2u.</p>"},{"location":"knowledge-base/","title":"Knowledge Base","text":""},{"location":"knowledge-base/#knowledge-base","title":"\ud83e\uded2 Knowledge Base","text":"<p>\u2b50 \"Live as if you were to die tomorrow. Learn as if you were to live forever\"</p> <p>\ud83d\udca1 \"Dreams don't work unless you do\"</p> <p> </p> <p> </p>"},{"location":"knowledge-base/#gioi-thieu","title":"\ud83c\udfaf Gi\u1edbi thi\u1ec7u","text":""},{"location":"knowledge-base/fastapi/","title":"FastAPI Tutorials","text":""},{"location":"knowledge-base/fastapi/lesson-01-overview/","title":"\u2744\ufe0f Lesson 01. FastAPI Overview and Project Setup","text":"<p>N\u1ed9i dung trong b\u00e0i n\u00e0y cung c\u1ea5p c\u00e1c ki\u1ebfn th\u1ee9c, c\u1ea5u tr\u00fac c\u01a1 b\u1ea3n v\u00e0 v\u1eefng ch\u1eafc v\u1ec1 FastAPI. B\u1ea1n s\u1ebd c\u00f3 th\u1ec3 thi\u1ebft l\u1eadp m\u1ed9t d\u1ef1 \u00e1n m\u1edbi, \u0111\u1ecbnh ngh\u0129a \u0111\u01b0\u1ee3c c\u00e1c endpoint API, n\u1eafm b\u1eaft \u0111\u01b0\u1ee3c c\u00e1ch x\u1eed l\u00fd d\u1eef li\u1ec7u v\u1edbi FastAPI.</p>"},{"location":"knowledge-base/fastapi/lesson-01-overview/#technical-requirements","title":"Technical requirements","text":"<p>\u0110\u1ec3 tri\u1ec3n khai th\u00e0nh c\u00f4ng m\u1ed9t d\u1ef1 \u00e1n v\u1edbi FastAPI, c\u1ea7n thi\u1ebft l\u1eadp m\u1ed9t m\u00f4i tr\u01b0\u1eddng h\u1ed7 tr\u1ee3 ph\u00e1t tri\u1ec3n Python v\u00e0 c\u00e1c ch\u1ee9c n\u0103ng c\u1ee7a FastAPI. M\u1ed9t s\u1ed1 th\u00e0nh ph\u1ea7n k\u1ef9 thu\u1eadt quan tr\u1ecdng c\u1ea7n c\u00e0i \u0111\u1eb7t:</p> <ul> <li> <p>Python: FastAPI \u0111\u01b0\u1ee3c x\u00e2y d\u1ef1ng tr\u00ean Python, v\u00ec v\u1eady c\u1ea7n m\u1ed9t phi\u00ean b\u1ea3n Python t\u01b0\u01a1ng th\u00edch v\u1edbi phi\u00ean b\u1ea3n FastAPI t\u01b0\u01a1ng \u1ee9ng.</p> </li> <li> <p>FastAPI: C\u00e0i \u0111\u1eb7t b\u1eb1ng pip, tr\u00ecnh qu\u1ea3n l\u00fd g\u00f3i c\u1ee7a Python.</p> </li> <li> <p>Uvicorn: FastAPI c\u1ea7n m\u1ed9t ASGI server (Asynchronous Server Gateway Interface), v\u00e0 Uvicorn l\u00e0 m\u1ed9t tri\u1ec3n khai ASCI c\u1ef1c k\u00ec nhanh.</p> </li> <li> <p>IDE (Integrated Development Environment): M\u1ed9t IDE nh\u01b0 Visual Studo Code (VS Code), PyCharm,..., h\u1ed7 tr\u1ee3 ph\u00e1t tri\u1ec3n Python trong vi\u1ec7c vi\u1ebft m\u00e3 v\u00e0 ki\u1ec3m th\u1eed code.</p> </li> <li> <p>Postman ho\u1eb7c Swagger UI: D\u00f9ng \u0111\u1ec3 ki\u1ec3m th\u1eed API endpoints. FastAPI t\u1ef1 \u0111\u1ed9ng t\u1ea1o v\u00e0 host Swagger UI, c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng ngay m\u00e0 kh\u00f4ng c\u1ea7n c\u1ea7n c\u1ea5u h\u00ecnh g\u00ec th\u00eam.</p> </li> <li> <p>Git: L\u00e0 c\u00f4ng c\u1ee5 \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng r\u1ed9ng r\u00e3i cho ph\u00e9p qu\u1ea3n l\u00fd phi\u00ean b\u1ea3n.</p> </li> </ul>"},{"location":"knowledge-base/fastapi/lesson-01-overview/#setting-up-development-environment","title":"Setting up development environment","text":"<p>C\u00e0i \u0111\u1eb7t Python tr\u00ean Windows. FastAPI h\u1ecdat \u0111\u1ed9ng v\u1edbi Python, v\u00ec v\u1eady c\u1ea7n ki\u1ec3m tra phi\u00ean b\u1ea3n Python tr\u01b0\u1edbc khi s\u1eed d\u1ee5ng, \u0111\u00e2y l\u00e0 b\u01b0\u1edbc quan tr\u1ecdng \u0111\u1ec3 thi\u1ebft l\u1eadp FastAPI.</p> <ol> <li> <p>Truy c\u1eadp trang ch\u00ednh th\u1ee9c c\u1ee7a Python: python.org, t\u1ea3i phi\u00ean b\u1ea3n Python m\u1edbi nh\u1ea5t, ho\u1eb7c t\u1ed1i thi\u1ec3u &gt;= 3.9.</p> </li> <li> <p>Ch\u1ea1y file c\u00e0i \u0111\u1eb7t, nh\u1edb t\u00edch v\u00e0o \u00f4 <code>Add Python to Path</code> tr\u01b0\u1edbc khi b\u1ea5m <code>Install Now</code>.</p> </li> <li> <p>Sau khi c\u00e0i xong, m\u1edf Command Prompt (cmd) v\u00e0 g\u00f5: <code>python --version</code> \u0111\u1ec3 ki\u1ec3m tra phi\u00ean b\u1ea3n.</p> </li> </ol> <p>C\u00e0i \u0111\u1eb7t Python tr\u00ean macOS/Linux. macOS th\u01b0\u1eddng c\u00f3 s\u1eb5n Python, nh\u01b0ng th\u01b0\u1eddng l\u00e0 b\u1ea3n c\u0169, b\u1ea1n n\u00ean c\u00e0i b\u1ea3n m\u1edfi b\u1eb1ng Homebrew.</p> <p>C\u00e0i Homebrew (n\u1ebfu ch\u01b0a c\u00f3):</p> <p><pre><code>/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n</code></pre> Sau \u0111\u00f3 c\u00e0i Python qua l\u1ec7nh:</p> <p><pre><code>brew install python\n</code></pre> \u0110\u1ed1i v\u1edbi Linux (Ubuntu/Debian) th\u1ef1c hi\u1ec7n c\u00e0i Python b\u1eb1ng <code>apt</code> th\u00f4ng qua l\u1ec7nh:</p> <pre><code>sudo apt-get install python3\n</code></pre> <p>Ki\u1ec3m tra phi\u00ean b\u1ea3n sau khi c\u00e0i \u0111\u1eb7t. Tr\u00ean macOS/Windows ch\u1ea1y <code>python --version</code>, tr\u00ean Linux <code>python3 --version</code>. Ngo\u00e0i ra, ki\u1ec3m tra pip (tr\u00ecnh qu\u1ea3n l\u00fd g\u00f3i c\u1ee7a Python), tr\u00ean macOS/Windows ch\u1ea1y <code>pip --version</code>, tr\u00ean Linux <code>pip3 --version</code>.</p> <p>C\u00e0i \u0111\u1eb7t FastAPI v\u00e0 Uvicorn. Sau khi c\u00e0i \u0111\u1eb7t th\u00e0nh c\u00f4ng Python v\u00e0 pip, ti\u1ebfp theo s\u1ebd c\u00e0i \u0111\u1eb7t FastAPI v\u00e0 Uvicorn. M\u1edf terminal/command prompt v\u00e0 ch\u1ea1y <code>pip install fastapi[all]</code>. L\u1ec7nh n\u00e0y s\u1ebd c\u00e0i FastAPI c\u00f9ng t\u1ea5t c\u1ea3 c\u00e1c dependencies \u0111\u01b0\u1ee3c khuy\u1ebfn ngh\u1ecb, bao g\u1ed3m c\u1ea3 Uvicorn. Ki\u1ec3m tra c\u00e0i \u0111\u1eb7t ch\u1ea1y <code>uvicorn --version</code>.</p> <p>Thi\u1ebft l\u1eadp IDE. IDE kh\u00f4ng ch\u1ec9 l\u00e0 editor, m\u00e0 c\u00f2n l\u00e0 n\u01a1i vi\u1ebft code, debug, v\u00e0 test \u1ee9ng d\u1ee5ng. M\u1ed9t s\u1ed1 IDE ph\u1ed5 bi\u1ebfn cho FastAPI m\u00e0 b\u1ea1n c\u00f3 th\u1ec3 t\u1ea3i v\u00e0 d\u00f9ng l\u00e0 VS Code v\u00e0 PyCharm.</p> <p>Thi\u1ebft l\u1eadp Git v\u00e0 Github. Qu\u1ea3n l\u00fd phi\u00ean b\u1ea3n (Version Control) l\u00e0 m\u1ed9t kh\u00eda c\u1ea1nh quan tr\u1ecdng c\u1ee7a ph\u00e1t tri\u1ec3n ph\u1ea7m m\u1ec1m. Git k\u1ebft h\u1ee3p GitHub t\u1ea1o th\u00e0nh m\u1ed9t b\u1ed9 c\u00f4ng c\u1ee5 m\u1ea1nh m\u1ebd \u0111\u1ec3 theo d\u00f5i thay \u0111\u1ed5i, c\u1ed9ng t\u00e1c nh\u00f3m v\u00e0 duy tr\u00ec l\u1ecbch s\u1eed d\u1ef1 \u00e1n. C\u00f3 th\u1ec3 t\u00ecm v\u00e0 c\u00e0i \u0111\u1eb7t Git t\u1eeb trang ch\u00ednh th\u1ee9c git-scm.com.</p> <p>Sau khi c\u00e0i xong, c\u1ea5u h\u00ecnh Git v\u1edbi t\u00ean v\u00e0 email c\u1ee7a b\u1ea1n trong command line:</p> <pre><code>git config --global user.name \"Your Name\"\ngit config --global user.email \"your.email@example.com\"\n</code></pre>"},{"location":"knowledge-base/fastapi/lesson-01-overview/#creating-a-fastapi-project","title":"Creating a FastAPI project","text":"<p>B\u1eaft \u0111\u1ea7u b\u1eb1ng vi\u1ec7c kh\u1edfi t\u1ea1o m\u1ed9t project folder v\u1edbi t\u00ean m\u00e0 b\u1ea1n th\u00edch (\u0111\u00e2y s\u1ebd l\u00e0 n\u01a1i ch\u1ee9a to\u00e0n b\u1ed9 m\u00e3 ngu\u1ed3n d\u1ef1 \u00e1n). Tr\u01b0\u1edbc h\u1ebft, b\u1ea1n c\u1ea7n t\u1ea1o m\u1ed9t m\u00f4i tr\u01b0\u1eddng \u1ea3o:</p> <pre><code>$ python -m venv .venv\n</code></pre> <p>\u0110\u1ec3 k\u00edch ho\u1ea1t m\u00f4i tr\u01b0\u1eddng \u1ea3o, n\u1ebfu b\u1ea1n s\u1eed d\u1ee5ng Mac or Linux:</p> <pre><code>$ source .venv/bin/activate\n</code></pre> <p>Tr\u00ean h\u1ec7 \u0111i\u1ec1u h\u00e0nh Windows, ch\u1ea1y d\u00f2ng l\u1ec7nh sau:</p> <pre><code>$ .venv\\Scripts\\activate\n</code></pre> <p>Khi m\u00f4i tr\u01b0\u1eddng \u1ea3o \u0111\u01b0\u1ee3c k\u00edch ho\u1ea1t, b\u1ea1n s\u1ebd th\u1ea5y trong terminal c\u00f3 m\u1ed9t chu\u1ed7i ti\u1ec1n t\u1ed1 nh\u01b0 sau: <code>(.venv) $</code>. T\u1eeb th\u1eddi \u0111i\u1ec3m n\u00e0y, to\u00e0n b\u1ed9 c\u00e1c module b\u1ea1n c\u00e0i \u0111\u1eb7t b\u1eb1ng pip s\u1ebd \u0111\u01b0\u1ee3c l\u01b0u tr\u1eef v\u00e0 c\u00e0i \u0111\u1eb7t v\u00e0o th\u01b0 m\u1ee5c <code>.venv</code>, v\u00e0 ch\u1ec9 s\u1eed d\u1ee5ng \u0111\u01b0\u1ee3c khi m\u00f4i tr\u01b0\u1eddng n\u00e0y \u0111ang ho\u1ea1t \u0111\u1ed9ng.</p> <p>B\u00e2y gi\u1edd, b\u1ea1n c\u00f3 th\u1ec3 c\u00e0i \u0111\u1eb7t g\u00f3i fastapi c\u00f9ng v\u1edbi uvicorn trong m\u00f4i tr\u01b0\u1eddng \u1ea3o c\u1ee7a m\u00ecnh b\u1eb1ng c\u00e1ch ch\u1ea1y l\u1ec7nh sau:</p> <pre><code>$ pip install fastapi uvicorn\n</code></pre> <p>Sau khi FastAPI \u0111\u00e3 \u0111\u01b0\u1ee3c c\u00e0i \u0111\u1eb7t, h\u00e3y m\u1edf th\u01b0 m\u1ee5c d\u1ef1 \u00e1n v\u00e0 t\u1ea1o m\u1ed9t file c\u00f3 t\u00ean l\u00e0 <code>main.py</code>. File n\u00e0y s\u1ebd l\u00e0 n\u01a1i \u1ee9ng d\u1ee5ng FastAPI c\u1ee7a b\u1ea1n b\u1eaft \u0111\u1ea7u.</p> <pre><code># import module FastAPI\nfrom fastapi import FastAPI\n\n# kh\u1edfi t\u1ea1o instance c\u1ee7a l\u1edbp FastAPI\napp = FastAPI()\n</code></pre> <p>\u0110\u1ecbnh ngh\u0129a router \u0111\u1ea7u ti\u00ean trong \u1ee9ng d\u1ee5ng. Router trong FastAPI gi\u1ed1ng nh\u01b0 bi\u1ebfn ch\u1ec9 \u0111\u01b0\u1eddng, gi\u00fap \u0111i\u1ec1u h\u01b0\u1edbng request \u0111\u1ebfn \u0111\u00fang function.</p> <pre><code>@app.get(\"/\")\ndef read_root(): \n    return {\"Hello\" : \"World\"}\n</code></pre>"},{"location":"knowledge-base/fastapi/lesson-01-overview/#structure-project","title":"Structure project","text":"<p>Trong b\u1ea5t k\u1ec3 d\u1ef1 \u00e1n n\u00e0o, vi\u1ec7c s\u1eafp x\u1ebfp m\u00e3 ngu\u1ed3n theo m\u1ed9t c\u1ea5u tr\u00fac r\u00f5 r\u00e0ng kh\u00f4ng ch\u1ec9 l\u00e0 v\u1ea5n \u0111\u1ec1 g\u1ecdn g\u00e0ng m\u00e0 c\u00f2n l\u00e0 vi\u1ec7c t\u1ea1o ra m\u1ed9t m\u00f4i tr\u01b0\u1eddng b\u1ec1n v\u1eefng v\u00e0 c\u00f3 kh\u1ea3 n\u0103ng m\u1edf r\u1ed9ng. \u0110i\u1ec1u n\u00e0y c\u00f3 ngh\u0129a l\u00e0 b\u1ea1n c\u1ea7n t\u1ed5 ch\u1ee9c d\u1ef1 \u00e1n theo c\u00e1ch t\u00e1ch bi\u1ec7t c\u00e1c ph\u1ea7n kh\u00e1c nhau c\u1ee7a \u1ee9ng d\u1ee5ng m\u1ed9t c\u00e1ch logic v\u00e0 hi\u1ec7u qu\u1ea3.</p> <p>Kh\u00f4ng c\u00f3 m\u1ed9t c\u1ea5u tr\u00fac duy nh\u1ea5t v\u00e0 ho\u00e0n h\u1ea3o cho m\u1ecdi d\u1ef1 \u00e1n FastAPI, tuy nhi\u00ean, m\u1ed9t c\u00e1ch ti\u1ebfp c\u1eadn ph\u1ed5 bi\u1ebfn l\u00e0 chia d\u1ef1 \u00e1n th\u00e0nh m\u1ed9t s\u1ed1 th\u01b0 m\u1ee5c ch\u00ednh:</p> <ul> <li> <p>/src: \u0110\u00e2y l\u00e0 n\u01a1i ch\u1ee9a code ch\u00ednh c\u1ee7a \u1ee9ng d\u1ee5ng, b\u00ean trong c\u00f3 th\u1ec3 c\u00f3 c\u00e1c th\u01b0 m\u1ee5c con cho nh\u1eefng module kh\u00e1c nhau. V\u00ed d\u1ee5: <code>models</code> - ch\u1ee9a c\u00e1c database models; <code>routes</code> - ch\u1ee9a c\u00e1c route c\u1ee7a FastAPI; <code>services</code> - ch\u1ee9a ph\u1ea7n logic nghi\u1ec7p v\u1ee5.</p> </li> <li> <p>/tests: T\u00e1ch ri\u00eang ra kh\u1ecfi code \u1ee9ng d\u1ee5ng l\u00e0 m\u1ed9t c\u00e1ch t\u1ed1t, gi\u00fap d\u1ec5 d\u00e0ng qu\u1ea3n l\u00fd, d\u1ed3ng th\u1eddi \u0111\u1ea3m b\u1ea3o r\u1eb1ng build production kh\u00f4ng bao g\u1ed3m code test.</p> </li> <li> <p>docs: T\u1ea3i li\u1ec7u l\u00e0 r\u1ea5t quan tr\u1ecdng v\u1edbi b\u1ea5t k\u1ef3 d\u1ef1 \u00e1n n\u00e0o, ph\u1ea7n n\u00e0y s\u1ebd bao g\u1ed3m h\u01b0\u1edbng d\u1eabn c\u00e0i \u0111\u1eb7t, h\u01b0\u1edbng d\u1eabn s\u1eed d\u1ee5ng,v.v. Vi\u1ec7c c\u00f3 m\u1ed9t th\u01b0 m\u1ee5c d\u00e0nh ri\u00eang cho t\u00e0i li\u1ec7u gi\u00fap d\u1ef1 \u00e1n r\u00f5 r\u00e0ng v\u00e0 d\u1ec5 duy tr\u00ec h\u01a1n.</p> </li> </ul>"},{"location":"knowledge-base/fastapi/lesson-01-overview/#basic-concepts-of-fastapi","title":"Basic concepts of FastAPI","text":"<p>Kh\u00e1i ni\u1ec7m v\u00e0 \u0111\u1eb7c \u0111i\u1ec3m ch\u00ednh c\u1ee7a FastAPI. FastAPI l\u00e0 m\u1ed9t framework web hi\u1ec7n \u0111\u1ea1i v\u00e0 nhanh \u0111\u1ec3 \u0111\u1ec3 x\u00e2y d\u1ef1ng API v\u1edbi Python, d\u1ef1a tr\u00ean type hints ti\u00eau chu\u1ea9n c\u1ee7a Python. M\u1ed9t s\u1ed1 \u0111\u1eb7c \u0111i\u1ec3m ch\u00ednh c\u1ee7a FastAPI:</p> <ul> <li> <p>T\u1ed1c \u0111\u1ed9: \u0110\u00e2y l\u00e0 m\u1ed9t trong nh\u1eefng framework nhanh nh\u1ea5t \u0111\u1ec3 x\u00e2y d\u1ef1ng API b\u1eb1ng Python, nh\u1edd s\u1eed d\u1ee5ng Starlette cho ph\u1ea7n web v\u00e0 Pydantic cho x\u1eed l\u00fd d\u1eef li\u1ec7u.</p> </li> <li> <p>D\u1ec5 s\u1eed d\u1ee5ng: FastAPI \u0111\u01b0\u1ee3c thi\u1ebft k\u1ebf \u0111\u1ec3 d\u1ec5 h\u1ecdc, d\u1ec5 code, gi\u00fap t\u0103ng t\u1ed1c \u0111\u1ed9 ph\u00e1t tri\u1ec3n.</p> </li> <li> <p>T\u00e0i li\u1ec7u t\u1ef1 \u0111\u1ed9ng: V\u1edbi FastAPI, t\u00e0i li\u1ec7u API \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng sinh ra, v\u1eeba ti\u1ebft ki\u1ec7m th\u1eddi gian, v\u1eeba c\u1ef1c k\u1ef3 h\u1eefu \u00edch cho l\u1eadp tr\u00ecnh vi\u00ean.</p> </li> </ul> <p>Asynchronous programming (l\u1eadp tr\u00ecnh b\u1ea5t \u0111\u1ed3ng b\u1ed9). M\u1ed9t trong nh\u1eefng t\u00ednh n\u0103ng m\u1ea1nh m\u1ebd nh\u1ea5t c\u1ee7a FastAPI l\u00e0 h\u1ed7 tr\u1ee3 l\u1eadp tr\u00ecnh b\u1ea5t \u0111\u1ed3ng b\u1ed9. Cho ph\u00e9p:</p> <ul> <li> <p>\u1ee8ng d\u1ee5ng x\u1eed l\u00fd \u0111\u01b0\u1ee3c nhi\u1ec1u request c\u00f9ng l\u00fac.</p> </li> <li> <p>Tr\u00e1nh vi\u1ec7c m\u1ed9t t\u00e1c v\u1ee5 ch\u1eb7n c\u00e1c t\u00e1c v\u1ee5 kh\u00e1c.</p> </li> <li> <p>C\u1ea3i thi\u1ec7n hi\u1ec7u n\u0103ng t\u1ed5ng th\u1ec3 c\u1ee7a \u1ee9ng d\u1ee5ng.</p> </li> </ul> <p>L\u1eadp tr\u00ecnh b\u1ea5t \u0111\u1ed3ng b\u1ed9 l\u00e0 m\u1ed9t ki\u1ec3u l\u1eadp tr\u00ecnh concurrent programming (ch\u1ea1y \u0111\u1ed3ng th\u1eddi), trong \u0111\u00f3 c\u00e1c t\u00e1c v\u1ee5 \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n m\u00e0 kh\u00f4ng ch\u1eb7n lu\u1ed3ng x\u1eed l\u00fd ch\u00ednh.</p> <pre><code>from fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get(\"/\")\nasync def read_root():\n    return {\"Hello\": \"World\"}\n</code></pre> <p>\u1ede \u0111\u00e2y, ta d\u00f9ng <code>async def</code> thay cho <code>def</code>, h\u00e0nh vi c\u1ee7a code v\u1eabn gi\u1ed1ng nh\u01b0 tr\u01b0\u1edbc, khi b\u1ea1n truy c\u1eadp <code>/</code>, h\u00e0m tr\u1ea3 v\u1ec1 <code>{\"Hello\": \"World\"}</code>. Nh\u01b0ng n\u1ebfu sau n\u00e0y b\u1ea1n c\u1ea7n g\u1ecdi c\u00e1c t\u00e1c v\u1ee5 I/O b\u1ea5t \u0111\u1ed3ng b\u1ed9 (v\u00ed d\u1ee5: g\u1ecdi API kh\u00e1c, query DB b\u1ea5t \u0111\u1ed3ng b\u1ed9), th\u00ec vi\u1ec7c d\u00f9ng <code>async</code> s\u1ebd gi\u00fap \u1ee9ng d\u1ee5ng t\u1ed1i \u01b0u v\u00e0 nhanh h\u01a1n.</p> <p>Endpoints. L\u00e0 nh\u1eefng \u0111i\u1ec3m m\u00e0 t\u1ea1i \u0111\u00f3 di\u1ec5n ra s\u1ef1 t\u01b0\u01a1ng t\u00e1c v\u1edbi API. Trong FastAPI, m\u1ed9t endpoint \u0111\u01b0\u1ee3c t\u1ea1o ra b\u1eb1ng c\u00e1ch trang tr\u00ed (decorating) m\u1ed9t h\u00e0m v\u1edbi m\u1ed9t HTTP method, ch\u1eb3ng h\u1ea1n nh\u01b0 <code>app.get(\"/\")</code>. \u0110i\u1ec1u n\u00e0y c\u00f3 ngh\u0129a l\u00e0 m\u1ed9t y\u00eau c\u1ea7u GET s\u1ebd \u0111\u01b0\u1ee3c g\u1eedi t\u1edbi root <code>(\"/\")</code> c\u1ee7a \u1ee9ng d\u1ee5ng.</p> <pre><code>from fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get(\"/\")\nasync def read_root():\n    return {\"Hello\": \"World\"}\n</code></pre> <p>Trong \u0111o\u1ea1n code n\u00e0y, ch\u00fang ta \u0111ang \u0111\u1ecbnh ngh\u0129a m\u1ed9t endpoint cho URL g\u1ed1c <code>(\"/\")</code>. Khi c\u00f3 m\u1ed9t y\u00eau c\u1ea7u GET \u0111\u01b0\u1ee3c g\u1eedi \u0111\u1ebfn URL n\u00e0y, h\u00e0m <code>read_root</code> s\u1ebd \u0111\u01b0\u1ee3c g\u1ecdi v\u00e0 tr\u1ea3 v\u1ec1 m\u1ed9t ph\u1ea3n h\u1ed3i d\u1ea1ng JSON.</p> <p>Routers. Khi ch\u00fang ta c\u1ea7n x\u1eed l\u00fd nhi\u1ec1u endpoint n\u1eb1m \u1edf c\u00e1c file kh\u00e1c nhau, ch\u00fang ta c\u00f3 th\u1ec3 t\u1eadn d\u1ee5ng routers. Routers gi\u00fap nh\u00f3m c\u00e1c endpoint th\u00e0nh nh\u1eefng module ri\u00eang bi\u1ec7t, t\u1eeb \u0111\u00f3 l\u00e0m cho codebase d\u1ec5 b\u1ea3o tr\u00ec v\u00e0 d\u1ec5 hi\u1ec3u h\u01a1n. V\u00ed d\u1ee5, ch\u00fang ta c\u00f3 th\u1ec3 d\u00f9ng m\u1ed9t router cho c\u00e1c thao t\u00e1c li\u00ean quan \u0111\u1ebfn users v\u00e0 m\u1ed9t router kh\u00e1c cho c\u00e1c thao t\u00e1c li\u00ean quan \u0111\u1ebfn products.</p> <p>\u0110\u1ec3 \u0111\u1ecbnh ngh\u0129a m\u1ed9t router, tr\u01b0\u1edbc h\u1ebft h\u00e3y t\u1ea1o m\u1ed9t file m\u1edbi trong th\u01b0 m\u1ee5c d\u1ef1 \u00e1n c\u1ee7a b\u1ea1n v\u1edbi t\u00ean <code>router.py</code>. Sau \u0111\u00f3, t\u1ea1o router nh\u01b0 sau:</p> <pre><code>from fastapi import APIRouter\n\nrouter = APIRouter()\n\n@router.get(\"/items/{item_id}\")\nasync def read_item(item_id: int):\n    return {\"item_id\": item_id}\n</code></pre> <p>Gi\u1edd \u0111\u00e2y b\u1ea1n c\u00f3 th\u1ec3 t\u00e1i s\u1eed d\u1ee5ng router n\u00e0y v\u00e0 g\u1eafn ch\u00fang v\u00e0o instance FastAPI trong file <code>main.py</code>.</p> <pre><code>from fastapi import FastAPI\nimport routers\n\napp = FastAPI()\n\napp.include_router(routers.router)\n\n@app.get(\"/\")\nasync def read_root():\n    return {\"Hello\": \"World\"}\n</code></pre> <p>L\u00fac n\u00e0y, b\u1ea1n \u0111\u00e3 c\u00f3 code \u0111\u1ec3 ch\u1ea1y server, trong \u0111\u00f3 bao g\u1ed3m router cho endpoint <code>GET / items</code> \u0111\u01b0\u1ee3c import t\u1eeb m\u1ed9t module kh\u00e1c.</p> <p>Ch\u1ea1y server FastAPI. \u0110\u1ec3 ch\u1ea1y \u1ee9ng d\u1ee5ng FastAPI, b\u1ea1n ch\u1ec9 c\u1ea7n cho Uvicorn bi\u1ebft instance c\u1ee7a \u1ee9ng d\u1ee5ng. N\u1ebfu file c\u1ee7a b\u1ea1n c\u00f3 t\u00ean l\u00e0 <code>main.py</code> v\u00e0 instance FastAPI \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 app, b\u1ea1n c\u00f3 th\u1ec3 kh\u1edfi \u0111\u1ed9ng server \u1edf c\u1ea5p th\u01b0 m\u1ee5c b\u1eb1ng l\u1ec7nh sau:</p> <pre><code>$ uvicorn main:app --reload\n</code></pre> <p>Tham s\u1ed1 <code>--reload</code> s\u1ebd l\u00e0m cho server t\u1ef1 \u0111\u1ed9ng kh\u1edfi \u0111\u1ed9ng l\u1ea1i sau m\u1ed7i l\u1ea7n thay \u0111\u1ed5i code, r\u1ea5t h\u1eefu \u00edch cho l\u1eadp tr\u00ecnh vi\u00ean. Khi server \u0111\u00e3 ch\u1ea1y, b\u1ea1n c\u00f3 th\u1ec3 truy c\u1eadp API c\u1ee7a m\u00ecnh t\u1ea1i [http://127.0.0.1.8000]. N\u1ebfu b\u1ea1n m\u1edf URL trong tr\u00ecnh duy\u1ec7t, b\u1ea1n s\u1ebd th\u1ea5y ph\u1ea3n h\u1ed3i JSON t\u1eeb endpoint <code>\"/\"</code> m\u00e0 ch\u00fang ta v\u1eeba t\u1ea1o.</p> <p>M\u1ed9t trong nh\u1eefng t\u00ednh n\u0103ng th\u00fa v\u1ecb nh\u1ea5t c\u1ee7a FastAPI l\u00e0 t\u00e0i li\u1ec7u t\u1ef1 \u0111\u1ed9ng. Khi b\u1ea1n ch\u1ea1y \u1ee9ng d\u1ee5ng FastAPI, hai giao di\u1ec7n t\u00e0i li\u1ec7u s\u1ebd \u0111\u01b0\u1ee3c t\u1ea1o s\u1eb5n:</p> <ul> <li> <p>Swagger UI: [http://127.0.0.1.8000/docs]</p> </li> <li> <p>Redoc: [http://127.0.0.1.8000/redoc]</p> </li> </ul> <p>Hai giao di\u1ec7n n\u00e0y cung c\u1ea5p m\u1ed9t c\u00e1ch t\u01b0\u01a1ng t\u00e1c tr\u1ef1c quan \u0111\u1ec3 kh\u00e1m ph\u00e1 API v\u00e0 ki\u1ec3m th\u1eed c\u00e1c ch\u1ee9c n\u0103ng c\u1ee7a ch\u00fang.</p>"},{"location":"knowledge-base/fastapi/lesson-01-overview/#defining-first-api-endpoint","title":"Defining first API endpoint","text":"<p>Khi b\u1ea1n \u0111\u00e3 n\u1eafm \u0111\u01b0\u1ee3c nh\u1eefng ki\u1ebfn th\u1ee9c c\u01a1 b\u1ea3n v\u1ec1 FastAPI v\u00e0 m\u00f4i tr\u01b0\u1eddng ph\u00e1t tri\u1ec3n \u0111\u00e3 s\u1eb5n s\u00e0ng, b\u00e2y gi\u1edd ch\u00fang ta s\u1ebd \u0111i chi ti\u1ebft v\u1ec1 vi\u1ec7c kh\u1edfi t\u1ea1o endpoint \u0111\u1ea7u ti\u00ean. \u0110\u00e2y ch\u00ednh l\u00e0 n\u01a1i s\u1ee9c m\u1ea1nh th\u1eadt s\u1ef1 c\u1ee7a FastAPI, b\u1ea1n c\u00f3 th\u1ec3 x\u00e2y d\u1ef1ng \u0111\u01b0\u1ee3c m\u1ed9t endpoint API ho\u1ea1t \u0111\u1ed9ng, s\u1eb5n s\u00e0ng ph\u1ea3n h\u1ed3i c\u00e1c HTTP request m\u1ed9t c\u00e1ch d\u1ec5 d\u00e0ng. </p> <p>Trong web API, GET request c\u00f3 l\u1ebd l\u00e0 ph\u1ed5 bi\u1ebfn nh\u1ea5t. Ch\u00fang \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 l\u1ea5y d\u1eef li\u1ec7u t\u1eeb server. Trong FastAPI, vi\u1ec7c x\u1eed l\u00fd m\u1ed9t GET request r\u1ea5t \u0111\u01a1n gi\u1ea3n v\u00e0 tr\u1ef1c quan. Gi\u1ea3 s\u1eed b\u1ea1n \u0111ang x\u00e2y d\u1ef1ng API cho m\u1ed9t c\u1eeda h\u00e0ng s\u00e1ch. Endpoint \u0111\u1ea7u ti\u00ean s\u1ebd cung c\u1ea5p th\u00f4ng tin v\u1ec1 m\u1ed9t cu\u1ed1n s\u00e1ch d\u1ef1a tr\u00ean ID.</p> <pre><code>from fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get(\"/books/{book_id}\")\nasync def read_book(book_id: int):\n    return {\n        \"book_id\": book_id,\n        \"title\": \"Machine Learning Basic\",\n        \"author\": \"Scott Mc\"\n    }\n</code></pre> <p>Trong \u0111o\u1ea1n m\u00e3 tr\u00ean, decorator <code>@app.get(\"/books/{book_id}\")</code> b\u00e1o cho FastAPI r\u1eb1ng h\u00e0m n\u00e0y s\u1ebd ph\u1ea3n h\u1ed3i c\u00e1c GET request t\u1ea1i \u0111\u01b0\u1eddng d\u1eabn <code>/books/{book_id}</code>. Ph\u1ea7n <code>{book_id}</code> trong path \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 path parameter, \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 truy\u1ec1n gi\u00e1 tr\u1ecb t\u1ef1 \u0111\u1ed9ng. FastAPI s\u1ebd t\u1ef1 \u0111\u1ed9ng l\u1ea5y gi\u00e1 tr\u1ecb <code>book_id</code> t\u1eeb URL v\u00e0 truy\u1ec1n v\u00e0o h\u00e0m c\u1ee7a b\u1ea1n.</p> <p>H\u00e3y ch\u00fa \u00fd \u0111\u1ebfn <code>book_id: int</code> \u0111\u00e2y l\u00e0 m\u1ed9t type hints, FastAPI s\u1eed d\u1ee5ng type hint n\u00e0y \u0111\u1ec3 ki\u1ec3m tra d\u1eef li\u1ec7u. N\u1ebfu request g\u1eedi l\u00ean m\u00e0 <code>book_id</code> kh\u00f4ng ph\u1ea3i s\u1ed1 nguy\u00ean, FastAPI s\u1ebd t\u1ef1 \u0111\u1ed9ng tr\u1ea3 v\u1ec1 l\u1ed7i k\u00e8m th\u00f4ng b\u00e1o chi ti\u1ebft. </p> <p>Sau khi \u0111\u1ecbnh ngh\u0129a endpoint GET, b\u1ea1n c\u00f3 th\u1ec3 ch\u1ea1y \u1ee9ng d\u1ee5ng FastAPI b\u1eb1ng uvicorn gi\u1ed1ng nh\u01b0 tr\u01b0\u1edbc. Nh\u01b0 \u0111\u00e3 \u0111\u01b0\u1ee3c \u0111\u1ec1 c\u1eadp FastAPI t\u1ef1 \u0111\u1ed9ng sinh t\u00e0i li\u1ec7u API d\u1ea1ng t\u01b0\u01a1ng t\u00e1c v\u1edbi Swagger UI. C\u00f4ng c\u1ee5 n\u00e0y cho ph\u00e9p ki\u1ec3m th\u1eed endpoint API tr\u1ef1c ti\u1ebfp t\u1eeb tr\u00ecnh duy\u1ec7t m\u00e0 kh\u00f4ng c\u1ea7n vi\u1ebft th\u00eam code. B\u1ea1n c\u00f3 th\u1ec3 d\u1ec5 d\u00e0ng ki\u1ec3m tra ngay endpoint <code>/books/{book_id}</code> v\u1eeba t\u1ea1o trong \u0111\u00f3.</p> <p>S\u1eed d\u1ee5ng Swagger UI. Truy c\u1eadp [http://127.0.0.1.8000/docs], \u1edf \u0111\u00f3 endpoint <code>/books/{book_id}</code>. H\u00e3y click v\u00e0o ch\u00fang v\u00e0 th\u1eed nh\u1eadp m\u1ed9t <code>book_id</code> b\u1ea5t k\u00ec, r\u1ed3i ch\u1ea1y th\u1eed. B\u1ea1n s\u1ebd th\u1ea5y reponse API tr\u1ea3 v\u1ec1.</p> <p>S\u1eed d\u1ee5ng \u1ee9ng d\u1ee5ng Postman. Postman l\u00e0 m\u1ed9t API client cho ph\u00e9p x\u00e2y d\u1ef1ng, ki\u1ec3m th\u1eed t\u00e0i li\u1ec7u h\u00f3a API m\u1ed9t c\u00e1ch chi ti\u1ebft h\u01a1n. T\u1ea3i v\u00e0 c\u00e0i \u0111\u1eb7t Postman t\u1eeb [https://www.postman.com/downloads/]. Sau khi c\u00e0i \u0111\u1eb7t: (1) t\u1ea1o m\u1ed9t request m\u1edbi; (2) ch\u1ecdn method l\u00e0 GET; (3) \u0111\u1eb7t URL l\u00e0 endpoint FastAPI c\u1ee7a b\u1ea1n <code>http://127.0.0.1:8000/books/1</code>; (4) Nh\u1ea5n send v\u00e0 nh\u1eadn ph\u1ea3n h\u1ed3i t\u1eeb server FastAPI.</p>"},{"location":"knowledge-base/fastapi/lesson-01-overview/#path-parameters-and-query-parameters","title":"Path parameters and query parameters","text":"<p>M\u1ed9t trong nh\u1eefng kh\u00eda c\u1ea1nh quan tr\u1ecdng c\u1ee7a ph\u00e1t tri\u1ec3n API l\u00e0 x\u1eed l\u00fd paramters. Parameters cho ph\u00e9p API nh\u1eadn input t\u1eeb ng\u01b0\u1eddi d\u00f9ng, gi\u00fap endpoints tr\u1edf n\u00ean \u0111\u1ed9ng v\u00e0 linh ho\u1ea1t h\u01a1n. </p> <p>Path parameters. L\u00e0 nh\u1eefng ph\u1ea7n trong URL \u0111\u01b0\u1ee3c k\u1ef3 v\u1ecdng s\u1ebd thay \u0111\u1ed5i. \u1ede \u0111\u00e2y v\u1edbi endpoint <code>/authors/{author_id}</code>, th\u00ec <code>author_id</code> ch\u00ednh l\u00e0 m\u1ed9t parameter. FastAPI cho ph\u00e9p l\u1ea5y gi\u00e1 tr\u1ecb c\u1ee7a parameter n\u00e0y m\u1ed9t c\u00e1ch d\u1ec5 d\u00e0ng v\u00e0 s\u1eed d\u1ee5ng trong h\u00e0m c\u1ee7a m\u00ecnh. Gi\u00e1 tr\u1ecb <code>name</code> kh\u00f4ng thay \u0111\u1ed5i, nh\u01b0ng <code>author_id</code> s\u1ebd l\u00e0 gi\u00e1 tr\u1ecb \u0111\u01b0\u1ee3c truy\u1ec1n v\u00e0o t\u1eeb request.</p> <pre><code>@app.get(\"/authors/{author_id}\")\nasync def read_author(author_id: int):\n    return {\n        \"author_id\": author_id,\n        \"name\": \"Nguyen Thai Hoc\"\n    }\n</code></pre> <p>Query parameters. \u0110\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 tinh ch\u1ec9nh ho\u1eb7c t\u00f9y bi\u1ebfn ph\u1ea3n h\u1ed3i c\u1ee7a API, ch\u00fang \u0111\u01b0\u1ee3c th\u00eam v\u00e0o URL sau d\u1ea5u ?. V\u00ed d\u1ee5 <code>/books?genre=ai&amp;year=2025</code> c\u00f3 th\u1ec3 tr\u1ea3 v\u1ec1 danh s\u00e1ch nh\u1eefng s\u00e1ch ph\u00e1t h\u00e0nh n\u0103m 2025 v\u00e0 thu\u1ed9c th\u1ec3 lo\u1ea1i AI. </p> <pre><code>@app.get(\"/books\")\nasync def read_book(year: int=None):\n    if year:\n        return {\n            \"year\" : year,\n            \"books\" : [\"Deep Learning\", \"Computer Vision\"]\n        }\n\n    return {\"books\": [\"All Books\"]}\n</code></pre> <p>\u1ede \u0111\u00e2y, <code>year</code> l\u00e0 m\u1ed9t query parameter t\u00f9y ch\u1ecdn, khi g\u00e1n gi\u00e1 tr\u1ecb m\u1eb7c \u0111\u1ecbnh l\u00e0 <code>None</code> ch\u00fang tr\u1edf th\u00e0nh optional, n\u1ebfu ng\u01b0\u1eddi d\u00f9ng truy\u1ec1n <code>year</code> endpoint s\u1ebd tr\u1ea3 v\u1ec1 danh s\u00e1ch c\u1ee7a n\u0103m \u0111\u00f3, n\u00eau kh\u00f4ng ch\u00fang s\u1ebd tr\u1ea3 v\u1ec1 t\u1ea5t c\u1ea3 c\u00e1c s\u00e1ch.</p>"},{"location":"knowledge-base/fastapi/lesson-01-overview/#defining-request-and-respone-models","title":"Defining request and respone models","text":"<p>Pydantic models. Pydantic models l\u00e0 m\u1ed9t t\u00ednh n\u0103ng m\u1ea1nh m\u1ebd cho vi\u1ec7c x\u00e1c th\u1ef1c v\u00e0 chuy\u1ec3n \u0111\u1ed5i d\u1eef li\u1ec7u. Ch\u00fang cho ph\u00e9p b\u1ea1n \u0111\u1ecbnh ngh\u0129a c\u1ea5u tr\u00fac, ki\u1ec3u d\u1eef li\u1ec7u, v\u00e0 c\u00e1c r\u00e0ng bu\u1ed9c c\u1ee7a d\u1eef li\u1ec7u m\u00e0 \u1ee9ng d\u1ee5ng x\u1eed l\u00fd, c\u1ea3 cho request \u0111\u1ebfn v\u00e0 response \u0111i.</p> <p>T\u1ea1o models. T\u1ea1o m\u1ed9t class k\u1ebf th\u1eeba BaseModel c\u1ee7a Pydantic cho \u1ee9ng d\u1ee5ng c\u1ee7a b\u1ea1n trong file c\u00f3 t\u00ean l\u00e0 <code>models.py</code>.</p> <pre><code>from pydantic import BaseModel\n\nclass Book(BaseModel):\n    title: str\n    author: str\n    year: int\n</code></pre> <p>\u1ede \u0111\u00e2y, Book l\u00e0 m\u1ed9t class k\u1ebf th\u1eeba t\u1eeb Pydantic BaseModel v\u1edbi ba tr\u01b0\u1eddng: title, author v\u00e0 year. M\u1ed7i tr\u01b0\u1eddng \u0111\u01b0\u1ee3c khai b\u00e1o ki\u1ec3u d\u1eef li\u1ec7u ri\u00eang, \u0111\u1ea3m b\u1ea3o r\u1eb1ng b\u1ea5t k\u1ef3 d\u1eef li\u1ec7u n\u00e0o tu\u00e2n theo model n\u00e0y s\u1ebd c\u00f3 c\u00e1c thu\u1ed9c t\u00ednh v\u1edbi ki\u1ec3u d\u1eef li\u1ec7u \u0111\u00e3 \u0111\u01b0\u1ee3c ch\u1ec9 \u0111\u1ecbnh.</p> <p>Request body. Trong FastAPI, c\u00e1c Pydantic models kh\u00f4ng ch\u1ec9 \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 x\u00e1c th\u1ef1c m\u00e0 c\u00f2n \u0111\u00f3ng vai tr\u00f2 l\u00e0 request body.</p> <pre><code>from models import Book\n\n@app.post(\"/book\")\nasync def create_book(book: Book):\n    return book\n</code></pre> <p>Trong endpoint n\u00e0y, khi ng\u01b0\u1eddi d\u00f9ng g\u1eedi m\u1ed9t POST request \u0111\u1ebfn endpoint <code>/book</code> v\u1edbi d\u1eef li\u1ec7u JSON, FastAPI s\u1ebd t\u1ef1 \u0111\u1ed9ng ph\u00e2n t\u00edch v\u00e0 x\u00e1c th\u1ef1c d\u1ef1a tr\u00ean model Book. N\u1ebfu d\u1eef li\u1ec7u kh\u00f4ng h\u1ee3p l\u1ec7, ng\u01b0\u1eddi d\u00f9ng s\u1ebd nh\u1eadn \u0111\u01b0\u1ee3c m\u1ed9t ph\u1ea3n h\u1ed3i l\u1ed7i t\u1ef1 \u0111\u1ed9ng.</p> <p>X\u00e1c th\u1ef1c d\u1eef li\u1ec7u request. Pydantic c\u00f2n cung c\u1ea5p c\u00e1c t\u00ednh n\u0103ng x\u00e1c th\u1ef1c n\u00e2ng cao. V\u00ed d\u1ee5, c\u00f3 th\u1ec3 th\u00eam regex validation, gi\u00e1 tr\u1ecb m\u1eb7c \u0111\u1ecbnh...</p> <pre><code>from pydantic import BaseModel, Field\n\nclass Book(BaseModel):\n    title: str = Field(..., min_length=1, max_length=1000)\n    author: str = Field(..., min_length=1, max_length=1000)\n    year: int = Field(..., gt=1900, lt=2100)\n</code></pre> <p>B\u1ea1n c\u00f3 th\u1ec3 xem chi ti\u1ebft c\u00e1c t\u00ednh n\u0103ng x\u00e1c th\u1ef1c \u1edf t\u00e0i li\u1ec7u ch\u00ednh th\u1ee9c c\u1ee7a Pydantic [https://docs.pydantic.dev/latest/concepts/fields/]. </p> <p>Qu\u1ea3n l\u00fd response formats. FastAPI cho ph\u00e9p \u0111\u1ecbnh ngh\u0129a response models m\u1ed9t c\u00e1ch r\u00f5 r\u00e0ng, \u0111\u1ea3m b\u1ea3o d\u1eef li\u1ec7u \u0111\u01b0\u1ee3c tr\u1ea3 v\u1ec1 b\u1edfi API c\u1ee7a b\u1ea1n kh\u1edbp v\u1edbi m\u1ed9t schema c\u1ee5 th\u1ec3. \u0110i\u1ec1u n\u00e0y r\u1ea5t c\u1ea7n thi\u1ebft trong vi\u1ec7c lo\u1ea1i b\u1ecf d\u1eef li\u1ec7u nh\u1ea1y c\u1ea3m ho\u1eb7c t\u00e1i c\u1ea5u tr\u00fac response.</p> <pre><code>from pydantic import BaseModel\n\nclass BookResponse(BaseModel):\n    title: str\n    author: str\n\n@app.get(\"/allbooks\")\nasync def read_all_books() -&gt; list[BookResponse]:\n    return [\n        {\"id\": 1, \"title\": \"Machine Learning\", \"author\": \"Chip Huyen\"},\n        {\"Id\": 2, \"title\": \"Computer Vision\", \"author\": \"Kaparthy\"}\n    ]\n</code></pre> <p>Ph\u1ea7n <code>-&gt; list[BookReponse]</code> trong khai b\u00e1o ki\u1ec3u tr\u1ea3 v\u1ec1 c\u1ee7a h\u00e0m cho FastAPI bi\u1ebft r\u1eb1ng ph\u1ea3i s\u1eed d\u1ee5ng model BookReponse cho response, \u0111\u1ea3m b\u1ea3o ch\u1ec9 c\u00f3 c\u00e1c tr\u01b0\u1eddng title v\u00e0 author \u0111\u01b0\u1ee3c \u0111\u01b0a v\u00e0o JSON tr\u1ea3 v\u1ec1.</p> <p>Ngo\u00e0i ra, b\u1ea1n c\u00f3 th\u1ec3 ch\u1ec9 \u0111\u1ecbnh response tr\u1ef1c ti\u1ebfp trong decorator c\u1ee7a endpoint nh\u01b0 sau:</p> <pre><code>@app.get(\"/allbooks\", response_model=list[BookResponse])\nasync def read_all_books() -&gt; Any:\n    return [\n        {\"id\": 1, \"title\": \"Machine Learning\", \"author\": \"Chip Huyen\"},\n        {\"Id\": 2, \"title\": \"Computer Vision\", \"author\": \"Kaparthy\"}\n    ]\n</code></pre>"},{"location":"knowledge-base/fastapi/lesson-01-overview/#handling-errors-and-exceptions","title":"Handling errors and exceptions","text":"<p>FastAPI cung c\u1ea5p v\u00e0 h\u1ed7 tr\u1ee3 cho vi\u1ec7c x\u1eed l\u00fd ngo\u1ea1i l\u1ec7 v\u00e0 l\u1ed7i. Khi m\u1ed9t l\u1ed7i x\u1ea3y ra, FastAPI tr\u1ea3 v\u1ec1 m\u1ed9t ph\u1ea3n h\u1ed3i JSON ch\u1ee9a chi ti\u1ebft v\u1ec1 l\u1ed7i, \u0111i\u1ec1u n\u00e0y r\u1ea5t h\u1eefu \u00edch cho vi\u1ec7c g\u1ee1 l\u1ed7i. Tuy nhi\u00ean, c\u00f3 nh\u1eefng t\u00ecnh hu\u1ed1ng b\u1ea1n c\u00f3 th\u1ec3 mu\u1ed1n t\u00f9y ch\u1ec9nh c\u00e1c ph\u1ea3n h\u1ed3i l\u1ed7i n\u00e0y \u0111\u1ec3 mang l\u1ea1i tr\u1ea3i nghi\u1ec7m ng\u01b0\u1eddi d\u00f9ng t\u1ed1t h\u01a1n ho\u1eb7c \u0111\u1ea3m b\u1ea3o b\u1ea3o m\u1eadt.</p> <pre><code>from fastapi import FastAPI, HTTPException\nfrom starlette.responses import JSONResponse\n\n@app.exception_handler(HTTPException)\nasync def http_exception_handler(request, exc):\n    return JSONResponse(\n        status_code=exc.status_code,\n        content={\n            \"message\": \"OOPs ! Something went wrong\"\n        }\n    )\n</code></pre> <p>Trong v\u00ed d\u1ee5 n\u00e0y, h\u00e0m <code>http_exception_handler</code> s\u1ebd \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 x\u1eed l\u00fd c\u00e1c l\u1ed7i <code>HTTPException</code>. B\u1ea5t c\u1ee9 khi n\u00e0o m\u1ed9t l\u1ed7i <code>HTTPException</code> \u0111\u01b0\u1ee3c raise \u1edf b\u1ea5t k\u1ef3 \u0111\u00e2u trong \u1ee9ng d\u1ee5ng c\u1ee7a b\u1ea1n, FastAPI s\u1ebd d\u00f9ng b\u1ed9 x\u1eed l\u00fd n\u00e0y \u0111\u1ec3 tr\u1ea3 v\u1ec1 m\u1ed9t ph\u1ea3n h\u1ed3i t\u00f9y ch\u1ec9nh.</p> <pre><code>@app.get(\"/error_endpoint\")\nasync def raise_exception():\n    raise HTTPException(status_code=400)\n</code></pre> <p>Endpoint n\u00e0y s\u1ebd n\u00e9m ra ph\u1ea3n h\u1ed3i l\u1ed7i HTTP \u0111\u1ec3 minh h\u1ecda th\u00f4ng b\u00e1o \u0111\u00e3 \u0111\u01b0\u1ee3c t\u00f9y ch\u1ec9nh \u1edf b\u01b0\u1edbc tr\u01b0\u1edbc \u0111\u00f3.</p> <p>Nh\u01b0 \u0111\u00e3 th\u1ea3o lu\u1eadn trong ph\u1ea7n Pydantic, FastAPI s\u1eed d\u1ee5ng cac model c\u1ee7a Pydantic \u0111\u1ec3 x\u00e1c th\u1ef1c d\u1eef li\u1ec7u. Khi m\u1ed9t request \u0111\u01b0\u01a1c g\u1eedi v\u1edbi d\u1eef li\u1ec7u kh\u00f4ng tu\u00e2n theo model \u0111\u00e3 \u0111\u1ecbnh ngh\u0129a, FastAPI s\u1ebd raise m\u1ed9t ngo\u1ea1i l\u1ec7 v\u00e0 tr\u1ea3 v\u1ec1 ph\u1ea3n h\u1ed3i l\u1ed7i. Trong m\u1ed9t s\u1ed1 tr\u01b0\u1eddng h\u1ee3p, b\u1ea1n c\u00f3 th\u1ec3 mu\u1ed1n t\u00f9y ch\u1ec9nh ph\u1ea3n h\u1ed3i cho c\u00e1c l\u1ed7i x\u00e1c th\u1ef1c.</p> <pre><code>import json\nfrom fastapi import FastAPI, HTTPException, Request, status\nfrom fastapi.exceptions import ResponseValidationError\nfrom fastapi.responses import PlainTextResponse\n\n@app.exception_handler(ResponseValidationError)\nasync def validation_exception_handler(\n    request: Request,\n    exc: ResponseValidationError\n):\n    return PlainTextResponse(\n        \"This is a plain text response:\"\n        f\"\\n{json.dumps(exc.errors(), indent=2)}\",\n        status_code=status.HTTP_400_BAD_REQUEST\n    )\n</code></pre> <p>B\u1ed9 x\u1eed l\u00fd t\u00f9y ch\u1ec9nh n\u00e0y s\u1ebd b\u1eaft b\u1ea5t k\u1ef3 l\u1ed7i RequestValidationError n\u00e0o v\u00e0 tr\u1ea3 v\u1ec1 m\u1ed9t ph\u1ea3n h\u1ed3i chi ti\u1ebft c\u1ee7a l\u1ed7i. Gi\u1ea3 s\u1eed b\u1ea1n th\u1eed g\u1ecdi endpoint <code>POST /book</code> v\u1edbi gi\u00e1 tr\u1ecb title l\u00e0 m\u1ed9t s\u1ed1 thay v\u00ec m\u1ed9t chu\u1ed7i, b\u1ea1n s\u1ebd nh\u1eadn \u0111\u01b0\u1ee3c ph\u1ea3n h\u1ed3i v\u1edbi m\u00e3 l\u1ed7i tr\u1ea1ng th\u00e1i 422.</p> <pre><code>@app.post(\"/book\")\nasync def create_book(book: Book):\n    return ({\n        \"message\": \"Book created successfully !\",\n        \"data\": book\n    })\n</code></pre>"},{"location":"knowledge-base/mlops/","title":"\ud83e\uded2 MLOps Tutorials: Fundamentals &amp; Practices","text":""},{"location":"knowledge-base/mlops/#i-nguyen-ly-nen-tang-cua-mot-quy-trinh-mlops","title":"I. Nguy\u00ean l\u00fd n\u1ec1n t\u1ea3ng c\u1ee7a m\u1ed9t quy tr\u00ecnh MLOps","text":""},{"location":"knowledge-base/mlops/#1-su-phat-trien-cua-ha-tang-va-phat-trien-pham-mem","title":"1. S\u1ef1 ph\u00e1t tri\u1ec3n c\u1ee7a h\u1ea1 t\u1ea7ng v\u00e0 ph\u00e1t tri\u1ec3n ph\u1ea7m m\u1ec1m","text":"<p>S\u1ef1 ra \u0111\u1eddi c\u1ee7a k\u1ef7 nguy\u00ean internet hi\u1ec7n \u0111\u1ea1i (kho\u1ea3ng n\u0103m 1995), \u0111\u00e3 ch\u1ee9ng ki\u1ebfn s\u1ef1 gia t\u0103ng c\u1ee7a c\u00e1c \u1ee9ng d\u1ee5ng ph\u1ea7n m\u1ec1m, t\u1eeb c\u00e1c h\u1ec7 \u0111i\u1ec1u h\u00e0nh nh\u01b0 Windows 95, Linux cho \u0111\u1ebfn c\u00e1c website nh\u01b0 Google v\u00e0 Amazon, \u0111\u00e2y l\u00e0 nh\u1eefng n\u1ec1n t\u1ea3ng tr\u1ef1c tuy\u1ebfn \u0111\u00e3 ph\u1ee5c v\u1ee5 to\u00e0n c\u1ea7u trong h\u01a1n hai th\u1eadp k\u1ef7. \u0110i\u1ec1u n\u00e0y \u0111\u00e3 v\u00f4 t\u00ecnh t\u1ea1o ra m\u1ed9t v\u0103n h\u00f3a c\u1ea3i ti\u1ebfn d\u1ecbch v\u1ee5 li\u00ean t\u1ee5c b\u1eb1ng c\u00e1ch thu th\u1eadp, l\u01b0u tr\u1eef v\u00e0 x\u1eed l\u00fd l\u01b0\u1ee3ng d\u1eef kh\u1ed5ng l\u1ed3 t\u1eeb t\u01b0\u01a1ng t\u00e1c c\u1ee7a ng\u01b0\u1eddi d\u00f9ng chung. Nh\u1eefng s\u1ef1 ph\u00e1t tri\u1ec3n n\u00e0y \u0111\u00e3 \u0111\u1ecbnh h\u00ecnh s\u1ef1 ti\u1ebfn h\u00f3a c\u1ee7a h\u1ea1 t\u1ea7ng CNTT v\u00e0 ph\u00e1t tri\u1ec3n ph\u1ea7n m\u1ec1m.</p> <p>C\u00e1c doanh nghi\u1ec7p ng\u00e0y c\u00e0ng \u00e1p d\u1ee5ng \u0111i\u1ec7n to\u00e1n \u0111\u00e1m m\u00e2y (cloud computing), v\u00ec ch\u00fang m\u1edf ra kh\u1ea3 n\u0103ng thu\u00ea ngo\u00e0i vi\u1ec7c b\u1ea3o tr\u00ec h\u1ea1 t\u1ea7ng CNTT, \u0111\u1ed3ng th\u1eddi cung c\u1ea5p c\u00e1c t\u00e0i nguy\u00ean c\u1ea7n thi\u1ebft nh\u01b0 l\u01b0u tr\u1eef v\u00e0 t\u00ednh t\u00f3an \u0111\u1ec3 v\u1eadn h\u00e0nh v\u00e0 m\u1edf r\u1ed9ng ho\u1ea1t \u0111\u1ed9ng. \u0110i\u1ec7n to\u00e1n \u0111\u00e1m m\u00e2y mang l\u1ea1i kh\u1ea3 n\u0103ng cung c\u1ea5p theo nhu c\u1ea7u v\u00e0 s\u1eb5n s\u00e0ng c\u00e1c t\u00e0i nguy\u00ean CNTT m\u00e0 kh\u00f4ng c\u1ea7n ng\u01b0\u1eddi d\u00f9ng tr\u1ef1c ti\u1ebfp qu\u1ea3n l\u00fd. V\u00ed d\u1ee5: c\u00e1c c\u00f4ng ty c\u00f3 th\u1ec3 thu\u00ea n\u0103ng l\u1ef1c t\u00ednh to\u00e1n v\u00e0 l\u01b0u tr\u1eef m\u00e0 kh\u00f4ng ph\u1ea3i ch\u1ecbu tr\u00e1ch nhi\u1ec7m duy tr\u00ec - vi\u1ec7c n\u00e0y \u0111\u01b0\u1ee3c giao cho nh\u00e0 cung c\u1ea5p d\u1ecbch v\u1ee5. Nh\u1edd \u0111\u00f3, doanh nghi\u1ec7p \u0111\u00e3 ti\u1ebft ki\u1ec7m \u0111\u01b0\u1ee3c chi ph\u00ed, gi\u1ea3m nhu c\u1ea7u \u0111\u1ed9i ng\u0169 k\u1ef9 thu\u1eadt IT v\u00e0 c\u00f3 th\u1ec3 t\u1ed1i \u01b0u h\u00f3a ngu\u1ed3n l\u1ef1c. \u0110i\u1ec7n to\u00e1n \u0111\u00e1m m\u00e2y c\u0169ng cho ph\u00e9p m\u1edf r\u1ed9ng v\u00e0 thanh to\u00e1n d\u1ef1a tr\u00ean m\u1ee9c s\u1eed d\u1ee5ng th\u1ef1c t\u1ebf khi c\u1ea7n.</p> <p>Trong th\u1eadp k\u1ef7 qua, nhi\u1ec1u c\u00f4ng ty l\u1edbn nh\u01b0 Google, IBM, Microsoft \u0111\u00e3 \u0111\u1ea7u t\u01b0 m\u1ea1nh v\u00e0o nghi\u00ean c\u1ee9u v\u00e0 ph\u00e1t tri\u1ec3n d\u1ecbch v\u1ee5 \u0111\u00e1m m\u00e2y. \u0110i\u1ec1u n\u00e0y \u0111\u00e3 d\u1eabn \u0111\u1ebfn s\u1ef1 chuy\u1ec3n d\u1ecbch t\u1eeb m\u00e1y ch\u1ee7 c\u1ee5c b\u1ed9 (localized computing) sang \u0111i\u1ec7n to\u00e1n theo nhu c\u1ea7u (on-demand computing).</p>"},{"location":"knowledge-base/mlops/#2-su-phat-trien-cua-machine-learning-va-deep-learning","title":"2. S\u1ef1 ph\u00e1t tri\u1ec3n c\u1ee7a Machine Learning v\u00e0 Deep Learning","text":"<p>Trong su\u1ed1t th\u1eadp k\u1ef7 qua, ch\u00fang ta \u0111\u00e3 ch\u1ee9ng ki\u1ebfn c\u00e1c \u1ee9ng d\u1ee5ng Machine Leanring (ML) \u0111\u00e3 len l\u1ecfi v\u00e0o nhi\u1ec1u l\u0129nh v\u1ef1c trong \u0111\u1eddi s\u1ed1ng h\u00e0ng ng\u00e0y. T\u1eeb d\u1ecbch m\u00e1y (machine translation), x\u1eed l\u00fd h\u00ecnh \u1ea3nh (image processing) cho \u0111\u1ebfn nh\u1eadn d\u1ea1ng gi\u1ecdng n\u00f3i (voice recognition). Nh\u1eefng \u1ee9ng d\u1ee5ng n\u00e0y \u0111\u01b0\u1ee3c th\u00fac \u0111\u1ea9y b\u1edfi s\u1ef1 ph\u00e1t tri\u1ec3n c\u1ee7a h\u1ea1 t\u1ea7ng t\u00ednh to\u00e1n, \u0111\u1eb7c bi\u1ec7t l\u00e0 khai th\u00e1c s\u1ee9c m\u1ea1nh x\u1eed l\u00fd (computation power), m\u1edf ra ti\u1ec1m n\u0103ng to l\u1edbn cho Deep Learning (DL) v\u00e0 ML.</p> <p>Nh\u1eefng b\u01b0\u1edbc \u0111\u1ed9t ph\u00e1 trong DL c\u00f3 m\u1ed1i t\u01b0\u01a1ng quan ch\u1eb7t ch\u1ebd v\u1edbi s\u1ef1 gia t\u0103ng c\u1ee7a n\u0103ng l\u1ef1c t\u00ednh to\u00e1n. Nh\u1eefng \u0111\u1ed9t ph\u00e1 n\u00e0y \u0111\u01b0\u1ee3c h\u1ed7 tr\u1ee3 b\u1edfi s\u1ef1 t\u0103ng tr\u01b0\u1edfng theo c\u00e2p s\u1ed1 nh\u00e2n c\u1ee7a s\u1ee9c m\u1ea1nh t\u00ednh to\u00e1n, v\u1edbi m\u1ee9c t\u0103ng kho\u1ea3ng 35 l\u00e2n m\u1ed7i 18 th\u00e1ng. Tuy nhi\u00ean, trong t\u01b0\u01a1ng l\u1ea1i, v\u1edbi nhu c\u1ea7u ng\u00e0y c\u00e0ng l\u1edbn, vi\u1ec7c g\u1eb7p ph\u1ea3i gi\u1edbi h\u1ea1n khi m\u1edf r\u1ed9ng kh\u1ea3 n\u0103ng t\u00ednh to\u00e1n trung t\u00e2m d\u1ef1a tr\u00ean CPU, GPU ho\u1eb7c TPU l\u00e0 \u0111i\u1ec1u kh\u00f4ng th\u1ec3 tr\u00e1nh kh\u1ecfi. \u0110i\u1ec1u n\u00e0y \u0111\u00e3 bu\u1ed9c ph\u1ea3i xem x\u00e9t c\u00e1c gi\u1ea3i ph\u00e1p thay th\u1ebf, ch\u1eb3ng h\u1ea1n nh\u01b0:</p> <ul> <li>Distributed learning (h\u1ecdc ph\u00e2n t\u00e1n): x\u1eed l\u00fd d\u1eef li\u1ec7u \u0111\u01b0\u1ee3c ph\u00e2n b\u1ed5 tr\u00ean nhi\u1ec1u n\u00fat t\u00ednh to\u00e1n.</li> <li>Federated learning (h\u1ecdc li\u00ean k\u1ebft): h\u1ecdc li\u00ean k\u1ebft, d\u1eef li\u1ec7u v\u1eabn \u1edf thi\u1ebft b\u1ecb ng\u01b0\u1eddi d\u00f9ng, ch\u1ec9 m\u00f4 h\u00ecnh \u0111\u01b0\u1ee3c hu\u1ea5n luy\u1ec7n chung.</li> <li>Edge computing: x\u1eed l\u00fd d\u1eef li\u1ec7u ngay t\u1ea1i thi\u1ebft b\u1ecb bi\u00ean (smartphone, IoT) thay v\u00ec g\u1eedi to\u00e1n b\u1ed9 l\u00ean trung t\u00e2m d\u1eef li\u1ec7u.</li> </ul> <p>To\u00e0n b\u1ed9 c\u00e1c ph\u01b0\u01a1ng ph\u00e1p h\u1ecdc ph\u00e2n t\u00e1n \u0111\u00e3 cho th\u1ea5y \u0111\u01b0\u1ee3c ti\u1ec1m n\u0103ng v\u00e0 mang l\u1ea1i nhi\u1ec1u s\u1ef1 h\u1ee9a h\u1eb9n \u0111\u1ec3 \u0111\u00e1p \u1ee9ng nhu c\u1ea7u ng\u00e0y c\u00e0ng t\u0103ng c\u1ee7a DL.</p>"},{"location":"knowledge-base/mlops/#3-ung-dung-lay-ai-lam-trung-tam","title":"3. \u1ee8ng d\u1ee5ng l\u1ea5y AI l\u00e0m trung t\u00e2m","text":"<p>C\u00e1c \u1ee9ng d\u1ee5ng ng\u00e0y c\u00e0ng tr\u1edf n\u00ean AI-centric, \u0111i\u1ec1u n\u00e0y di\u1ec5n ra \u1edf nhi\u1ec1u ngh\u00e0nh c\u00f4ng nghi\u1ec7p. H\u1ea7u nh\u01b0 m\u1ecdi \u1ee9ng d\u1ee5ng hi\u1ec7n nay \u0111\u1ec1u t\u00edch h\u1ee3p AI, v\u00e0 ch\u00fang th\u01b0\u1eddng ch\u1ea1y t\u00e1ch bi\u1ec7t tr\u00ean c\u00e1c t\u1ea3i c\u00f4ng vi\u1ec7c ph\u00e2n t\u00e1n (distributed workloads) nh\u01b0 HPC (High-Performance Computing), Microservices v\u00e0 Big Data. B\u1eb1ng c\u00e1ch k\u1ebft h\u1ee3p HPC v\u00e0 AI, ta c\u00f3 \u0111\u01b0\u1ee3c kh\u1ea3 n\u0103ng t\u00ednh to\u00e1n m\u1ea1nh m\u1ebd c\u1ea7n thi\u1ebft \u0111\u1ec3 hu\u1ea5n luy\u1ec7n c\u00e1c m\u00f4 h\u00ecnh DL v\u00e0 ML. V\u01a1i s\u1ef1 giao thoa c\u1ee7a Big Data v\u00e0 AI, ta c\u00f3 th\u1ec3 khai th\u00e1c d\u1eef li\u1ec7u \u1edf quy m\u00f4 l\u1edbn \u0111\u1ec3 hu\u1ea5n luy\u1ec7n m\u00f4 h\u00ecnh AI. V\u1edbi s\u1ef1 giao thoa c\u1ee7a Microservices v\u00e0 AI, ta c\u00f3 th\u1ec3 tri\u1ec3n khai m\u00f4 h\u00ecnh AI ph\u1ee5c v\u1ee5 suy lu\u1eadn (inference) t\u0103ng c\u01b0\u1eddng ho\u1ea1t \u0111\u1ed9ng kinh doanh v\u00e0 t\u1ea1o ra c\u00e1c t\u00e1c \u0111\u1ed9ng th\u1ef1c ti\u1ec5n. Ch\u00ednh v\u00ec v\u1eady, c\u00e1c \u1ee9ng d\u1ee5ng ph\u00e2n t\u00e1n \u0111\u00e3 tr\u1edf th\u00e0nh m\u1ed9t chu\u1ea9n m\u1ef1c m\u1edbi (new norm).</p> <p>\u0110\u1ec3 ph\u00e1t tri\u1ec3n \u1ee9ng d\u1ee5ng AI-centric \u1edf quy m\u00f4 l\u1edbn, c\u1ea7n c\u00f3 s\u1ef1 c\u1ed9ng h\u01b0\u1edfng c\u1ee7a c\u00e1c \u1ee9ng d\u1ee5ng ph\u00e2n t\u00e1n. V\u00e0 \u0111\u1ec3 \u0111\u1ea1t \u0111\u01b0\u1ee3c \u0111i\u00eau n\u00e0y, c\u1ea7n m\u1ed9t c\u00e1ch ph\u00e1t tri\u1ec3n ph\u1ea7n m\u1ec1m m\u1edbi.</p>"},{"location":"knowledge-base/mlops/#4-su-tien-hoa-trong-phat-trien-pham-mem","title":"4. S\u1ef1 ti\u1ebfn h\u00f3a trong ph\u00e1t tri\u1ec3n ph\u1ea7m m\u1ec1m","text":"<p>Ph\u00e1t tri\u1ec3n ph\u1ea7m m\u1ec1m \u0111\u00e3 ti\u1ebfn h\u00f3a song h\u00e0nh v\u1edbi s\u1ef1 ph\u00e1t tri\u1ec3n c\u1ee7a h\u1ea1 t\u1ea7ng CNTT nh\u1eb1m h\u1ed7 tr\u1ee3 vi\u1ec7c ph\u00e1t tri\u1ec3n \u1ee9ng d\u1ee5ng m\u1ed9t c\u00e1ch hi\u1ec7u qu\u1ea3. M\u00f4 h\u00ecnh th\u00e1c n\u01b0\u1edbc (Waterfall method) l\u00e0 m\u1ed9t ph\u01b0\u01a1ng ph\u00e1p truy\u1ec1n th\u1ed1ng, trong \u0111\u00f3 qu\u00e1 tr\u00ecnh ph\u00e1t tri\u1ec3n di\u1ec5n ra theo tuy\u1ebfn t\u00ednh: thu th\u1eadp y\u00eau c\u1ea7u, thi\u1ebft k\u1ebf v\u00e0 ph\u00e1t tri\u1ec3n. Tuy nhi\u00ean, ph\u01b0\u01a1ng ph\u00e1p n\u00e0y c\u00f3 nhi\u1ec1u h\u1ea1n ch\u1ebf, d\u1eabn \u0111\u1ebfn s\u1ef1 xu\u1ea5t hi\u1ec7n c\u1ee7a c\u00e1c ph\u01b0\u01a1ng ph\u00e1p m\u1edbi nh\u01b0 Agile v\u00e0 DevOps.</p> <p>M\u00f4 h\u00ecnh Waterfall \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng r\u1ed9ng r\u00e3i t\u1eeb khi b\u1eaft \u0111\u1ea7u k\u1ef7 nguy\u00ean internet. \u0110\u00e2y l\u00e0 m\u1ed9t cach ph\u00e1t tri\u1ec3n kh\u00f4ng l\u1eb7p l\u1ea1i (non-iterative), th\u1ef1c hi\u1ec7n theo chi\u00eau \u0111\u01a1n h\u01b0\u1edbng (unidirectional). M\u1ed7i giai \u0111o\u1ea1n \u0111\u01b0\u1ee3c x\u00e1c \u0111\u1ecbnh s\u1eb5n v\u00e0 th\u1ef1c hi\u1ec7n tu\u1ea7n t\u1ef1. M\u00f4 h\u00ecnh n\u00e0y th\u00edch h\u1ee3p khi y\u00eau c\u1ea9u \u0111\u01b0\u1ee3c x\u00e1c \u0111\u1ecbnh r\u00f5 r\u00e0ng, c\u1ee5 th\u1ec3 v\u00e0 kh\u00f4ng thay \u0111\u1ed5i theo th\u1eddi gian. Ng\u01b0\u1ee3c l\u1ea1i, kh\u00f4ng ph\u00f9 h\u1ee3p v\u1edbi c\u00e1c d\u1ef1 d\u00e1n \u0111\u1ed9ng - n\u01a1i y\u00eau c\u1ea7u th\u01b0\u1eddng xuy\u00ean thay \u0111\u1ed5i theo nhu c\u00e2u ng\u01b0\u1eddi d\u00f9ng.</p> <p>Nh\u00ecn chung, m\u00f4 h\u00ecnh Waterfall t\u1ed3n t\u1ea1i nh\u1eefng nh\u01b0\u1ee3c \u0111i\u1ec3m ch\u00ednh nh\u01b0:</p> <ul> <li>To\u00e0n b\u1ed9 y\u00eau c\u1ea7u ph\u1ea3i \u0111\u01b0\u1ee3c x\u00e1c \u0111\u1ecbnh ngay t\u1eeb \u0111\u1ea7u, kh\u00f4ng th\u1ec3 thay \u0111\u1ed5i trong qu\u00e1 tr\u00ecnh ho\u1eb7c sau khi ph\u00e1t tri\u1ec3n.</li> <li>Kh\u00f3 t\u1ea1o ra ho\u1eb7c t\u00e1i s\u1eed d\u1ee5ng c\u00e1c th\u00e0nh ph\u1ea7n ph\u1ea7n m\u1ec1m.</li> <li>Ki\u1ec3m th\u1eed ch\u1ec9 di\u1ec5n ra sau khi ph\u00e1t tri\u1ec3n xong, kh\u00f4ng th\u1ec3 l\u1eb7p l\u1ea1i, v\u00e0 kh\u00f4ng d\u1ec5 s\u1eeda l\u1ed7i khi \u0111\u00e3 ho\u00e0n t\u1ea5t.</li> <li>Vi\u1ec7c ki\u1ec3m th\u1eed ch\u1ea5p nh\u1eadn c\u1ee7a kh\u00e1ch h\u00e0ng th\u01b0\u1eddng d\u1ea5n \u0111\u1ebfn thay \u0111\u1ed5i, g\u00e2y ch\u1eadm tr\u1ec5 v\u00e0 chi ph\u00ed cao.</li> <li>H\u1ec7 th\u1ed1ng th\u01b0\u1eddng \u0111\u01b0\u1ee3c x\u00e2y d\u1ef1ng theo c\u00e1ch hi\u1ec3u c\u1ee7a l\u1eadp tr\u00ecnh vi\u00ean, kh\u00f4ng ph\u1ea3i l\u00e0 t\u1eeb g\u00f3c nh\u00ecn ng\u01b0\u1eddi d\u00f9ng, d\u1eabn \u0111\u1ebfn s\u1ea3n ph\u1ea9m kh\u00f4ng \u0111\u00e1p \u1ee9ng nhu c\u1ea7u th\u1ef1c t\u1ebf.</li> </ul> <p>Ph\u01b0\u01a1ng ph\u00e1p Agile kh\u1eafc ph\u1ee5c nh\u1eefng h\u1ea1n ch\u1ebf c\u1ee7a Waterfall v\u1edbi \u01b0u th\u1ebf t\u1ea1o \u0111i\u1ec1u ki\u1ec7n cho m\u1ed9t c\u00e1ch ti\u1ebfp c\u1eadn l\u1eb7p l\u1ea1i (iterative) v\u00e0 ti\u1ebfn b\u1ed9 trong ph\u00e1t tri\u1ec3n ph\u1ea7n m\u00e8m. kh\u00e1c v\u1edbi Waterfall, Agile l\u1ea5y ng\u01b0\u1eddi d\u00f9ng l\u00e0m trung t\u00e2m. Ph\u01b0\u01a1ng ph\u00e1p n\u00e0y mang t\u00ednh hai chi\u1ec1u (bidirectional) v\u00e0 th\u01b0\u1eddng c\u00f3 s\u1ef1 tham gia tr\u1ef1c ti\u1ebfp c\u1ee7a ng\u01b0\u1eddi d\u00f9ng ho\u1eb7c kh\u00e1ch h\u00e0ng trong qu\u00e1 tr\u00ecnh ph\u00e1t tri\u1ec3n v\u00e0 ki\u1ec3m th\u1eed. Nh\u1edd \u0111\u00f3, c\u00f3 c\u01a1 h\u1ed9i \u0111\u1ec3 ki\u1ec3m tra, ph\u1ea3n h\u1ed3i, v\u00e0 \u0111\u1ec1 xu\u1ea5t c\u1ea3i ti\u1ebfn xuy\u00ean su\u1ed1t c\u00e1c giai \u0111o\u1ea1n c\u1ee7a d\u1ef1 \u00e1n.</p> <p>M\u1ed9t s\u1ed1 \u01b0u \u0111i\u1ec3m c\u1ee7a Agile:</p> <ul> <li>Y\u00eau c\u1ea7u \u0111\u01b0\u1ee3c x\u00e1c \u0111\u1ecbnh tr\u01b0\u1edbc khi b\u1eaft \u0111\u1ea7u ph\u00e1t tri\u1ec3n \u1ee9ng d\u1ee5ng, nh\u01b0ng c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c thay \u0111\u1ed5i b\u1ea5t c\u1ee9 l\u1ee9c n\u00e0o.</li> <li>C\u00f3 th\u1ec3 t\u1ea1o ho\u1eb7c tri\u1ec3n khai c\u00e1c th\u00e0nh ph\u1ea7n t\u00e1i s\u1eed d\u1ee5ng.</li> <li>Gi\u1ea3i ph\u00e1p c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c chia th\u00e0nh nhi\u1ec1u module nh\u1ecf, \u0111\u01b0\u1ee3c x\u1eed l\u00fd v\u00e0 b\u00e0n giao \u0111\u1ecbnh k\u1ef3.</li> <li>Ng\u01b0\u1eddi d\u00f9ng ho\u1eb7c kh\u00e1ch h\u00e0ng c\u00f3 th\u1ec3 \u0111\u1ed3ng s\u00e1ng t\u1ea1o b\u1eb1ng c\u00e1ch ki\u1ec3m th\u1eed v\u00e0 \u0111\u00e1nh gi\u00e1 c\u00e1c module \u0111\u00e3 ph\u00e1t tri\u1ec3n theo t\u1eebng giai \u0111o\u1ea1n, \u0111\u1ea3m b\u1ea3o r\u1eb1ng nhu c\u1ea7u th\u1ef1c t\u1ebf \u0111\u01b0\u1ee3c \u0111\u00e1p \u1ee9ng.</li> </ul> <p>Ph\u01b0\u01a1ng ph\u00e1p DevOps m\u1edf r\u1ed9ng c\u00e1c th\u1ef1c ti\u1ec5n c\u1ee7a Agile b\u1eb1ng c\u00e1ch tinh g\u1ecdn h\u01a1n n\u1eefa qu\u00e1 tr\u00ecnh thay \u0111\u1ed5i ph\u1ea7n m\u1ec1m qua c\u00e1c giai \u0111o\u1ea1n: x\u00e2y d\u1ef1ng (build), ki\u1ec3m th\u1eed (test), tri\u1ec3n khai (deploy) v\u00e0 b\u00e0n giao (delivery). DevOps trao quy\u1ec1n cho c\u00e1c nh\u00f3m \u0111a ch\u1ee9c n\u0103ng quy\u1ec1n t\u1ef1 ch\u1ee7 trong vi\u1ec7c th\u1ef1c thi \u1ee9ng d\u1ee5ng ph\u1ea7n m\u1ec1m, d\u1ef1a tr\u00ean c\u00e1c c\u01a1 ch\u1ebf: CI (Continuous Integration - T\u00edch h\u1ee3p li\u00ean t\u1ee5c), CD (Continous Deployment - Tri\u1ec3n khai li\u00ean t\u1ee5c) v\u00e0 CD (Continous Delivery - B\u00e0n giao li\u00ean t\u1ee5c).</p> <p>Ph\u01b0\u01a1ng ph\u00e1p n\u00e0y khuy\u1ebfn kh\u00edch s\u1ef1 h\u1ee3p t\u00e1c, t\u00edch h\u1ee3p v\u00e0 t\u1ef1 \u0111\u1ed9ng h\u00f3a gi\u1eefa l\u1eadp tr\u00ecnh vi\u00ean v\u00e0 nh\u00e2n vi\u1ec7n v\u1eadn h\u00e0nh IT, n\u0103ng cao hi\u1ec7u qu\u1ea3, t\u1ed1c \u0111\u1ed9 v\u00e0 ch\u00e2t l\u01b0\u1ee3ng trong vi\u1ec7c cung c\u1ea5p ph\u1ea7m m\u1ec1m h\u01b0\u1edbng t\u1edbi ng\u01b0\u1eddi d\u00f9ng. DevOps cung c\u1ea5p m\u1ed9t khung ph\u00e1t tri\u1ec3n ph\u1ea7m m\u1ec1m tinh g\u1ecdn cho vi\u1ec7c thi\u1ebft k\u1ebf, ki\u1ec3m th\u1eed, tri\u1ec3n khai v\u00e0 gi\u00e1m s\u00e1t h\u1ec7 th\u1ed1ng trong m\u00f4i tr\u01b0\u1eddng production.</p>"},{"location":"knowledge-base/mlops/#5-thach-thuc-cua-viec-phat-trien-pham-mem-truyen-thong","title":"5. Th\u00e1ch th\u1ee9c c\u1ee7a vi\u1ec7c ph\u00e1t tri\u1ec3n ph\u1ea7m m\u1ec1m truy\u1ec1n th\u1ed1ng","text":"<p>M\u1eb7c d\u00f9 DevOps \u0111\u00e3 gi\u00fap doanh nghi\u1ec7p tri\u1ec3n khai ph\u1ea7n m\u1ec1m m\u1ed9t c\u00e1ch nhanh ch\u00f3ng v\u00e0 tin c\u1eady, cho ph\u00e9p \u0111\u01b0a ph\u1ea7n m\u1ec1m v\u00e0o production ch\u1ec9 trong v\u00e0i ph\u00fat v\u00e0 v\u1eabn gi\u0169 cho h\u1ec7 th\u1ed1ng ho\u1ea1t \u0111\u1ed9ng oonrn \u0111\u1ecbnh. Tuy nhi\u00ean, ch\u00fang kh\u00f4ng th\u1ec3 \u00e1p d\u1ee5ng y nguy\u00ean cho \u1ee9ng d\u1ee5ng ML v\u00e0 DL. Nguy\u00ean nh\u00e2n ch\u00ednh l\u00e0 ML development kh\u00e1c c\u0103n b\u1ea3n so v\u1edbi software development truy\u1ec1n th\u1ed1ng. Ph\u1ea7n m\u1ec1m truy\u1ec1n th\u1ed1ng ch\u1ec9 g\u1ed3m code, trong khi \u0111\u00f3 ML l\u00e0 code v\u00e0 data. Trong khi code \u0111\u01b0\u1ee3c vi\u1ebft v\u00e0 ki\u1ec3m so\u00e1t c\u1ea9n th\u1eadn trong m\u00f4i tr\u01b0\u1eddng ph\u00e1t tri\u1ec3n, th\u00ec d\u1eef li\u1ec7u l\u1ea1i \u0111\u01b0\u1ee3c thu th\u1eadp t\u1eeb nhi\u1ec1u ngu\u1ed3n kh\u00e1c nhau. D\u1eef li\u1ec7u lu\u00f4n lu\u00f4n thay \u0111\u1ed5i theo kh\u1ed1i l\u01b0\u1ee3ng, t\u1ed1c \u0111\u1ed9, \u0111\u1ed9 tin c\u1eady v\u00e0 \u0111a d\u1ea1ng. Do \u0111\u00f3, khi d\u1eef li\u1ec7u ti\u1ebfn h\u00f3a, code c\u0169ng c\u1ea7n ph\u1ea3i thay \u0111\u1ed5i theo th\u1eddi gian.</p> <p>C\u00f3 th\u1ec3 h\u00ecnh dung code v\u00e0 data t\u1ed3n t\u1ea1i tr\u00ean hai m\u1eb7t ph\u1eb3ng kh\u00e1c nhau: c\u00f9ng chia s\u1ebb tr\u1ee5c th\u1eddi gian, nh\u01b0ng \u0111\u1ed9c l\u1eadp \u1edf c\u00e1c kh\u00eda c\u1ea1nh kh\u00e1c. Th\u00e1ch th\u1ee9c trong ph\u00e1t tri\u1ec3n ML l\u00e0 x\u00e2y c\u1ea7u n\u1ed1i gi\u1eefa code v\u00e0 data theo c\u00e1ch c\u00f3 ki\u1ec3m so\u00e1t. N\u1ebfu kh\u00f4ng qu\u1ea3n l\u00fd t\u1ed1t, tri\u1ec3n khai s\u1ebd ch\u1eadm ch\u1ea1p, mong manh, r\u1eddi r\u1ea1c v\u00e0 kh\u00f4ng nh\u1ea5t qu\u00e1n, thi\u1ebfu s\u1ef1 t\u00e1i l\u1eadp v\u00e0 truy xu\u1ea5t ngu\u1ed3n g\u1ed1c. \u0110\u1ec3 gi\u1ea3i quy\u1ebft c\u00e1c v\u1ea5n \u0111\u1ec1 tr\u00ean, MLOPs \u0111\u01b0a ra m\u1ed9t c\u00e1ch ti\u1ebfp c\u1eadn c\u00f3 h\u1ec7 th\u1ed1ng:</p> <ul> <li>K\u1ebft n\u1ed1i code v\u00e0 data c\u00f9ng ti\u1ebfn tri\u1ec3n theo th\u1eddi gian v\u1edbi m\u1ed9t m\u1ee5c ti\u00eau duy nh\u1ea5t, x\u00e2y d\u1ef1ng v\u00e0 duy tr\u00ec m\u1ed9t h\u1ec7 th\u1ed1ng ML m\u1ea1nh m\u1ebd, c\u00f3 th\u1ec3 m\u1edf r\u1ed9ng.</li> <li>H\u1ed7 tr\u1ee3 ph\u00e1t tri\u1ec3n, tri\u1ec3n khai, gi\u00e1m s\u00e1t ML model m\u1ed9t c\u00e1ch tinh g\u1ecdn v\u00e0 h\u1ec7 th\u1ed1ng.</li> <li>Trao quy\u1ec1n h\u1ee3p t\u00e1c cho nh\u00f3m Data Science &amp; IT, c\u00f9ng x\u00e1c th\u1ef1c, ki\u1ec3m so\u00e1t v\u00e0 qu\u1ea3n tr\u1ecb ho\u1ea1t \u0111\u1ed9ng.</li> <li>T\u1ea5t c\u1ea3 c\u00e1c ho\u1ea1t \u0111\u1ed9ng \u0111\u1ec1u \u0111\u01b0\u1ee3c ghi l\u1ea1i, ki\u1ec3m to\u00e1n c\u00f3 th\u1ec3 truy xu\u1ea5t v\u00e0 l\u1eb7p l\u1ea1i.</li> </ul>"},{"location":"knowledge-base/mlops/#6-khai-niem-va-quy-trinh-lam-viec-cua-mlops","title":"6. Kh\u00e1i ni\u1ec7m v\u00e0 quy tr\u00ecnh l\u00e0m vi\u1ec7c c\u1ee7a MLOps","text":"<p>Kh\u00e1i ni\u1ec7m. MLOps l\u00e0 m\u1ed9t ph\u01b0\u01a1ng ph\u00e1p m\u1edbi n\u1ed5i nh\u1eb1m k\u1ebft h\u1ee3p ML v\u1edbi ph\u00e1t tri\u1ec3n ph\u1ea7n m\u1ec1m b\u1eb1ng c\u00e1ch t\u00edch h\u1ee3p nhi\u1ec1u l\u0129nh v\u1ef1c kh\u00e1c nhau, v\u00ec MLOPs k\u1ebft h\u1ee3p ML, DevOps v\u00e0 k\u1ef9 thu\u1eadt d\u1eef li\u1ec7u (Data Engineering) v\u1edbi m\u1ee5c ti\u00eau x\u00e2y d\u1ef1ng, tri\u1ec3n khai v\u00e0 duy tr\u00ec c\u00e1c h\u1ec7 th\u1ed1ng ML trong m\u00f4i tr\u01b0\u1eddng s\u1ea3n xu\u1ea5t. Do \u0111\u00f3, MLOps c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c gi\u1ea3i th\u00edch nh\u01b0 l\u00e0 m\u1ed9t giao \u0111i\u1ec3m c\u1ee7a ba l\u0129nh v\u1ef1c n\u00e0y.</p> <p>Quy tr\u00ecnh l\u00e0m vi\u1ec7c. Nh\u00ecn chung, quy tr\u00ecnh c\u00f4ng vi\u1ec7c c\u1ee7a MLOps \u0111\u01b0\u1ee3c chia th\u00e0nh hai m\u00f4-\u0111un. </p> <ul> <li>Pipeline MLOps (x\u00e2y d\u1ef1ng, tri\u1ec3n khai v\u00e0 gi\u00e1m s\u00e1t) - l\u1edbp tr\u00ean c\u00f9ng. </li> <li>C\u00e1c \u00fd\u1ebfu t\u1ed1 \u0111i\u1ec1u khi\u1ec3n (drivers): d\u1eef li\u1ec7u, m\u00e3 ngu\u1ed3n, artifacts, middleware v\u00e0 h\u1ea1 t\u1ea7ng - l\u1edbp gi\u1eefa v\u00e0 l\u1edbp d\u01b0\u1edbi.</li> </ul> <p>L\u1edbp Pipeline MLOPs \u0111\u01b0\u1ee3c v\u1eadn h\u00e0nh nh\u1edd c\u00e1c y\u1ebfu t\u1ed1 \u0111i\u1ec1u khi\u1ec3n nh\u01b0 d\u1eef li\u1ec7u, m\u00e3 ngu\u1ed3n, artifacts, middleware v\u00e0 h\u1ea1 t\u1ea7ng. Ch\u00fang \u0111\u01b0\u1ee3c h\u1ed7 tr\u1ee3 b\u1edfi m\u1ed9t t\u1eadp h\u1ee3p c\u00e1c d\u1ecbch v\u1ee5, drivers, middleware v\u00e0 h\u1ea1 t\u1ea7ng, t\u1eeb d\u00f3 t\u1ea1o ra c\u00e1c gi\u1ea3i ph\u00e1p d\u1ef1a tr\u00ean ML.</p>"},{"location":"research/","title":"Research Logs","text":""},{"location":"research/#research-logs","title":"\ud83d\udd2c Research Logs","text":"<p>\ud83c\udf39 \"Dream big. Start small. Act now\"</p> <p>\ud83c\udf3b \"The expert in anything was once a beginner\"</p> <p> </p> <p> </p> <p> </p>"},{"location":"research/#tong-quan","title":"\ud83d\udca1 T\u1ed5ng quan","text":"<p>Trong qu\u00e1 tr\u00ecnh nghi\u00ean c\u1ee9u t\u1ea1i Vi\u1ec7n Khoa h\u1ecdc v\u00e0 C\u00f4ng ngh\u1ec7 \u1ee8ng d\u1ee5ng (IAST), t\u00f4i \u0111\u00e3 c\u00f3 c\u01a1 h\u1ed9i tham gia v\u00e0o nhi\u1ec1u d\u1ef1 \u00e1n li\u00ean quan \u0111\u1ebfn \u1ee9ng d\u1ee5ng tr\u00ed tu\u1ec7 nh\u00e2n t\u1ea1o (AI) trong l\u0129nh v\u1ef1c ch\u0103m s\u00f3c s\u1ee9c kh\u1ecfe v\u00e0 gi\u00e1o d\u1ee5c. Trong c\u00e1c d\u1ef1 \u00e1n n\u00e0y, t\u00f4i tr\u1ef1c ti\u1ebfp \u0111\u1ea3m nhi\u1ec7m m\u1ed9t s\u1ed1 nhi\u1ec7m v\u1ee5 nghi\u00ean c\u1ee9u v\u00e0 tri\u1ec3n khai c\u00e1c gi\u1ea3i ph\u00e1p k\u1ef9 thu\u1eadt.</p> <p>M\u1ed7i d\u1ef1 \u00e1n \u0111\u01b0\u1ee3c chia th\u00e0nh nhi\u1ec1u ch\u1ee7 \u0111\u1ec1 nh\u1ecf nh\u1eb1m m\u1edf r\u1ed9ng h\u01b0\u1edbng ti\u1ebfp c\u1eadn v\u00e0 khai th\u00e1c \u0111a chi\u1ec1u b\u00e0i to\u00e1n th\u1ef1c ti\u1ec5n. To\u00e0n b\u1ed9 c\u00e1c ch\u1ee7 \u0111\u1ec1 c\u0169ng nh\u01b0 b\u00e1o c\u00e1o chi ti\u1ebft v\u1ec1 t\u1eebng nhi\u1ec7m v\u1ee5 t\u00f4i \u0111\u00e3 th\u1ef1c hi\u1ec7n \u0111\u1ec1u \u0111\u01b0\u1ee3c h\u1ec7 th\u1ed1ng h\u00f3a v\u00e0 tr\u00ecnh b\u00e0y t\u1ea1i m\u1ee5c [Research Notes].</p>"},{"location":"research/#chu-e-nghien-cuu","title":"\ud83c\udff7\ufe0f Ch\u1ee7 \u0111\u1ec1 nghi\u00ean c\u1ee9u","text":"Ch\u00fa th\u00edch <ul> <li> \u0110\u00e3 ho\u00e0n th\u00e0nh</li> <li> \u0110ang ph\u00e1t tri\u1ec3n</li> <li> Ch\u01b0a b\u1eaft \u0111\u1ea7u</li> </ul> No. Project Status Key Task 01 \u1ee8ng d\u1ee5ng AI h\u1ed7 tr\u1ee3 b\u00e1c s\u0129 trong ph\u00e2n lo\u1ea1i ung th\u01b0 c\u1ed5 t\u1eed cung t\u1ebf b\u00e0o h\u1ecdc  [Link] X\u00e2y d\u1ef1ng v\u00e0 ph\u00e1t tri\u1ec3n m\u00f4 h\u00ecnh AI h\u1ed7 tr\u1ee3 ph\u00e2n lo\u1ea1i v\u00e0 h\u1ed7 tr\u1ee3 c\u00e1c b\u00e1c s\u0129 g\u00e1n nh\u00e3n t\u1ef1 \u0111\u1ed9ng 02 \u1ee8ng d\u1ee5ng c\u00f4ng ngh\u1ec7 AI h\u1ed7 tr\u1ee3 gi\u00e1o d\u1ee5c ph\u1ed5 th\u00f4ng (\u1ee8ng d\u1ee5ng h\u1ed7 tr\u1ee3 h\u1ecdc v\u00e0 d\u1ea1y ti\u1ebfng Anh)  [Link] Nghi\u00ean c\u1ee9u c\u00e1c k\u1ef9 thu\u1eadt v\u00e0 ph\u01b0\u01a1ng ph\u00e1p cho b\u00e0i to\u00e1n Pronunciation Scoring (PS) - Ch\u1ea5m \u0111i\u1ec3m ph\u00e1t \u00e2m ti\u1ebfng Anh cho ng\u01b0\u1eddi Vi\u1ec7t 03 \u1ee8ng d\u1ee5ng AI h\u1ed7 tr\u1ee3 y h\u1ecdc Nghi\u00ean c\u1ee9u ph\u00e1t tri\u1ec3n h\u1ec7 th\u1ed1ng AI h\u1ed7 tr\u1ee3 b\u00e1c s\u0129 trong qu\u00e1 tr\u00ecnh qu\u1ea3n l\u00fd, \u0111\u01b0a ra t\u01b0 v\u1ea5n v.v, li\u00ean quan \u0111\u1ebfn thu\u1ed1c 04 \u1ee8ng d\u1ee5ng AI h\u1ed7 tr\u1ee3 ph\u00e2n lo\u1ea1i ung th\u01b0 \u0111\u1ea1i tr\u1ef1c tr\u00e0ng Tri\u1ec3n khai h\u1ec7 th\u1ed1ng h\u1ed7 tr\u1ee3 b\u00e1c s\u0129 ph\u00e2n lo\u1ea1i ung th\u01b0 \u0111\u1ea1i tr\u1ef1c tr\u00e0ng, g\u00e1n nh\u00e3n v\u00e0 x\u00e2y d\u1ef1ng t\u00e0i li\u1ec7u h\u1ecdc t\u1eadp"},{"location":"research/cervical-cancer-cytology/","title":"Cervical Cancer Cytology","text":""},{"location":"research/cervical-cancer-cytology/#cervical-cancer-cytology","title":"\ud83c\udfe5 Cervical Cancer Cytology","text":"<p>Cervical Cancer Cytology (Ung th\u01b0 c\u1ed5 t\u1eed cung \u2013 T\u1ebf b\u00e0o h\u1ecdc) l\u00e0 m\u1ed9t d\u1ef1 \u00e1n nghi\u00ean c\u1ee9u v\u00e0 ph\u00e1t tri\u1ec3n \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n trong khu\u00f4n kh\u1ed5 h\u1ee3p t\u00e1c gi\u1eefa Vi\u1ec7n Khoa h\u1ecdc v\u00e0 C\u00f4ng ngh\u1ec7 \u1ee8ng d\u1ee5ng v\u00e0 B\u1ec7nh vi\u1ec7n A, Th\u00e1i Nguy\u00ean. M\u1ee5c ti\u00eau ch\u00ednh c\u1ee7a d\u1ef1 \u00e1n l\u00e0 x\u00e2y d\u1ef1ng m\u1ed9t h\u1ec7 th\u1ed1ng h\u1ed7 tr\u1ee3 b\u00e1c s\u0129 trong vi\u1ec7c s\u00e0ng l\u1ecdc v\u00e0 ra quy\u1ebft \u0111\u1ecbnh nhanh ch\u00f3ng tr\u00ean h\u00ecnh \u1ea3nh t\u1ebf b\u00e0o h\u1ecdc b\u1eb1ng c\u00e1c ph\u01b0\u01a1ng ph\u00e1p AI hi\u1ec7n \u0111\u1ea1i.</p> <p>Trang n\u00e0y s\u1ebd t\u1ed5ng h\u1ee3p to\u00e0n b\u1ed9 nh\u1eadt k\u00fd nghi\u00ean c\u1ee9u, m\u00e3 ngu\u1ed3n c\u00e1 nh\u00e2n trong qu\u00e1 tr\u00ecnh x\u00e2y d\u1ef1ng h\u1ec7 th\u1ed1ng, c\u0169ng nh\u01b0 b\u1ed9 d\u1eef li\u1ec7u \u1ea3nh t\u1ebf b\u00e0o h\u1ecdc quy m\u00f4 l\u1edbn \u0111\u01b0\u1ee3c cung c\u1ea5p v\u00e0 cho ph\u00e9p s\u1eed d\u1ee5ng c\u00f4ng khai t\u1eeb B\u1ec7nh vi\u1ec7n A, Th\u00e1i Nguy\u00ean.</p>"},{"location":"research/cervical-cancer-cytology/#my-research-work","title":"My research work","text":""},{"location":"research/cervical-cancer-cytology/#research-topics-overview","title":"Research topics overview","text":"No. Topic Status Description 01 Ensemble Learning for Cervical Cancer Cytology  [notes] [code] <ul><li>Nghi\u00ean c\u1ee9u v\u00e0 \u0111\u00e1nh gi\u00e1 hi\u1ec7u su\u1ea5t c\u00e1c ph\u01b0\u01a1ng ph\u00e1p h\u1ecdc t\u1eadp t\u1ed5 h\u1ee3p (ensemble methods) trong ph\u00e2n lo\u1ea1i \u1ea3nh t\u1ebf b\u00e0o h\u1ecdc.</li><li>Thi\u1ebft k\u1ebf th\u00ed nghi\u1ec7m v\u00e0 hu\u1ea5n luy\u1ec7n m\u00f4 h\u00ecnh tr\u00ean c\u00e1c b\u1ed9 d\u1eef li\u1ec7u th\u1ef1c t\u1ebf v\u1ec1 ung th\u01b0 c\u1ed5 t\u1eed cung.</li><li>\u0110\u00e1nh gi\u00e1 hi\u1ec7u n\u0103ng c\u1ee7a m\u00f4 h\u00ecnh d\u1ef1a tr\u00ean nhi\u1ec1u ti\u00eau ch\u00ed kh\u00e1c nhau.</li><li>C\u00f4ng b\u1ed1 k\u1ebft qu\u1ea3 nghi\u00ean c\u1ee9u t\u1ea1i m\u1ed9t h\u1ed9i ngh\u1ecb chuy\u00ean ng\u00e0nh v\u1ec1 Tr\u00ed tu\u1ec7 Nh\u00e2n t\u1ea1o.</li></ul> 02 Improving Cervical Cancer Screening Through Self-Supervised Learning  [notes] [code] <ul><li>Kh\u1ea3o s\u00e1t c\u00e1c k\u1ef9 thu\u1eadt h\u1ecdc t\u1ef1 gi\u00e1m s\u00e1t trong ph\u00e2n t\u00edch \u1ea3nh y t\u1ebf.</li><li>X\u00e2y d\u1ef1ng b\u1ed9 d\u1eef li\u1ec7u v\u00e0 l\u1ef1a ch\u1ecdn c\u00e1c t\u00e1c v\u1ee5 ti\u1ec1n hu\u1ea5n luy\u1ec7n ph\u00f9 h\u1ee3p v\u1edbi \u1ea3nh t\u1ebf b\u00e0o h\u1ecdc.</li><li>Thi\u1ebft k\u1ebf b\u1ed9 ti\u00eau ch\u00ed \u0111\u00e1nh gi\u00e1 \u0111\u1ec3 so s\u00e1nh v\u1edbi c\u00e1c ph\u01b0\u01a1ng ph\u00e1p truy\u1ec1n th\u1ed1ng.</li></ul>"},{"location":"research/cervical-cancer-cytology/#materials-related-to-the-research","title":"Materials related to the research","text":"<p>Topic 01. Ensemble Learning for Cervical Cancer Cytology:</p> <ul> <li>Paper A: Analysis of Cytology Pap Smear Images Based on Ensemble Deep Learning Approach</li> <li>Paper B: A Deep Learning Ensemble Method to Assist Cytopathologists in Pap Test Image Classification</li> <li>Paper C: A fuzzy rank-based ensemble of CNN models for classification of cervical cytology</li> <li>Paper D: Automated cervical cell segmentation using deep ensemble learning</li> <li>Paper E: An ensemble machine learning-based approach to predict cervical cancer using hybrid feature selection</li> </ul> <p>Topic 02. Improving Cervical Cancer Screening Through Self-Supervised Learning:</p> <ul> <li>Paper A: A Simple Framework for Contrastive Learning of Visual Representations</li> <li>Paper B: Emerging Properties in Self-Supervised Vision Transformers</li> <li>Paper C: Bootstrap Your Own Latent A New Approach to Self-Supervised Learning</li> </ul>"},{"location":"research/cervical-cancer-cytology/#quick-links","title":"Quick links","text":"<p>To\u00e0n b\u1ed9 ghi ch\u00fa (notes), code (m\u00e3) v\u00e0 t\u1eadp d\u1eef li\u1ec7u (datasets) v\u1ec1 Ung th\u01b0 c\u1ed5 t\u1eed cung li\u00ean quan \u0111\u1ebfn d\u1ef1 \u00e1n c\u00f3 th\u1ec3 t\u00ecm th\u1ea5y t\u1ea1i \u0111\u00e2y:</p> <ul> <li> <p>Notes for Project</p> </li> <li> <p>Code for Project</p> </li> <li> <p>Atlat Datasets - [ account: BOCSDL@ai4med.com | password:BenhvienAThaiNguyen ]</p> </li> </ul>"},{"location":"research/cervical-cancer-cytology/experiments/exp-01-ensemble_learning/","title":"Notes on Data Aggregation, Training, and Evaluation Strategies","text":"<p>Trong nghi\u00ean c\u1ee9u n\u00e0y, t\u1eadp trung v\u00e0o c\u00e1c m\u00f4 h\u00ecnh \u0111\u01a1n l\u1ebb (single models). M\u1ee5c ti\u00eau l\u00e0 ph\u00e2n t\u00edch c\u00e1ch g\u1ed9p d\u1eef li\u1ec7u t\u1eeb nhi\u1ec1u ngu\u1ed3n, tri\u1ec3n khai hu\u1ea5n luy\u1ec7n v\u00e0 \u0111\u00e1nh gi\u00e1 \u0111\u1ec3 \u0111\u1ea3m b\u1ea3o t\u00ednh t\u1ed5ng qu\u00e1t h\u00f3a v\u00e0 kh\u1ea3 n\u0103ng so s\u00e1nh gi\u1eefa c\u00e1c b\u1ed9 d\u1eef li\u1ec7u kh\u00e1c nhau.</p>"},{"location":"research/cervical-cancer-cytology/experiments/exp-01-ensemble_learning/#experiments-setup","title":"Experiments setup","text":"<p>\u00c1p d\u1ee5ng 3 chi\u1ebfn l\u01b0\u1ee3c hu\u1ea5n luy\u1ec7n v\u00e0 \u0111\u00e1nh gi\u00e1 bao g\u1ed3m:</p> <ul> <li> <p>Chi\u1ebfn l\u01b0\u1ee3c 1. G\u1ed9p d\u1eef li\u1ec7u th\u1ed1ng nh\u1ea5t (Unified Training). T\u1ea5t c\u1ea3 c\u00e1c b\u1ed9 d\u1eef li\u1ec7u \u0111\u01b0\u1ee3c ti\u1ec1n x\u1eed l\u00fd theo c\u00f9ng m\u1ed9t chu\u1ea9n, g\u1ed9p th\u00e0nh m\u1ed9t t\u1eadp duy nh\u1ea5t. D\u1eef li\u1ec7u \u0111\u01b0\u1ee3c chia theo t\u1ef7 l\u1ec7 c\u1ed1 \u0111\u1ecbnh (train/dev/test 70/15/15) \u0111\u1ec3 hu\u1ea5n luy\u1ec7n v\u00e0 \u0111\u00e1nh gi\u00e1.</p> </li> <li> <p>Chi\u1ebfn l\u01b0\u1ee3c 2. \u0110\u00e1nh gi\u00e1 ch\u00e9o theo b\u1ed9 d\u1eef li\u1ec7u (Cross-Dataset Evaluation). M\u00f4 h\u00ecnh \u0111\u01b0\u1ee3c hu\u1ea5n luy\u1ec7n tr\u00ean m\u1ed9t b\u1ed9 d\u1eef li\u1ec7u c\u1ee5 th\u1ec3 v\u00e0 \u0111\u00e1nh gi\u00e1 tr\u00ean c\u00e1c b\u1ed9 d\u1eef li\u1ec7u kh\u00e1c. Quy tr\u00ecnh n\u00e0y gi\u00fap ph\u00e2n t\u00edch kh\u1ea3 n\u0103ng kh\u00e1i qu\u00e1t h\u00f3a v\u00e0 \u0111\u1ed9 \u1ed5n \u0111\u1ecbnh c\u1ee7a m\u00f4 h\u00ecnh.</p> </li> <li> <p>Chi\u1ebfn l\u01b0\u1ee3c 3. Hu\u1ea5n luy\u1ec7n \u0111a ngu\u1ed3n v\u1edbi \u0111\u00e1nh gi\u00e1 ch\u00e9o (Multi-Source Training). T\u1ea5t c\u1ea3 c\u00e1c b\u1ed9 d\u1eef li\u1ec7u \u0111\u01b0\u1ee3c g\u1ed9p l\u1ea1i trong qu\u00e1 tr\u00ecnh hu\u1ea5n luy\u1ec7n. Tuy nhi\u00ean, \u0111\u00e1nh gi\u00e1 \u0111\u01b0\u1ee3c ti\u1ebfn h\u00e0nh ri\u00eang bi\u1ec7t tr\u00ean t\u1eadp test c\u1ee7a t\u1eebng b\u1ed9 d\u1eef li\u1ec7u, cho ph\u00e9p quan s\u00e1t hi\u1ec7u su\u1ea5t tr\u00ean t\u1eebng ph\u00e2n ph\u1ed1i kh\u00e1c nhau.</p> </li> </ul>"},{"location":"research/cervical-cancer-cytology/experiments/exp-01-ensemble_learning/#data-aggregation","title":"Data Aggregation","text":"<p>D\u1ef1a v\u00e0o th\u00f4ng tin th\u1ed1ng k\u00ea, \u0111\u1eb7c \u0111i\u1ec3m c\u1ee7a c\u00e1c b\u1ed9 d\u1eef li\u1ec7u [datasets-overview], th\u1ef1c hi\u1ec7n mapping v\u1ec1 d\u1eef li\u1ec7u d\u1ea1ng 2 nh\u00e3n. </p> Datasets Label Class Herlev superficiel Normal intermediate Normal columnar Normal light dysplastic Abnormal moderate_dysplastic Abnormal severe dysplastic Abnormal carcinoma in situ Abnormal LBC NILM Normal LSIL Abnormal HSIL Abnormal SCC Abnormal Hicervix ASC_H Abnormal ASC_US Abnormal HSIL Abnormal LSIL Abnormal SCC Abnormal SipakMed Dyskeratotic (DYSK) Abnormal Koilocytotic (KOIL) Abnormal Metaplastic (META) Normal Parabasal (PARA) Normal Superficial-Moderate (SM) Normal BVA ASC_H Abnormal ASC_US Abnormal HSIL Abnormal LSIL Abnormal SCC Abnormal <p>B\u1ea3ng 1. B\u1ea3ng quy \u0111\u1ed5i nh\u00e3n t\u01b0\u01a1ng \u1ee9ng tr\u00ean t\u1eebng b\u1ed9 d\u1eef li\u1ec7u d\u1ef1a tr\u00ean quy \u01b0\u1edbc ph\u00e2n lo\u1ea1i trong t\u1ebf b\u00e0o h\u1ecdc t\u1eed cung. </p> <p>Sau khi mapping ti\u1ebfn h\u00e0nh g\u1ed9p d\u1eef li\u1ec7u v\u00e0 thu \u0111\u01b0\u1ee3c b\u1ed9 d\u1eef li\u1ec7u l\u1edbn \u0111\u01b0\u1ee3c th\u1ed1ng k\u00ea m\u00f4 t\u1ea3 nh\u01b0 sau:</p> Dataset Normal Abnormal Total Herlev 242 675 917 LBC 0 963 963 HiCervix 0 8,840 8,840 SIPaKMed 1,618 2,472 4,090 Hospital A 0 22,434 22,434 Total 1,860 35,384 37,244 <p>B\u1ea3ng 2. B\u1ea3ng d\u1eef li\u1ec7u th\u1ed1ng k\u00ea sau khi ti\u1ebfn h\u00e0nh g\u1ed9p d\u1eef li\u1ec7u t\u1eeb 5 b\u1ed9 ri\u00eang bi\u1ec7t, v\u1edbi hai nh\u00e3n b\u00ecnh th\u01b0\u1eddng + b\u1ea5t th\u01b0\u1eddng.</p>"},{"location":"research/cervical-cancer-cytology/experiments/exp-01-ensemble_learning/#cross-dataset-evaluation","title":"Cross-Dataset Evaluation","text":"<ul> <li> <p>\u00dd t\u01b0\u1edfng. Trong chi\u1ebfn l\u01b0\u1ee3c n\u00e0y, c\u00e1c m\u00f4 h\u00ecnh \u0111\u01b0\u1ee3c hu\u1ea5n luy\u1ec7n tr\u00ean b\u1ed9 d\u1eef li\u1ec7u B\u1ec7nh vi\u1ec7n A v\u00e0 sau \u0111\u00f3 \u0111\u00e1nh gi\u00e1 kh\u1ea3 n\u0103ng kh\u00e1i qu\u00e1t h\u00f3a (generalization) tr\u00ean nhi\u1ec1u b\u1ed9 d\u1eef li\u1ec7u c\u00f4ng khai kh\u00e1c nhau. To\u00e0n b\u1ed9 d\u1eef li\u1ec7u \u0111\u01b0\u1ee3c quy \u0111\u1ed5i v\u1ec1 c\u00f9ng m\u1ed9t nhi\u1ec7m v\u1ee5 ph\u00e2n lo\u1ea1i nh\u1ecb ph\u00e2n (normal vs. abnormal).</p> </li> <li> <p>\u01afu \u0111i\u1ec3m. \u0110\u00e1nh gi\u00e1 \u0111\u01b0\u1ee3c kh\u1ea3 n\u0103ng kh\u00e1i qu\u00e1t h\u00f3a c\u1ee7a m\u00f4 h\u00ecnh sang ngu\u1ed3n d\u1eef li\u1ec7u kh\u00e1c v\u00e0 cho ph\u00e9p so s\u00e1nh m\u1ee9c \u0111\u1ed9 ph\u1ee5 thu\u1ed9c ph\u00e2n ph\u1ed1i d\u1eef li\u1ec7u gi\u1eefa c\u00e1c ki\u1ebfn tr\u00fac.</p> </li> <li> <p>Nh\u01b0\u1ee3c \u0111i\u1ec3m. Kh\u00f4ng t\u1eadn d\u1ee5ng \u0111\u01b0\u1ee3c to\u00e0n b\u1ed9 d\u1eef li\u1ec7u c\u00f3 s\u1eb5n, vi\u1ec7c d\u1eabn \u0111\u1ebfn s\u1ef1 kh\u00e1i qu\u00e1t h\u00f3a k\u00e9m ho\u00e0n to\u00e0n c\u00f3 th\u1ec3 x\u1ea3y ra.</p> </li> </ul> <p>\u0110\u00e1nh gi\u00e1.</p> <ul> <li> <p>M\u00f4 h\u00ecnh hu\u1ea5n luy\u1ec7n tr\u00ean d\u1eef li\u1ec7u B\u1ec7nh vi\u1ec7n A \u0111\u1ea1t hi\u1ec7u su\u1ea5t cao. </p> </li> <li> <p>Khi \u0111\u00e1nh gi\u00e1 tr\u00ean c\u00e1c b\u1ed9 d\u1eef li\u1ec7u c\u00f4ng khai, F1-score gi\u1ea3m cho th\u1ea5y s\u1ef1 ph\u1ee5 thu\u1ed9c v\u00e0o ph\u00e2n ph\u1ed1i d\u1eef li\u1ec7u g\u1ed1c.</p> </li> <li> <p>Nh\u00f3m InceptionV3 / InceptionResNetV2 v\u01b0\u1ee3t tr\u1ed9i h\u01a1n VGG16 v\u00e0 ResNet101 kho\u1ea3ng h\u01a1n 10% \u0111i\u1ec3m F1-score.</p> </li> <li> <p>MobileNetV2 v\u00e0 Xception \u0111\u1ea1t k\u1ebft qu\u1ea3 trung b\u00ecnh nh\u01b0ng \u1ed5n \u0111\u1ecbnh, c\u00e2n b\u1eb1ng gi\u1eefa \u0111\u1ed9 ch\u00ednh x\u00e1c v\u00e0 chi ph\u00ed t\u00ednh to\u00e1n.</p> </li> </ul> <p>\u0110\u00e1nh gi\u00e1 ch\u00e9o cho th\u1ea5y m\u00f4 h\u00ecnh duy tr\u00ec hi\u1ec7u su\u1ea5t tr\u00ean trung b\u00ecnh v\u1edbi d\u1eef li\u1ec7u m\u1edbi, nh\u01b0ng v\u1eabn c\u00f2n kho\u1ea3ng c\u00e1ch l\u1edbn so v\u1edbi t\u1eadp g\u1ed1c.</p> Dataset Model Accuracy Precision Recall F1-Score Hospital A MobileNetV2 65.51 72.84 73.05 72.41 InceptionV3 69.93 77.24 76.25 76.57 InceptionResNetV2 71.62 78.36 78.12 78.04 VGG16 61.94 69.22 69.15 68.65 ResNet101 58.83 65.08 65.91 64.41 Xception 65.58 71.74 72.75 71.18 Herlev MobileNetV2 57.13 64.27 64.62 63.58 InceptionV3 61.12 68.34 67.41 67.05 InceptionResNetV2 63.48 70.21 69.67 69.14 VGG16 53.26 60.38 60.71 59.63 ResNet101 50.47 57.16 57.42 56.54 Xception 57.39 64.11 65.08 63.62 LBC Pap Smear MobileNetV2 54.72 61.14 61.85 61.02 InceptionV3 58.43 65.12 65.07 64.78 InceptionResNetV2 60.07 66.83 66.14 66.02 VGG16 51.29 57.41 57.82 57.09 ResNet101 48.75 54.62 55.18 54.71 Xception 54.06 60.72 61.41 60.38 HiCervix MobileNetV2 52.63 59.82 60.44 59.67 InceptionV3 56.38 62.94 63.05 62.58 InceptionResNetV2 58.07 65.11 64.82 64.55 VGG16 49.41 55.48 56.02 55.17 ResNet101 47.22 53.27 53.68 53.01 Xception 52.05 58.74 59.16 58.42 SIPakMed MobileNetV2 54.82 61.37 61.92 61.14 InceptionV3 58.63 64.95 65.21 64.58 InceptionResNetV2 60.42 67.24 67.01 66.73 VGG16 51.73 57.68 58.12 57.42 ResNet101 49.28 55.02 55.41 54.86 Xception 54.15 60.34 60.82 60.02 <p>B\u1ea3ng 3. \u0110\u00e1nh gi\u00e1 hi\u1ec7u su\u1ea5t c\u1ee7a c\u00e1c m\u00f4 h\u00ecnh \u0111\u01b0\u1ee3c hu\u1ea5n luy\u1ec7n tr\u00ean BVA tr\u00ean c\u00e1c b\u1ed9 d\u1eef li\u1ec7u c\u00f4ng khai kh\u00e1c.</p>"},{"location":"research/cervical-cancer-cytology/experiments/exp-01-ensemble_learning/#unified-training","title":"Unified Training","text":"<ul> <li> <p>\u00dd t\u01b0\u1edfng. T\u1ea5t c\u1ea3 c\u00e1c b\u1ed9 d\u1eef li\u1ec7u \u0111\u01b0\u1ee3c ti\u1ec1n x\u1eed l\u00fd theo c\u00f9ng m\u1ed9t chu\u1ea9n (k\u00edch th\u01b0\u1edbc, s\u1ed1 l\u1edbp normal vs. abnormal, v.v.). Sau \u0111\u00f3 \u0111\u01b0\u1ee3c g\u1ed9p l\u1ea1i th\u00e0nh m\u1ed9t t\u1eadp d\u1eef li\u1ec7u duy nh\u1ea5t \u0111\u1ec3 hu\u1ea5n luy\u1ec7n v\u00e0 \u0111\u00e1nh gi\u00e1.</p> </li> <li> <p>\u01afu \u0111i\u1ec3m. D\u1ec5 tri\u1ec3n khai, t\u1ea1o ra t\u1eadp d\u1eef li\u1ec7u \u0111\u1ee7 l\u1edbn gi\u00fap m\u00f4 h\u00ecnh h\u1ecdc \u0111\u01b0\u1ee3c nhi\u1ec1u \u0111\u1eb7c tr\u01b0ng h\u01a1n.</p> </li> <li> <p>Nh\u01b0\u1ee3c \u0111i\u1ec3m. \u0110\u1eb7c th\u00f9 ph\u00e2n ph\u1ed1i b\u1ed9 d\u1eef li\u1ec7u c\u00f3 th\u1ec3 b\u1ecb m\u1ea5t \u0111i, d\u1eabn \u0111\u1ebfn k\u1ebft qu\u1ea3 \u0111\u00e1nh gi\u00e1 kh\u00f4ng ph\u1ea3n \u00e1nh \u0111\u1ea7y \u0111\u1ee7 kh\u1ea3 n\u0103ng kh\u00e1i qu\u00e1t h\u00f3a cho m\u1ed7i ngu\u1ed3n d\u1eef li\u1ec7u ri\u00eang bi\u1ec7t.</p> </li> </ul> <p>K\u1ebft qu\u1ea3 \u0111\u00e1nh gi\u00e1.</p> <ul> <li> <p>Nh\u00ecn chung hi\u1ec7u su\u00e2t t\u1ed5ng th\u1ec3 kh\u00e1 \u0111\u1ed3ng \u0111\u1ec1u, c\u00e1c m\u00f4 h\u00ecnh InceptionResNetV2 v\u00e0 Xception cho k\u1ebft qu\u1ea3 cao nh\u1ea5t v\u01b0\u1ee3t tr\u1ed9i so v\u1edbi c\u00e1c m\u00f4 h\u00ecnh c\u1ed5 \u0111i\u1ec3n VGG16.</p> </li> <li> <p>S\u1ef1 kh\u00e1c bi\u1ec7t gi\u1eefa c\u00e1c ch\u1ec9 s\u1ed1, \u0111\u1ed9 \u0111\u00f4 hi\u1ec7u su\u1ea5t l\u00e0 kh\u00f4ng l\u1edbn, tuy nhi\u00ean kh\u00f4ng ph\u1ea3n \u00e1nh h\u1ebft \u0111\u01b0\u1ee3c kh\u1ea3 n\u0103ng t\u01b0\u01a1ng th\u00edch theo t\u1eebng mi\u1ec1n d\u1eef li\u1ec7u ri\u00eang l\u1ebb.</p> </li> </ul> Model Accuracy Precision Recall F1-Score MobileNetV2 71.12 71.85 70.43 70.82 InceptionV3 73.21 73.88 72.65 72.94 InceptionResNetV2 74.95 75.41 73.88 74.11 VGG16 70.42 70.11 69.87 69.35 ResNet101 71.76 71.94 70.68 71.28 Xception 73.48 73.92 72.75 73.02 <p>B\u1ea3ng 4. So s\u00e1nh hi\u1ec7u su\u1ea5t c\u1ee7a c\u00e1c m\u00f4 h\u00ecnh \u0111\u01a1n l\u1ebb sau khi \u0111\u01b0\u1ee3c hu\u1ea5n luy\u1ec7n v\u00e0 \u0111\u00e1nh gi\u00e1 tr\u00ean b\u1ed9 d\u1eef li\u1ec7u \u0111\u01b0\u1ee3c g\u1ed9p.</p>"},{"location":"research/cervical-cancer-cytology/experiments/exp-01-ensemble_learning/#multi-source-training","title":"Multi-Source Training","text":"<ul> <li> <p>\u00dd t\u01b0\u1edfng. Trong chi\u1ebfn l\u01b0\u1ee3c n\u00e0y, nhi\u1ec1u b\u1ed9 d\u1eef li\u1ec7u \u0111\u01b0\u1ee3c g\u1ed9p chung \u0111\u1ec3 hu\u1ea5n luy\u1ec7n, \u0111\u1ea3m b\u1ea3o m\u00f4 h\u00ecnh ti\u1ebfp x\u00fac v\u1edbi ph\u00e2n ph\u1ed1i phong ph\u00fa v\u00e0 \u0111a d\u1ea1ng. Qu\u00e1 tr\u00ecnh \u0111\u00e1nh gi\u00e1 sau \u0111\u00f3 \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n ri\u00eang bi\u1ec7t tr\u00ean t\u1eebng b\u1ed9 d\u1eef li\u1ec7u, cho ph\u00e9p ph\u00e2n t\u00edch hi\u1ec7u su\u1ea5t trong t\u1eebng ng\u1eef c\u1ea3nh c\u1ee5 th\u1ec3.</p> </li> <li> <p>\u01afu \u0111i\u1ec3m. Gi\u00fap m\u00f4 h\u00ecnh ti\u1ebfp x\u00fac v\u1edbi ph\u00e2n ph\u1ed1i d\u1eef li\u1ec7u \u0111a d\u1ea1ng, t\u0103ng kh\u1ea3 n\u0103ng kh\u00e1i qu\u00e1t h\u00f3a, cho ph\u00e9p nh\u00ecn th\u1ea5y \u0111\u01b0\u1ee3c hi\u1ec7u su\u1ea5t ri\u00eang bi\u1ec7t c\u1ee7a t\u1eebng ngu\u1ed3n d\u1eef li\u1ec7u.</p> </li> <li> <p>H\u1ea1n ch\u1ebf. C\u00f3 th\u1ec3 b\u1ecb bias n\u1ebfu m\u1ed9t b\u1ed9 d\u1eef li\u1ec7u t\u1eeb m\u1ed9t ngu\u1ed3n v\u01b0\u1ee3t tr\u1ed9i h\u01a1n (v\u00ed d\u1ee5 b\u1ed9 Hircervix v\u00e0 BVA).</p> </li> </ul> <p>\u0110\u00e1nh gi\u00e1. To\u00e0n b\u1ed9 d\u1eef li\u1ec7u train c\u1ee7a 5 b\u1ed9 d\u1eef li\u1ec7u \u0111\u01b0\u1ee3c g\u1ed9p l\u1ea1i \u0111\u1ec3 hu\u1ea5n luy\u1ec7n, qu\u00e1 tr\u00ecnh d\u00e1nh gi\u00e1 c\u00e1c m\u00f4 h\u00ecnh s\u1ebd s\u1eed d\u1ee5ng t\u1eadp test c\u1ee7a t\u1eebng b\u1ed9 d\u1eef li\u1ec7u g\u1ed1c.</p> <ul> <li> <p>Nh\u00f3m Inception (V3, ResNetV2) v\u1eabn \u1ed5n \u0111\u1ecbnh v\u00e0 v\u01b0\u1ee3t tr\u1ed9i h\u01a1n. </p> </li> <li> <p>MobileNetV2, Xception cho k\u1ebft qu\u1ea3 trung b\u00ecnh nh\u01b0ng kh\u00e1 \u0111\u1ed3ng \u0111\u1ec1u tr\u00ean c\u00e1c b\u1ed9 d\u1eef li\u1ec7u.</p> </li> <li> <p>VGG16, ResNet101 consistently th\u1ea5p h\u01a1n, \u0111\u1eb7c bi\u1ec7t tr\u00ean HiCervix.</p> </li> </ul> <p>K\u1ebft qu\u1ea3 ph\u1ea3n \u00e1nh r\u1eb1ng hu\u1ea5n luy\u1ec7n \u0111a ngu\u1ed3n gi\u00fap duy tr\u00ec hi\u1ec7u su\u1ea5t t\u01b0\u01a1ng \u0111\u1ed1i kh\u00e1 tr\u00ean c\u00e1c t\u1eadp test kh\u00e1c nhau, d\u00f9 v\u1eabn c\u00f3 ch\u00eanh l\u1ec7ch theo t\u1eebng ph\u00e2n ph\u1ed1i d\u1eef li\u1ec7u.</p> Model Hospital A Herlev LBC HiCervix SIPakMed MobileNetV2 70.42 62.18 59.87 58.41 61.22 InceptionV3 74.63 66.32 63.95 61.72 65.48 InceptionResNetV2 73.58 68.77 66.42 63.18 67.23 VGG16 67.11 59.24 57.13 54.62 58.04 ResNet101 64.88 57.86 55.42 53.01 56.27 Xception 69.14 63.02 60.71 64.02 68.11 <p>B\u1ea3ng 5. . K\u1ebft qu\u1ea3 F1-Score (%) c\u1ee7a c\u00e1c m\u00f4 h\u00ecnh theo t\u1eebng b\u1ed9 d\u1eef li\u1ec7u (\u0111\u01b0\u1ee3c \u0111\u00e1nh gi\u00e1 tr\u00ean t\u1eadp test).</p>"},{"location":"research/cervical-cancer-cytology/experiments/exp-01-ensemble_learning/#leave-on-dataset-out","title":"Leave-On-Dataset-out","text":""},{"location":"research/cervical-cancer-cytology/experiments/exp-01-ensemble_learning/#domain-adaptation","title":"Domain Adaptation","text":""},{"location":"research/cervical-cancer-cytology/experiments/exp-01-ensemble_learning/#multi-task-learning","title":"Multi-Task Learning","text":""},{"location":"research/cervical-cancer-cytology/experiments/exp-02-self_supervised_learning/","title":"Topic 01. Self-Supervised Learning for Cervical Cancer Classification","text":""},{"location":"research/cervical-cancer-cytology/experiments/exp-02-self_supervised_learning/#experimental-setup","title":"Experimental setup","text":""},{"location":"research/cervical-cancer-cytology/experiments/exp-02-self_supervised_learning/#datasets","title":"Datasets","text":"<p>Herlev datasets. B\u1ed9 d\u1eef li\u1ec7u t\u1ebf b\u00e0o h\u1ecdc c\u1ed5 t\u1eed cung \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng r\u1ed9ng r\u00e3i trong nghi\u00ean c\u1ee9u v\u1ec1 nh\u1eadn d\u1ea1ng v\u00e0 ph\u00e2n lo\u1ea1i t\u1ebf b\u00e0o ung th\u01b0 c\u1ed5 t\u1eed cung t\u1eeb \u1ea3nh hi\u1ec3n vi (Jan Jantzen et al., 2006), \u0111\u01b0\u1ee3c thu th\u1eadp t\u1ea1i Herlev University Hospital, \u0110an M\u1ea1ch. Th\u1ed1ng k\u00ea b\u1ed9 d\u1eef li\u1ec7u \u0111\u01b0\u1ee3c m\u00f4 t\u1ea3 trong B\u1ea3ng 1. B\u1ed9 d\u1eef li\u1ec7u g\u1ed3m 917 \u1ea3nh v\u1edbi 7 lo\u1ea1i nh\u00e3n kh\u00e1c nhau, trong \u0111\u00f3 c\u00f3 3 nh\u00e3n l\u00e0 normal (b\u00ecnh th\u01b0\u1eddng) v\u00e0 4 nh\u00e3n l\u00e0 b\u1ea5t th\u01b0\u1eddng (abnormal). </p> Label Number for label Types superficiel 74 Normal intermediate 70 Normal columnar 98 Normal light dysplastic 182 Abnormal severe dysplastic 197 Abnormal moderate_dysplastic 146 Abnormal carcinoma in situ 150 Abnormal Total 917 <p>B\u1ea3ng 1. Th\u1ed1ng k\u00ea m\u00f4 t\u1ea3 b\u1ed9 d\u1eef li\u1ec7u Herlev Pap-smear.</p> <p>LBC Pap smear datasets. LBC (Liquid-Based Cytology) l\u00e0 m\u1ed9t trong c\u00e1c x\u00e9t nghi\u1ec7m s\u00e0ng l\u1ecdc ung th\u01b0 c\u1ed5 t\u1eed cung (Elima Husain et al., 2020). B\u1ed9 d\u1eef li\u1ec7u n\u00e0y bao g\u1ed3m t\u1ed5ng c\u1ed9ng 963 \u1ea3nh LBC, \u0111\u01b0\u1ee3c chia th\u00e0nh b\u1ed1n nh\u00f3m t\u01b0\u01a1ng \u1ee9ng v\u1edbi b\u1ed1n l\u1edbp t\u1ed5n th\u01b0\u01a1ng: NILM, LSIL, HSIL v\u00e0 SCC. C\u00e1c l\u1edbp n\u00e0y \u0111\u1ea1i di\u1ec7n cho c\u00e1c t\u1ed5n th\u01b0\u01a1ng ti\u1ec1n ung th\u01b0 v\u00e0 ung th\u01b0 c\u1ed5 t\u1eed cung. H\u00ecnh \u1ea3nh \u0111\u01b0\u1ee3c thu th\u1eadp t\u1eeb 460 b\u1ec7nh nh\u00e2n, v\u1edbi nhi\u1ec1u v\u1ea5n \u0111\u1ec1 ph\u1ee5 khoa kh\u00e1c nhau. M\u00f4 t\u1ea3 th\u1ed1ng k\u00ea c\u1ee7a b\u1ed9 d\u1eef li\u1ec7u \u0111\u01b0\u1ee3c cung c\u1ea5p trong B\u1ea3ng 2.</p> Label Number for label Types LSIL 113 Precancerous NILM 613 Precancerous HSIL 163 Precancerous SCC 74 Cancer Total 963 <p>B\u1ea3ng 2. B\u1ed9 d\u1eef li\u1ec7u LBC bao g\u1ed3m b\u1ed1n \u0111\u1ea1i di\u1ec7n t\u1ed5n th\u01b0\u01a1ng: NILM, LSIL, HSIL v\u00e0 SCC.</p> <p>HiCerix datasets. B\u1ed9 d\u1eef li\u1ec7u t\u1ebf b\u00e0o h\u1ecdc c\u1ed5 t\u1eed cung l\u1edbn nh\u1ea5t v\u00e0 \u0111a trung t\u00e2m nh\u1ea5t \u0111\u01b0\u1ee3c c\u00f4ng b\u1ed1 c\u00f4ng khai (De Cai et al., 2024). HiCervix bao g\u1ed3m 40.299 \u1ea3nh t\u1ebf b\u00e0o c\u1ed5 t\u1eed cung \u0111\u01b0\u1ee3c c\u1eaft t\u1eeb 4.496 \u1ea3nh l\u00e1t c\u1eaft to\u00e0n b\u1ed9 (whole slide images), \u0111\u01b0\u1ee3c ph\u00e2n lo\u1ea1i th\u00e0nh 29 l\u1edbp v\u00e0 c\u00f3 ch\u00fa th\u00edch. C\u00e1c l\u1edbp n\u00e0y \u0111\u01b0\u1ee3c t\u1ed5 ch\u1ee9c theo m\u1ed9t c\u00e2y ph\u00e2n c\u1ea5p ba t\u1eb1ng nh\u1eb1m n\u1eafm b\u1eaft th\u00f4ng tin chi ti\u1ebft v\u1ec1 c\u00e1c nh\u00f3m nh\u1ecf (fine-grained subtypes). Trong b\u1ed9 d\u1eef li\u1ec7u n\u00e0y c\u00f3 ch\u1ee9a 8.840 h\u00ecnh \u1ea3nh thu\u1ed9c 5 nh\u00e3n m\u1ee5c ti\u00eau cho giai \u0111o\u1ea1n downstream task (th\u1ed1ng k\u00ea m\u00f4 t\u1ea3 B\u1ea3ng 3).</p> Label Number for label Types ASC_H 1437 Precancerous ASC_US 2599 Precancerous HSIL 1988 Precancerous LSIL 1744 Precancerous SCC 1072 Cancer Total 8840 <p>B\u1ea3ng 3. C\u00e1c nh\u00e3n m\u1ee5c ti\u00eau cho giai \u0111o\u1ea1n downstream task \u0111\u01b0\u1ee3c tr\u00edch xu\u1ea5t t\u1eeb b\u1ed9 d\u1eef li\u1ec7u Hicervix.</p> <p>SIPaKMed datasets. L\u00e0 m\u1ed9t trong nh\u1eefng b\u1ed9 d\u1eef li\u1ec7u \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng r\u1ed9ng r\u00e3i trong b\u00e0i to\u00e1n ph\u00e2n lo\u1ea1i t\u1ebf b\u00e0o c\u1ed5 t\u1eed cung t\u1eeb \u1ea3nh Pap smear. Bao g\u1ed3m 4.090 \u1ea3nh t\u1ebf b\u00e0o ri\u00eang bi\u1ec7t \u0111\u01b0\u1ee3c crop th\u1ee7 c\u00f4ng t\u1eeb 966 \u1ea3nh nh\u1edbm t\u1ebf b\u00e0o Pap smear. SiPaKMed ph\u00e2n lo\u1ea1i t\u1ebf b\u00e0o theo n\u0103m l\u1edbp d\u1ef1a tr\u00ean \u0111\u1eb7c \u0111i\u1ec3m h\u00ecnh th\u00e1i (m\u00f4 t\u1ea3 chi ti\u1ebft trong B\u1ea3ng 4).</p> Label Number for label Types Dyskeratotic (DYSK) 813 abnormal Koilocytotic (KOIL) 825 abnormal Metaplastic (META) 793 benign Parabasal (PARA) 787 normal Superficial-Moderate (SM) 831 normal Total 4090 <p>B\u1ea3ng 4. B\u1ed9 d\u1eef li\u1ec7u SIPaKMed g\u1ed3m n\u0103m l\u1edbp ch\u00ednh, \u0111\u01b0\u1ee3c thu th\u1eadp t\u1eeb 966 \u1ea3nh nh\u00f3m t\u1ebf b\u00e0o Pap smear.</p> <p>Hospital A datasets. B\u1ed9 d\u1eef li\u1ec7u thu th\u1eadp t\u1eeb B\u1ec7nh vi\u00ean A th\u00e1i nguy\u00ean, g\u1ed3m 22.434 \u1ea3nh t\u1ebf b\u00e0o g\u1ed3m n\u0103m nh\u00e3n l\u1edbp ch\u00ednh (B\u1ea3ng 5).</p> Label Number for label Types ASC_H 5.669 precancerous ASC_US 3.869 precancerous HSIL 6.355 precancerous LSIL 4.780 precancerous SCC 1.761 cancer Total 22.434 <p>B\u1ea3ng 5. Ph\u00e2n ph\u1ed1i chi ti\u1ebft b\u1ed9 d\u1eef li\u1ec7u thu th\u1eadp t\u1eeb B\u1ec7nh vi\u1ec7n A, Th\u00e1i Nguy\u00ean tr\u00ean n\u0103m nh\u00e3n ch\u00ednh.</p>"},{"location":"research/cervical-cancer-cytology/experiments/exp-02-self_supervised_learning/#data-design-strategy","title":"Data design strategy","text":"<p>\u0110\u1ec3 ph\u1ee5c v\u1ee5 cho qu\u00e1 tr\u00ecnh th\u1ef1c nghi\u1ec7m, l\u00e0m r\u00f5 m\u1ed9t s\u1ed1 v\u1ea5n \u0111\u1ec1, c\u00e1c b\u1ed9 d\u1eef li\u1ec7u (\u0111\u00e3 \u0111\u01b0\u1ee3c m\u00f4 t\u1ea3 \u1edf Ph\u1ea7n 1) s\u1ebd \u0111\u01b0\u1ee3c thi\u1ebft k\u1ebf \u0111\u1ec3 \u0111\u1ea3m b\u1ea3o t\u00ednh \u0111a d\u1ea1ng, kh\u1ea3 thi v\u00e0 ph\u00f9 h\u1ee3p:</p> <ul> <li> <p>HSLBC datasets. G\u1ed9p ba b\u1ed9 d\u1eef li\u1ec7u Herlev, SIPakMed v\u00e0 LBC.</p> </li> <li> <p>HSLBCHi datasets. M\u1edf r\u1ed9ng th\u00eam b\u1ed9 d\u1eef li\u1ec7u HSLBC b\u1eb1ng c\u00e1ch th\u00eam v\u00e0o b\u1ed9 Hicervix.</p> </li> </ul> <p>B\u1ed9 d\u1eef li\u1ec7u \u1edf b\u1ec7nh vi\u1ec7n A l\u00e0 b\u1ed9 d\u1eef li\u1ec7u m\u1ee5c ti\u00eau ch\u00ednh cho giai \u0111o\u1ea1n downstream task, b\u1ed9 d\u1eef li\u1ec7u n\u00e0y s\u1ebd \u0111\u01b0\u1ee3c chia th\u00e0nh c\u00e1c t\u1eadp d\u1eef li\u1ec7u con ph\u1ee5c v\u1ee5 cho qu\u00e1 tr\u00ecnh hu\u1ea5n luy\u1ec7n, ki\u1ec3m th\u1eed v\u00e0 \u0111\u00e1nh gi\u00e1.</p> #train (70%) #val (15%) #test (15%) 15.704 3.366 3.364"},{"location":"research/pronunciation-scoring/","title":"Pronunciation Scoring","text":""},{"location":"research/pronunciation-scoring/#pronunciation-scoring-for-education","title":"Pronunciation Scoring for Education","text":"<p> M\u1ee5c ti\u00eau h\u01b0\u1edbng t\u1edbi: X\u00e2y d\u1ef1ng h\u1ec7 th\u1ed1ng t\u1ef1 \u0111\u1ed9ng ch\u1ea5m \u0111i\u1ec3m ph\u00e1t \u00e2m (Pronunciation Scoring - PS) ho\u1eb7c h\u1ed7 tr\u1ee3 ph\u00e1t hi\u1ec7n l\u1ed7i ph\u00e1t \u00e2m cho ng\u01b0\u1eddi h\u1ecdc Ti\u1ebfng Anh: T\u1eadp trung v\u00e0o 3 nhi\u1ec7m v\u1ee5 nh\u1ecf:</p> <ul> <li> <p>Ph\u00e1t hi\u1ec7n l\u1ed7i ph\u00e1t \u00e2m (Mispronunciation Detection)</p> </li> <li> <p>Ch\u1ea5m \u0111i\u1ec3m ph\u00e1t \u00e2m (Pronuncation Scoring)</p> </li> <li> <p>Ph\u1ea3n h\u1ed3i v\u00e0 \u0111\u00e1nh gi\u00e1 (Diagnosis &amp; Feedback)</p> </li> </ul>"},{"location":"research/pronunciation-scoring/#ke-hoach-nhiem-vu-chi-tiet","title":"\u23f3 K\u1ebf ho\u1ea1ch &amp; Nhi\u1ec7m v\u1ee5 chi ti\u1ebft","text":"Phase Deadline Task Description Resources 01_Nghi\u00ean c\u1ee9u t\u1ed5ng quan &amp; Chu\u1ea9n b\u1ecb d\u1eef li\u1ec7u 02/06 - 02/07, 2025 <code>W01_T\u1ed5ng quan v\u1ec1 b\u00e0i to\u00e1n Pronunciation Scoring</code> - Ph\u00e2n t\u00edch 3 ch\u1ee9c n\u0103ng, m\u1ee5c ti\u00eau ch\u00ednh c\u1ee7a b\u00e0i to\u00e1n (detect, score, feedback).  - Nghi\u00ean c\u1ee9u m\u1ed9t s\u1ed1 paper quan tr\u1ecdng li\u00ean quan \u0111\u1ebfn PS (GOP, DNN-GOP, Wav2Vec-Scoring).  - Nghi\u00ean c\u1ee9u m\u1ed9t s\u1ed1 ki\u1ebfn tr\u00fac PS t\u1ed5ng th\u1ec3 (g\u1ed3m ph\u1ea7n thu \u00e2m, x\u1eed l\u00fd \u00e2m thanh, ph\u00e2n t\u00edch, ch\u1ea5m \u0111i\u1ec3m v\u00e0 ph\u1ea3n h\u1ed3i cho ng\u01b0\u1eddi h\u1ecdc). <code>[report]</code> <code>W02: Thu th\u1eadp v\u00e0 t\u00ecm hi\u1ec3u m\u1ed9t s\u1ed1 b\u1ed9 d\u1eef li\u1ec7u c\u00f4ng khai</code> - L\u1ef1a ch\u1ecdn, t\u00ecm c\u00e1c b\u1ed9 d\u1eef li\u1ec7u ng\u01b0\u1eddi Vi\u1ec7t n\u00f3i Ti\u1ebfng Anh ho\u1eb7c ng\u01b0\u1eddi kh\u00f4ng ph\u1ea3i b\u1ea3n \u0111\u1ecba n\u00f3i ti\u1ebfng Anh.  - Chu\u1ea9n h\u00f3a \u00e2m thanh sao cho c\u00f3 \u0111\u1ecbnh d\u1ea1ng \u0111\u1ea3m b\u1ea3o t\u00ednh ph\u00f9 h\u1ee3p v\u00e0 ch\u00e2t l\u01b0\u1ee3ng.  - T\u1ea1o transcript \u0111i k\u00e8m, chuy\u1ec3n sang d\u1ea1ng ph\u00e1t \u00e2m t\u1eebng \u00e2m ti\u1ebft.  - C\u0103n kh\u1edbp \u00e2m thanh v\u1edbi v\u0103n b\u1ea3n, s\u1eed d\u1ee5ng m\u1ed9t s\u1ed1 c\u00f4ng c\u1ee5 c\u0103n kh\u1edbp \u0111\u1ec3 x\u00e1c \u0111\u1ecbnh ch\u00ednh x\u00e1c v\u1ecb tr\u00ed t\u1eebng \u00e2m thanh trong c\u00e2u n\u00f3i (Montreal Forced Aligner ho\u1eb7c Gentle). <code>W03: Ch\u1ea1y m\u00f4 h\u00ecnh \u0111\u00e1nh gi\u00e1 c\u01a1 b\u1ea3n v\u00e0 ph\u00e2n t\u00edch l\u1ed7i</code> - D\u00f9ng m\u1ed9t s\u1ed1 m\u00f4 h\u00ecnh \u0111\u01a1n gi\u1ea3n c\u00f3 s\u1eb5n nh\u01b0 GOP \u0111\u1ec3 ch\u1ea5m \u0111i\u1ec3m t\u1eebng \u00e2m ng\u01b0\u1eddi h\u1ecdc ph\u00e1t ra, t\u1eeb \u0111\u00f3 bi\u1ebft \u00e2m n\u00e0o ph\u00e1t \u0111\u00fang, \u00e2m n\u00e0o sai.  - D\u1ef1a v\u00e0o k\u1ebft qu\u1ea3 m\u00f4 h\u00ecnh, \u0111\u00e1nh gi\u00e1 th\u1ee7 c\u00f4ng, x\u00e1c \u0111\u1ecbnh m\u1ed9t s\u1ed1 l\u1ed7i ph\u1ed5 bi\u1ebfn m\u00e0 ng\u01b0\u1eddi Vi\u1ec7t th\u01b0\u1eddng m\u1eafc ph\u1ea3i khi n\u00f3i ti\u1ebfng Anh.  - L\u1ef1a ch\u1ecdn ho\u1eb7c t\u1ef1 t\u1ea1o m\u1ed9t b\u1ed9 d\u1eef li\u1ec7u th\u1ee7 c\u00f4ng, t\u1ef1 g\u00e1n nh\u00e3n \u0111\u00fang sai nh\u1eb1m so s\u00e1nh k\u1ebft qu\u1ea3 m\u00e0 m\u00f4 h\u00ecnh \u0111\u01b0a ra. <code>[report]</code> <code>W04: Ph\u00e2n t\u00edch \u0111\u1eb7c tr\u01b0ng &amp; Th\u1eed nghi\u1ec7m m\u00f4 h\u00ecnh ch\u1ea5m \u0111i\u1ec3m</code> - L\u1ea5y \u0111\u1eb7c \u0111i\u1ec3m c\u1ee7a \u00e2m thanh \u0111\u1ec3 ph\u00e2n t\u00edch m\u1edf r\u1ed9ng, s\u1eed d\u1ee5ng m\u00f4t s\u1ed1 c\u00f4ng c\u1ee5 nh\u01b0 librosa ho\u1eb7c openSMILE \u0111\u1ec3 tr\u00edch xu\u1ea5t m\u1ed9t s\u1ed1 \u0111\u1eb7c \u0111i\u1ec3m quan tr\u1ecdng (\u0111\u1ed9 cao gi\u1ecdng, \u0111\u1ed9 vang, h\u00ecnh d\u1ea1ng \u00e2m thanh,v.v.).  - S\u1eed d\u1ee5ng m\u1ed9t s\u1ed1 thu\u1eadt to\u00e1n d\u1ec5 hu\u1ea5n luy\u1ec7n \u0111\u1ec3 \u01b0\u1edbc l\u01b0\u1ee3ng \u0111i\u1ec3m ph\u00e1t \u00e2m c\u1ee7a ng\u01b0\u1eddi h\u1ecdc d\u1ef1a tr\u00ean c\u00e1c \u0111\u1eb7c tr\u01b0ng \u0111\u00e3 tr\u00edch xu\u1ea5t.  - Th\u1eed nghi\u1ec7m v\u00e0 ph\u1ea3n h\u1ed3i c\u01a1 b\u1ea3n nh\u01b0 \u00e2m n\u00e0o ng\u01b0\u1eddi h\u1ecdc \u0111\u00e3 n\u00f3i sai, c\u00e1ch ph\u00e1t \u00e2m \u0111\u00fang l\u00e0 g\u00ec.v.v. 02_Th\u1eed nghi\u1ec7m m\u00f4 h\u00ecnh &amp; T\u1ed1i \u01b0u h\u00f3a 02/07 - 02/08, 2025 <code>W01_Hu\u1ea5n luy\u1ec7n m\u00f4 h\u00ecnh ph\u00e1t hi\u1ec7n l\u1ed7i ph\u00e1t \u00e2m (Mispronunciation Detection)</code> - S\u1eed d\u1ee5ng m\u1ed9t s\u1ed1 m\u00f4 h\u00ecnh \u00e2m thanh truy\u1ec1n th\u1ed1ng ho\u0103c hi\u1ec7n \u0111\u1ea1i \u0111\u1ec3 tinh ch\u1ec9nh tr\u00ean d\u1eef li\u1ec7u ph\u00e1t \u00e2m sai (HuBERT, Wav2Vec2).  - So s\u00e1nh k\u1ebft qu\u1ea3 c\u1ee7a m\u00f4 h\u00ecnh n\u00e0y v\u1edbi ph\u01b0\u01a1ng ph\u00e1p truy\u1ec1n th\u1ed1ng GOP \u1edf phare 01 xem c\u00e1i n\u00e1o ph\u00e1t hi\u1ec7n l\u1ed7i t\u1ed1t h\u01a1n.  - Ki\u1ec3m th\u1eed b\u1eb1ng tay \u0111\u1ec3 ki\u1ec3m tra m\u00f4 h\u00ecnh b\u1eb1ng c\u00e1ch t\u1ef1 t\u1ea1o b\u1ed9 d\u1eef li\u1ec7u g\u00e1n nh\u00e3n th\u1ee7 c\u00f4ng. <code>W02_Hu\u1ea5n luy\u1ec7n m\u00f4 h\u00ecnh ch\u1ea5m \u0111i\u1ec3m ph\u00e1t \u00e2m (Pronunciation Scoring)</code> - S\u1eed d\u1ee5ng m\u00f4 h\u00ecnh h\u1ecdc m\u00e1y ho\u1eb7c h\u1ecdc s\u00e2u \u0111\u1ec3 l\u1ea5y \u0111\u1eb7c tr\u01b0ng \u00e2m thanh, sau \u0111\u00f3 \u0111\u01b0a v\u00e0o m\u1ed9t s\u1ed1 m\u00f4 h\u00ecnh \u0111\u01a1n gi\u1ea3n nh\u1eafm t\u00ednh ra \u0111i\u1ec3m t\u1ed5ng th\u1ec3 cho m\u1ed7i c\u00e2u n\u00f3i.  - So s\u00e1nh \u0111i\u1ec3m m\u00e1y ch\u1ea5m v\u1edbi \u0111i\u1ec3m d\u1eef li\u1ec7u ch\u1ea5m th\u1ef1c t\u1ebf \u0111\u1ec3 \u0111o \u0111\u1ed9 t\u01b0\u01a1ng \u0111\u1ed3ng (correlation). <code>W03_T\u1ea1o ph\u1ea3n h\u1ed3i s\u1eeda l\u1ed7i cho ng\u01b0\u1eddi h\u1ecdc</code> - Khi m\u00f4 h\u00ecnh ph\u00e1t hi\u1ec7n ra l\u1ed7i ph\u00e1t \u00e2m, h\u1ec7 th\u1ed1ng c\u1ea7n x\u00e1c \u0111\u1ecbnh l\u1ed7i n\u00e0o, g\u1ee3i \u00fd s\u1eeda l\u1ed7i \u0111\u00f3.  - T\u1ea1o m\u1eabu g\u1ee3i \u00fd ph\u00e1t \u00e2m chu\u1ea9n theo text ho\u1eb7c audio,v.v. <code>W04_\u0110\u00e1nh gi\u00e1 l\u1ea1i m\u00f4 h\u00ecnh</code> - \u0110\u00e1nh gi\u00e1 t\u1ed5ng th\u1ec3 hi\u1ec7u su\u1ea5t c\u00e1c m\u00f4 h\u00ecnh b\u1eb1ng c\u00e1c ch\u1ec9 s\u1ed1 ph\u1ed5 bi\u1ebfn kh\u00e1c nh\u01b0 precision, recall.  - V\u1edbi m\u00f4 h\u00ecnh ch\u1ea5m \u0111i\u1ec3m. s\u1eed d\u1ee5ng \u0111\u1ed9 \u0111o sai s\u1ed1 trung b\u00ecnh MSE \u0111\u1ec3 \u0111\u00e1nh gi\u00e1. 03_Tri\u1ec3n khai v\u00e0 ki\u1ec3m th\u1eed th\u1ef1c t\u1ebf 02/08 - 02/09, 2025 <code>W01_T\u00edch h\u1ee3p ho\u00e0n ch\u1ec9nh c\u00e1c m\u00f4 h\u00ecnh</code> - Gh\u00e9p c\u00e1c th\u00e0nh ph\u1ea7n ch\u00ednh: ph\u00e1t hi\u1ec7n l\u1ed7i, ch\u1ea5m \u0111i\u1ec3m, ph\u00e0n h\u1ed3i s\u1eeda l\u1ed7i v\u00e0o c\u00f9ng m\u1ed9t h\u1ec7 th\u1ed1ng.  - Thi\u1ebft k\u1ebft lu\u1ed3ng x\u1eed l\u00fd t\u1eeb nh\u1eadn \u00e2m thanh \u0111\u1ea7u vao cho \u0111\u1ebfn khi \u0111\u01b0a ra k\u1ebft qu\u1ea3 cu\u1ed1i c\u00f9ng cho ng\u01b0\u1eddi d\u00f9ng. <code>W02&amp;W03_Ki\u1ec3m th\u1eed v\u1edbi c\u00e1c ph\u00e0n h\u1ed3i th\u1ef1c t\u1ebf</code> - Thu th\u1eadp ph\u1ea3n h\u1ed3i \u0111\u1ec3 \u0111\u00e1nh gi\u00e1 v\u00e0 c\u1ea3i thi\u1ec7n, tinh ch\u1ec9nh th\u00eam m\u00f4 h\u00ecnh ho\u1eb7c h\u1ec7 th\u1ed1ng.  - T\u1ed5ng h\u1ee3p c\u00e1c g\u00f3p \u00fd \u0111\u1ec3 l\u00ean k\u1ebf ho\u1ea1ch n\u00e2ng c\u1ea5p ho\u1eb7c ch\u1ec9nh s\u1eeda. <code>W04_T\u1ed5ng k\u1ebft v\u00e0 b\u00e1o c\u00e1o k\u1ebft qu\u1ea3</code> - \u0110\u00e1nh gi\u00e1 t\u1ed5ng quan v\u1ec1 hi\u1ec7u qu\u1ea3 c\u1ee7a h\u1ec7 th\u1ed1ng v\u00e0 nh\u1eefng h\u1ea1n ch\u1ebf c\u00f2n t\u1ed3n t\u1ea1i.  - Vi\u1ebft b\u00e1o c\u00e1o k\u1ef9 thu\u1eadt t\u1ed5ng h\u1ee3p k\u1ebft qu\u1ea3 nghi\u00ean c\u1ee9u v\u00e0 tri\u1ec3n khai h\u1ec7 th\u1ed1ng th\u1ef1c t\u1ebf.  - \u0110\u1ec1 xu\u1ea5t h\u01b0\u1edbng c\u1ea3i thi\u1ec7n ti\u1ebfp theo."},{"location":"research/pronunciation-scoring/#datasets","title":"\ud83d\udee2\ufe0f Datasets","text":"No. Name Details Link 01 <code>Speechocean762</code> - T\u1eadp d\u1eef li\u1ec7u gi\u1ecdng n\u00f3i ph\u1ee5c v\u1ee5 cho b\u00e0i to\u00e1n \u0111\u00e1nh gi\u00e1 ph\u00e1t \u00e2m.  - G\u1ed3m 5000 c\u00e2u ti\u1ebfng Anh \u0111\u01b0\u1ee3c ph\u00e1t \u00e2m b\u1edfi 250 ng\u01b0\u1eddi kh\u00f4ng ph\u1ea3i b\u1ea3n \u0111\u1ecba, trong \u0111\u00f3 m\u1ed9t n\u1eeda l\u00e0 tr\u1ebb em. Nh\u00e3n \u0111\u01b0\u1ee3c c\u00e1c chuy\u00ean gia ng\u00f4n ng\u1eef \u0111\u00e1nh gi\u00e1 \u1edf ba c\u1ea5p \u0111\u1ed9: c\u1ea5p c\u00e2u (sentence-level), c\u1ea5p t\u1eeb (word-level), c\u1ea5p \u00e2m v\u1ecb (phoneme-level). <code>[speechocean762]</code> 02 <code>L2-ARCTIC</code> - B\u1ed9 d\u1eef li\u1ec7u g\u1ed3m 26.867 c\u00e2u tho\u1ea1i c\u1ee7a 24 ng\u01b0\u1eddi kh\u00f4ng ph\u1ea3i b\u1ea3n \u0111\u1ecba, c\u00f3 c\u00e2n b\u1eb1ng gi\u1edbi t\u00ednh.  - T\u1ed5ng 27 gi\u1edd \u00e2m thanh v\u00e0 c\u00f3 g\u00e1n nh\u00e3n l\u1ed7i ph\u00e1t \u00e2m (thay \u00e2m, thi\u1ebfu \u00e2m, th\u00eam \u00e2m) <code>[l2-arctic]</code> 03 <code>LibriSpeech</code> - B\u1ed9 d\u1eef li\u1ec7u l\u1edbn g\u1ea7n 1000 gi\u1edd g\u1ed3m c\u00e1c \u0111o\u1ea1n ghi \u00e2m s\u00e1ch n\u00f3i ti\u1ebfng Anh.  - \u0110\u01b0\u1ee3c chia th\u00e0nh hai type ch\u00ednh (clean v\u00e0 other), trong \u0111\u00f3 clean \u0111\u01b0\u1ee3c cho l\u00e0 d\u1ec5 d\u00e0ng nh\u1eadn d\u1ea1ng h\u01a1n c\u00f2n other c\u00f3 ti\u1ec1ng \u1ed3n v\u00e0 kh\u00f3 nh\u1eadn bi\u1ebft h\u01a1n. <code>[librispeech]</code> 04 <code>EpaDB</code> - Thi\u1ebft k\u1ebf \u0111\u1eb7c bi\u1ec7t cho nghi\u00ean c\u1ee9u v\u00e0 ph\u00e1t tri\u1ec3n b\u00e0i to\u00e1n ch\u1ea5m \u0111i\u1ec3m ph\u00e1t \u00e2m.  - Bao g\u1ed3m 3200 \u0111o\u1ea1n n\u00f3i ti\u1ebfng Anh, \u0111\u01b0\u1ee3c t\u1ea1o ra b\u1edfi 50 ng\u01b0\u1eddi n\u00f3i ti\u1ebfng T\u00e2y Ban Nha g\u1ed1c Argentina, \u0111\u01b0\u1ee3c ch\u00fa th\u00edch \u1edf m\u00fac \u0111\u1ed9 ng\u1eef \u00e2m chi ti\u1ebft. <code>[epadb]</code>"},{"location":"research/pronunciation-scoring/#benchmarks-for-pronunciation-scoring-datasets","title":"\u2694\ufe0f Benchmarks for Pronunciation Scoring Datasets","text":"No. Dataset Task Model PCC Notes Resources 01 <code>Speechocean762</code> Phone-level HierCB+ConPCO 0.70 S\u1eed d\u1ee5ng contrastive learning &amp; orginal regression \u0111\u1ec3 c\u1ea3i thi\u1ec7n \u0111\u1ed9 ch\u00ednh x\u00e1c Paper 02 GOPT-PAII 0.68 S\u1eed d\u1ee5ng m\u00f4 h\u00ecnh transformer cho ph\u00e2n t\u00edch v\u1ec1 nhi\u1ec1u kh\u00eda c\u1ea1nh ti\u1ebfng n\u00f3i Paper 03 SpeechBlender + LSTM 0.63 T\u1ea1o d\u1eef li\u1ec7u l\u1ed7i gi\u1ea3 l\u1eadp + LSTM \u0111\u1ec3 ch\u1ea5m \u0111i\u1ec3m Paper 04 HiPAMA-LibriSpeech 0.62 \u00c1p d\u1ee5ng attention \u0111\u1ec3 \u0111\u00e1nh gi\u00e1 ph\u00e1t \u00e2m theo c\u1ea5u tr\u00fac ph\u00e2n c\u1ea5p Paper 05 GOP 0.45 Ph\u01b0\u01a1ng ph\u00e1p truy\u1ec1n th\u1ed1ng Paper 01 <code>Speechocean762</code> Word-level 3MH 0.69 Paper 02 GOPT-PAII 0.60 Paper 03 HiPAMA-Librispeech 0.59 Paper 01 <code>Speechocean762</code> Utterance-level 3MH 0.81 Paper 02 HierCB+ConPCO 0.80 Paper 03 GOPT-Librispeech 0.74 Paper 04 GOPT-PAII 0.73 Paper"},{"location":"research/pronunciation-scoring/experiments/exp-03-design_multitask_baseline/","title":"Multi-task learning for Pronunciation Scoring","text":""},{"location":"research/pronunciation-scoring/experiments/exp-03-design_multitask_baseline/#i-problems-and-objective","title":"I. Problems and objective","text":"<p>M\u1ee5c ti\u00eau m\u00f4 h\u00ecnh. Nghi\u00ean c\u1ee9u thi\u1ebft k\u1ebf m\u00f4 h\u00ecnh v\u1edbi hai m\u1ee5c ti\u00eau ch\u00ednh:</p> <ul> <li> <p>Tr\u1ea3 v\u1ec1 c\u1ea3 nh\u00e3n l\u1ed7i chi ti\u1ebft (phoneme-level)</p> </li> <li> <p>Tr\u1ea3 v\u1ec1 \u0111i\u1ec3m ph\u00e1t \u00e2m to\u00e0n c\u00e2u (sentence-level score)</p> </li> </ul> <p>V\u1ea5n \u0111\u1ec1 ch\u00ednh. B\u1ed9 d\u1eef li\u1ec7u [speechocean] v\u00e0 b\u1ed9 d\u1eef li\u1ec7u [l2arctic] c\u00f3 nh\u1eefng \u0111\u1eb7c \u0111i\u1ec3m, \u0111\u1ea1c tr\u01b0ng ph\u00e2n t\u00e1n kh\u00e1c nhau:</p> <ul> <li> <p>Speech Ocean: C\u00f3 nh\u00e3n \u0111i\u1ec3m to\u00e0n c\u00e2u (accuracy, completeness, fluency, prosodic) nh\u01b0ng kh\u00f4ng c\u00f3 nh\u00e3n l\u1ed7i \u00e2m v\u1ecb chi ti\u1ebft.</p> </li> <li> <p>L2-ARCTIC: C\u00f3 nh\u00e3n l\u1ed7i chi ti\u1ebft \u1edf m\u1ee9c \u00e2m v\u1ecb (phoneme-level) nh\u01b0ng kh\u00f4ng c\u00f3 \u0111i\u1ec3m to\u00e0n c\u00e2u.</p> </li> </ul> <p>Hi\u1ec7n t\u1ea1i kh\u00f4ng c\u00f3 b\u1ed9 datasets n\u00e0o c\u00f3 th\u1ec3 cung c\u1ea5p \u0111\u1ea7y \u0111\u1ee7 c\u00e1c th\u00f4ng tin nh\u00e3n l\u1ed7i chi ti\u1ebft v\u00e0 nh\u00e3n \u0111i\u1ec3m to\u00e0n c\u00e2u.</p> <p>H\u01b0\u1edbng nghi\u00ean c\u1ee9u. Thi\u1ebft k\u1ebf b\u00e0i to\u00e1n multi-task learning v\u1edbi d\u1eef li\u1ec7u kh\u00f4ng \u0111\u1ed3ng b\u1ed9 nh\u1eb1m t\u1eadn d\u1ee5ng m\u1ecdi d\u1eef li\u1ec7u m\u00e0 kh\u00f4ng c\u1ea7n t\u00e1i nh\u00e3n.</p>"},{"location":"research/pronunciation-scoring/experiments/exp-03-design_multitask_baseline/#ii-proposed-model","title":"II. Proposed model","text":"<p>Backbone. T\u1eadn d\u1ee5ng c\u00e1c m\u00f4 h\u00ecnh \u0111\u00e3 \u0111\u01b0\u1ee3c pretrained tr\u00ean l\u01b0\u1ee3ng d\u1eef li\u1ec7u l\u1edbn (wav2vec 2.0/HuBERT) nh\u1eb1m tr\u00edch xu\u1ea5t \u0111\u1eb7c tr\u01b0ng th\u00f4 tr\u1ef1c ti\u1ebfp t\u1eeb \u00e2m thanh (frame-level embeddings). Th\u1ef1c hi\u1ec7n hai chi\u1ebfn l\u01b0\u1ee3c khi \u0111\u01b0a backbone v\u00e0o m\u00f4 h\u00ecnh ch\u1ea5m \u0111i\u1ec3m ph\u00e1t \u00e2m:</p> <ul> <li> <p>Kh\u00f4ng fine-tune (ch\u1ec9 l\u00e0m feature extractor): Ch\u1ec9 l\u1ea5y embedding c\u1ed1 \u0111\u1ecbnh t\u1eeb backbone cho m\u1ed7i audio, sau \u0111\u00f3 \u0111\u01b0a ch\u00fang v\u00e0o c\u00e1c m\u00f4 h\u00ecnh \u0111\u1ec3 ph\u1ee5c v\u1ee5 cho hai task ch\u00ednh: phone-level classification ho\u1eb7c sentence-level regression.</p> </li> <li> <p>Fine-tune to\u00e0n b\u1ecd backbone: Khi train multi-task, c\u00e1c gradient + loss c\u1ee7a c\u1ea3 hai task s\u1ebd \u0111\u1ed3ng th\u1eddi \u0111\u01b0\u1ee3c truy\u1ec1n ng\u01b0\u1ee3c v\u00e0o backbone \u0111\u1ec3 tinh ch\u1ec9nh.</p> </li> </ul> <p>Heads (multi-task). T\u1eadp trung v\u00e0o hai task ch\u00ednh ph\u1ee5c v\u1ee5 cho hai m\u1ee5c ti\u00eau c\u1ee7a m\u00f4 h\u00ecnh:</p> <ol> <li> <p>Phoneme-level MLP classifier (frame-level). S\u1eed d\u1ee5ng c\u00e1c embdding \u0111\u00e3 \u0111\u01b0\u1ee3c tr\u00edch xu\u1ea5t t\u1eeb backbone hu\u1ea5n luy\u1ec7n m\u1ed9t b\u1ed9 ph\u00e2n lo\u1ea1i \u0111\u1ec3 phan lo\u1ea1i v\u00e0 x\u00e1c \u0111\u1ecbnh l\u1ed7i chi ti\u1ebft.</p> </li> <li> <p>Sentence-level regression. Hu\u1ea5n luy\u1ec7n b\u1ed9 h\u1ed3i quy tr\u00ean c\u00e1c embddings \u0111\u01b0\u1ee3c backbone tr\u00edch xu\u1ea5t \u0111\u1ec3 d\u1ef1 \u0111o\u00e1n ra m\u1ed9t s\u1ed1 nh\u00e3n \u0111i\u1ec3m cho to\u00e0n c\u00e2u (accuracy, completeness, fluency, prosodic)</p> </li> </ol>"},{"location":"research/pronunciation-scoring/experiments/exp-03-design_multitask_baseline/#iii-training-strategy","title":"III. Training strategy","text":"<p>V\u1edbi d\u1eef li\u1ec7u \u0111\u1ebfn t\u1eeb hai b\u1ed9 kh\u00e1c nhau, m\u1ed9t s\u1ed1 chi\u1ebfn l\u01b0\u1ee3c hu\u1ea5n luy\u1ec7n \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng:</p> <ul> <li> <p>D\u1eef li\u1ec7u t\u1eeb L2-ARCTIC: ch\u1ec9 forward cho phoneme-level head v\u00e0 backbone (n\u1ebfu fine-tune) trong khi \u0111\u00f3 sentence-level head kh\u00f4ng t\u00ednh gradient</p> </li> <li> <p>D\u1eef li\u1ec7u t\u1eeb Speech Ocean: ch\u1ec9 forward cho sentence-level head v\u00e0 bacbone (n\u1ebfu fine-tune), phoneme-level head kh\u00f4ng t\u00ednh gradient.</p> </li> </ul> <p>\u0110\u1ec3 \u0111i\u1ec1u ch\u1ec9nh s\u1ef1 c\u00e2n b\u1eb1ng cho hai task, h\u00e0m loss \u0111\u01b0\u1ee3c thi\u1ebft k\u1ebf \u0111\u01a1n gi\u1ea3n, \\(\\alpha\\) v\u00e0 \\(\\beta\\) c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c tinh ch\u1ec9nh: </p> \\[ \\text{total_loss} = \\alpha * \\text{phoneme_loss} + \\beta * \\text{sentence_loss} \\]"},{"location":"research/pronunciation-scoring/experiments/exp-03-design_multitask_baseline/#iv-experimental-setup","title":"IV. Experimental setup","text":"<p>Datasets.</p> <ol> <li> <p>L2-ARCTIC</p> <ul> <li> <p>M\u1ee5c ti\u00eau: Hu\u1ea5n luy\u1ec7n phoneme-level classifier</p> </li> <li> <p>Preprocessing: S\u1eed d\u1ee5ng MFA \u0111\u1ec3 \u00e9p khung v\u00e0 g\u00e1n nh\u00e3n frame-level sau \u0111\u00f3 tr\u00edch xu\u1ea5t embedding t\u1eeb backbone cho m\u1ed7i frame</p> </li> </ul> </li> <li> <p>Speech Ocean</p> <ul> <li> <p>M\u1ee5c ti\u00eau: Hu\u1ea5n luy\u1ec7n sentence-level regression</p> </li> <li> <p>Preprocessing: Chu\u00e2n h\u00f3a d\u1eef li\u1ec7u audio gi\u1ed1ng nh\u01b0 b\u1ed9 d\u1eef li\u1ec7u L2-ARCTIC, sau \u0111\u00f3 pool frame embeddings th\u00e0nh sentence embedding (mean pooling, attention pooling)</p> </li> </ul> </li> </ol> <p>Evaluation metrics.</p> <ul> <li> <p>Phoneme-level (classification task): accuracy, f1-score, confusion-matrix.</p> </li> <li> <p>Sentence-level (regression task): RMSE, MSE, MAE</p> </li> </ul> <p>Ablation study. Ph\u1ea7n n\u00e0y nh\u1eb1m t\u00ecm v\u00e0 ph\u00e2n t\u00edch c\u00e1c y\u1ebfu t\u1ed1 \u1ea3nh h\u01b0\u1edfng nh\u1ea5t \u0111\u1ebfn hi\u1ec7u su\u1ea5t m\u00f4 h\u00ecnh</p> <ul> <li> <p>Backbone frozen vs fine-tune: So s\u00e1nh xem li\u1ec7u fine-tune c\u00f3 gi\u00fap ph\u00e1t hi\u1ec7n l\u1ed7i v\u00e0 d\u1ef1 \u0111o\u00e1n \u0111i\u1ec3m ch\u00ednh x\u00e1c h\u01a1n kh\u00f4ng.</p> </li> <li> <p>Pooling strategies: ch\u1ec9 \u00e1p d\u1ee5ng cho sentence-level head, t\u1eadp trung v\u00e0o hai option ch\u00ednh l\u00e0: (1) mean pooling - trung b\u00ecnh c\u00e1c frame embedding; (2) attention pooling - cho ph\u00e9p model h\u1ecdc tr\u1ecdng s\u1ed1 kh\u00e1c nhau cho t\u1eebng frame quan tr\u1ecdng.</p> </li> <li> <p>Loss balancing (\\(\\alpha/\\beta\\) impact): \u0110\u00e1nh gi\u00e1 s\u1ef1 \u1ea3nh h\u01b0\u1edfng c\u1ee7a hai tham s\u1ed1 n\u00e0y t\u1edbi hi\u1ec7u su\u1ea5t c\u1ee7a m\u00f4 h\u00ecnh \u0111\u1ed3ng th\u1eddi \u1edf c\u1ea3 hai task.</p> </li> </ul>"},{"location":"research/pronunciation-scoring/experiments/exp-03-design_multitask_baseline/#v-baseline-comparisions","title":"V. Baseline comparisions","text":"<ol> <li> <p>MLP classifier + backbone frozen</p> <ul> <li>\u0110\u00e2y l\u00e0 baseline c\u01a1 b\u1ea3n cho phomeme-level task</li> <li>Backbone \u0111\u01b0\u1ee3c gi\u1eef nguy\u00ean, kh\u00f4ng fine-tune ch\u1ec9 d\u00f9ng \u0111\u1ec3 tr\u00edch xu\u1ea5t \u0111\u1eb7c tr\u01b0ng c\u00f4 \u0111\u1ecbnh t\u1eeb audio</li> <li>Ph\u1ea7n MLP classifier \u0111\u01b0\u1ee3c hu\u1ea5n luy\u1ec7n \u0111\u1ec3 ph\u00e2n lo\u1ea1i l\u1ed7i phoneme d\u1ef1a tr\u00ean embedding n\u00e0y</li> <li>M\u1ee5c \u0111\u00edch: \u0111\u00e1nh gi\u00e1 hi\u1ec7u qu\u1ea3 c\u1ee7a feature extractor nguy\u00ean g\u1ed1c khi kh\u00f4ng tinh ch\u1ec9nh s\u1eed d\u1ee5ng c\u00e1c \u0111\u1ed9 \u0111\u00f4 nh\u01b0 accuracy v\u00e0 f1-score</li> </ul> </li> <li> <p>MLP classifier + backbone fine-tuned</p> <ul> <li>T\u01b0\u01a1ng t\u1ef1 baseline tr\u00ean, nh\u01b0ng \u1edf \u0111\u00e2y backbone \u0111\u01b0\u1ee3c fine-tuen c\u00f9ng v\u1edbi MLP classifier</li> <li>M\u1ee5c \u0111\u00edch: xem vi\u1ec7c fine-tune backbone c\u00f3 gi\u00fap t\u0103ng hi\u1ec7u qu\u1ea3 nh\u1eadn di\u1ec5n l\u1ed7i phoneme kh\u00f4ng.</li> </ul> </li> <li> <p>Multi-task model + backbone frozen</p> <ul> <li>Hu\u1ea5n luy\u1ec7n \u0111\u1ed3ng th\u1eddi phomeme-level v\u00e0 sentence-level nh\u01b0ng kh\u00f4ng fine-tune backbone</li> <li>M\u1ee5c ti\u00eau: ki\u1ec3m tra hi\u1ec7u qu\u1ea3 c\u1ee7a backbone gi\u1eefa hai task, ngay c\u1ea3 khi embeddings kh\u00f4ng \u0111\u01b0\u1ee3c tinh ch\u1ec9nh.</li> </ul> </li> <li> <p>Multi-tasl model + backbone fine-tuned</p> <ul> <li>Hu\u1ea5n luy\u1ec7n \u0111\u1ed3ng th\u1eddi c\u1ea3 hai task v\u1ee5, nh\u01b0ng backbone \u0111\u01b0\u1ee3c fine-tune t\u1eeb c\u1ea3 hai task.</li> <li>M\u1ee5c ti\u00eau: \u0110\u00e1nh gi\u00e1 l\u1ee3i \u00edch c\u1ee7a fine-tune backbone trong multi-task \u0111\u1ec3 t\u0103ng kh\u1ea3 n\u0103ng nh\u1eadn di\u1ec7n v\u00e0 d\u1ef1 \u0111o\u00e1n.</li> </ul> </li> </ol>"},{"location":"research/pronunciation-scoring/experiments/exp-03-design_multitask_baseline/#vi-results","title":"VI. Results","text":"<ul> <li>Tri\u1ec3n khai \u0111\u00e1nh gi\u00e1 c\u00e1c c\u00e1c m\u00f4 h\u00ecnh cho b\u00e0i t\u00f3an d\u1ef1 \u0111o\u00e1n \u0111i\u1ec3m to\u00e0n c\u00e2u \u0111\u01b0\u1ee3c \u0111\u00e1nh gi\u00e1 tr\u00ean b\u1ed9 d\u1eef li\u1ec7u SpeechOcean s\u1eed d\u1ee5ng PCC (Pearson Correlation Coefficient). </li> </ul> Model Prosody Completeness Fluency Linear Regression 0.70 \u00b1 0.06 0.71 \u00b1 0.05 0.73 \u00b1 0.04 Decision Tree 0.72 \u00b1 0.05 0.73 \u00b1 0.04 0.75 \u00b1 0.03 Random Forest 0.76 \u00b1 0.03 0.77 \u00b1 0.03 0.78 \u00b1 0.03 XGBoost 0.78 \u00b1 0.03 0.79 \u00b1 0.02 0.80 \u00b1 0.02 <ul> <li>C\u00e1c m\u00f4 h\u00ecnh \u0111\u01b0\u1ee3c hu\u1ea5n luy\u1ec7n tr\u01b0\u1edbc tr\u00ean b\u1ed9 d\u1eef li\u1ec7u l2-arctic \u0111\u01b0\u1ee3c \u0111\u00e1nh gi\u00e1 tr\u00ean b\u1ed9 speechocean (\u0111\u00e1nh gi\u00e1 nh\u1ecb ph\u00e2n) nh\u1eb1m \u0111\u00e1nh gi\u00e1 kh\u1ea3 n\u0103ng t\u1ed5ng qu\u00e1t h\u00f3a khi d\u1ecbch chuy\u1ec3n sang mi\u1ec1n d\u1eef li\u1ec7u m\u1edbi  </li> </ul> Model Speechocean762 (F1-score) MLP 0.68 \u00b1 0.04 BiLSTM 0.72 \u00b1 0.03 GOP-based 0.65 \u00b1 0.05 Mini-Transformer 0.73 \u00b1 0.03"},{"location":"research/pronunciation-scoring/experiments/report01/","title":"N\u1ec1n t\u1ea3ng v\u00e0 ph\u01b0\u01a1ng ph\u00e1p x\u1eed l\u00fd ti\u1ebfng n\u00f3i cho \u0111\u00e1nh gi\u00e1 ph\u00e1t \u00e2m","text":"<p>M\u00f4 t\u1ea3</p> <p>Ph\u1ea7n n\u00e0y s\u1ebd \u0111\u1ec1 c\u1eadp \u0111\u1ebfn nh\u1eefng n\u1ec1n t\u1ea3ng c\u01a1 b\u1ea3n c\u1ee7a Tr\u00ed tu\u1ec7 nh\u00e2n t\u1ea1o trong x\u1eed l\u00fd ti\u1ebfng n\u00f3i, \u0111\u1eb7c bi\u1ec7t l\u00e0 trong c\u00e1c b\u00e0i to\u00e1n \u0111\u00e1nh gi\u00e1 v\u00e0 ch\u1ea5m \u0111i\u1ec3 ph\u00e1t \u00e2m. M\u1ed9t s\u1ed1 n\u1ed9i dung s\u1ebd \u0111\u01b0\u1ee3c \u0111\u1ec1 c\u1eadp \u0111\u1ebfn:</p> <ul> <li>Gi\u1edbi thi\u1ec7u t\u1ed5ng quan v\u1ec1 h\u1ec7 th\u1ed1ng h\u1ed7 tr\u1ee3 h\u1ecdc ng\u00f4n ng\u1eef.</li> <li>C\u01a1 s\u1edf l\u00fd thuy\u1ebft c\u1ee7a x\u1eed l\u00fd ti\u1ebfng n\u00f3i.</li> <li>Tr\u00ecnh b\u00e0y, kh\u1ea3o s\u00e1t c\u00e1c c\u00f4ng tr\u00ecnh nghi\u00ean c\u1ee9u li\u00ean quan.</li> <li>T\u1ed5ng quan v\u1ec1 b\u00e0i to\u00e1n ch\u1ea5m \u0111i\u1ec3m ph\u00e1t \u00e2m.</li> </ul>"},{"location":"research/pronunciation-scoring/experiments/report01/#bai-toan-anh-gia-phat-am","title":"B\u00e0i to\u00e1n \u0111\u00e1nh gi\u00e1 ph\u00e1t \u00e2m","text":"<p>Trong b\u1ed1i c\u1ea3nh to\u00e0n c\u1ea7u h\u00f3a, vi\u1ec7c h\u1ecdc ngo\u1ea1i ng\u1eef tr\u1edf n\u00ean quan tr\u1ecdng h\u01a1n bao gi\u1edd h\u1ebft. S\u1ef1 ph\u00e1t tri\u1ec3n c\u1ee7a c\u00f4ng ngh\u1ec7 th\u00f4ng tin \u0111a th\u00fac \u0111\u1ea9y s\u1ef1 ph\u1ed5 bi\u1ebfn c\u1ee7a c\u00e1c h\u1ec7 th\u1ed1ng h\u1ecdc ngo\u1ea1i ng\u1eef c\u00f3 s\u1ef1 h\u1ed7 tr\u1ee3 c\u1ee7a m\u00e1y t\u00ednh (Computer Assisted Language Learning - CALL), cho ph\u00e9p ng\u01b0\u1eddi h\u1ecdc r\u00e8n luy\u1ec7n v\u00e0 ti\u1ebfn b\u1ed9 ngay c\u1ea3 khi kh\u00f4ng c\u00f3 gi\u00e1o vi\u00ean tr\u1ef1c ti\u1ebfp h\u01b0\u1edbng d\u1eabn. Trong s\u1ed1 \u0111\u00f3, c\u00e1c h\u1ec7 th\u1ed1ng luy\u1ec7n ph\u00e1t \u00e2m c\u00f3 s\u1ef1 h\u1ed7 tr\u1ee3 c\u1ee7a m\u00e1y t\u00ednh (Computer Aided Pronunciation Training - CAPT) n\u1ed5i b\u1eadt nh\u1edd kh\u1ea3 n\u0103ng h\u1ed7 tr\u1ee3 c\u1ea3i thi\u1ec7n ph\u00e1t \u00e2m - m\u1ed9t k\u1ef9 n\u0103ng v\u1ed1n kh\u00f3 luy\u1ec7n t\u1eadp n\u1ebfu thi\u1ebfu gi\u1ea3ng vi\u00ean c\u00e1 nh\u00e2n.</p> <p>C\u00e1c h\u1ec7 th\u1ed1ng CAPT c\u00f3 th\u1ec3 \u0111\u00e1nh gi\u00e1 ch\u1ea5t l\u01b0\u1ee3ng ph\u00e1t \u00e2m \u1edf nhi\u1ec1u c\u1ea5p \u0111\u1ed9 kh\u00e1c nhau: c\u1ee5m t\u1eeb, t\u1eeb ho\u1eb7c \u00e2m v\u1ecb. Trong \u0111\u00f3, ch\u1ea5m \u0111i\u1ec3m ph\u00e1t \u00e2m \u1edf m\u1ee9c \u00e2m v\u1ecb l\u00e0 chi ti\u1ebft v\u00e0 th\u00e1ch th\u1ee9c nh\u1ea5t, b\u1edfi l\u01b0\u1ee3ng d\u1eef li\u1ec7u d\u00f9ng \u0111\u1ec3 \u0111\u00e1nh gi\u00e1 m\u1ed7i \u0111\u01a1n v\u1ecb \u00e2m thanh l\u00e0 r\u1ea5t nh\u1ecf. Tuy nhi\u00ean, m\u1ee9c \u0111\u1ed9 n\u00e0y l\u1ea1i \u0111\u1eb7c bi\u1ec7t h\u1eefu \u00edch cho ng\u01b0\u1eddi h\u1ecdc m\u1edbi, v\u00ec ch\u00fang cung c\u1ea5p th\u00f4ng tin chi ti\u1ebft h\u01a1n v\u00e0 ch\u1ec9 ra l\u1ed7i ph\u00e1t \u00e2m c\u1ee5 th\u1ec3 \u1edf t\u1eebng \u00e2m v\u1ecb, trong khi \u0111\u00e1nh gi\u00e1 \u1edf m\u1ee9c c\u1ee5m t\u1eeb ch\u1ec9 ph\u1ea3n \u00e1nh t\u1ed5ng quan.</p>"},{"location":"research/pronunciation-scoring/experiments/report01/#cac-nghien-cuu-lien-quan","title":"C\u00e1c nghi\u00ean c\u1ee9u li\u00ean quan","text":""},{"location":"research/pronunciation-scoring/experiments/report01/#goodness-of-pronunciation","title":"Goodness of Pronunciation","text":"<p>M\u1ed9t trong nh\u1eefng h\u1ec7 th\u1ed1ng \u0111\u00e1nh gi\u00e1 ph\u00e1t \u00e2m \u1edf m\u1ee9c phone s\u1edbm nh\u1ea5t \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 Goodness of Pronunciation (GOP), d\u1ef1a tr\u00ean c\u00e1c m\u00f4 h\u00ecnh Automatic Speech Recognition (ASR), v\u1ed1n \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 t\u1ef1 \u0111\u1ed9ng chuy\u1ec3n \u0111\u1ed5i l\u1eddi n\u00f3i th\u00e0nh v\u0103n b\u1ea3n. Khi ph\u01b0\u01a1ng ph\u00e1p GOP l\u1ea7n \u0111\u1ea7u \u0111\u01b0\u1ee3c \u0111\u1ec1 xu\u1ea5t, c\u00e1c m\u00f4 h\u00ecnh ASR ch\u1ee7 y\u1ebfu d\u1ef1a tr\u00ean Hidden Markov Models (HMM), trong \u0111\u00f3 m\u1ed7i phone \u0111\u01b0\u1ee3c hu\u1ea5n luy\u1ec7n v\u1edbi Gaussian Mixture Models (GMM) l\u00e0m h\u00e0m m\u1eadt \u0111\u1ed9 x\u00e1c su\u1ea5t \u0111\u1ec3 m\u00f4 t\u1ea3 s\u1ef1 ki\u1ec7n \u00e2m thanh.</p> <p>Ph\u01b0\u01a1ng ph\u00e1p GOP \u0111\u00e1nh gi\u00e1 ch\u1ea5t l\u01b0\u1ee3ng ph\u00e1t \u00e2m c\u1ee7a m\u1ed9t phone c\u1ee5 th\u1ec3 \\(p\\) b\u1eb1ng logarit c\u1ee7a x\u00e1c su\u1ea5t h\u1eadu nghi\u1ec7m \\(P(p | O(p))\\), t\u1ee9c l\u00e0 x\u00e1c xu\u1ea5t ng\u01b0\u1eddi n\u00f3i ph\u00e1t \u00e2m \u0111\u00fang phone \\(p\\) d\u1ef1a tr\u00ean quan s\u00e1t \u0111o\u1ea1n \u00e2m thanh \\(O(p)\\), sau \u0111\u00f3 chu\u1ea9n h\u00f3a theo \u0111\u1ed9 d\u00e0i (s\u1ed1 frame) c\u1ee7a phone.</p> \\[GOP(p) = \\log \\frac{P(p | O(p))}{NF(p)}\\] <p>\u00c1p d\u1ee5ng \u0111\u1ecbnh l\u00fd Bayes, \u0111i\u1ec3m s\u1ed1 n\u00e0y c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c \u01b0\u1edbc l\u01b0\u1ee3ng th\u00f4ng qua x\u00e1c su\u1ea5t kh\u1ea3 n\u0103ng x\u1ea3y ra \\(p(O(p) | p)\\) \u0111\u01b0\u1ee3c t\u00ednh t\u1eeb m\u00f4 h\u00ecnh GMM-HMM \u0111\u00e3 n\u00eau. Khi \u0111\u00f3, c\u00f4ng th\u1ee9c GOP tr\u1edf th\u00e0nh:</p> \\[ GOP(p) = \\left( \\log \\frac{p(O(p)|p) \\cdot P(p)}{\\sum_{q\\in Q} p(O(p)|q) \\cdot P(q)} \\right) \\Bigg/ NF(p) \\] <p>Trong \u0111\u00f3:</p> <ul> <li>\\(Q\\) l\u00e0 t\u1eadp h\u1ee3p t\u1ea5t c\u1ea3 c\u00e1c phone</li> <li>\\(NF(p)\\) l\u00e0 s\u1ed1 frame m\u00e0 phone \\(p\\) chi\u1ebfm</li> <li>\\(p(O(p) | p)\\) \u1edf t\u1eed s\u1ed1 \u0111\u01b0\u1ee3c x\u00e1c \u0111\u1ecbnh b\u1eb1ng c\u00e1ch c\u0103n ch\u1ec9nh transcription \u0111\u00e3 bi\u1ebft v\u1edbi b\u1ea3n ghi \u00e2m th\u00f4ng qua thu\u1eadt to\u00e1n Viterbi, s\u1eed d\u1ee5ng m\u00f4 h\u00ecnh GMM-HMM</li> <li>\\(p(O(p) | q)\\) \u1edf m\u1eabu s\u1ed1 c\u0169ng \u0111\u01b0\u1ee3c t\u00ednh t\u1eeb m\u00f4 h\u00ecnh GMM-HMM, nh\u01b0ng kh\u00f4ng b\u1ecb r\u00e0ng bu\u1ed9c b\u1edfi transcription n\u00e0o c\u1ea3</li> </ul> <p>C\u00f3 th\u1ec3 hi\u1ec3u, \u0111i\u1ec3m GOP nh\u01b0 m\u1ed9t th\u01b0\u1edbc \u0111o m\u1ee9c \u0111\u1ed9 t\u1ef1 tin c\u1ee7a m\u00f4 h\u00ecnh ASR khi d\u1ef1 \u0111o\u00e1n m\u1ed9t phone. Phone n\u00e0o \u0111\u01b0\u1ee3c ph\u00e1t \u00e2m c\u00e0ng g\u1ea7n v\u1edbi chu\u1ea9n c\u1ee7a ng\u01b0\u1eddi b\u1ea3n ng\u1eef th\u00ec x\u00e1c su\u1ea5t c\u1ee7a phone \u0111\u00f3 c\u00e0ng cao, do \u0111\u00f3 GOP c\u0169ng c\u00e0ng l\u1edbn. V\u00ec GOP l\u00e0 log-likelihood n\u00ean n\u1ebfu likelihood b\u1eb1ng 1 th\u00ec GOP s\u1ebd b\u1eb1ng 0, n\u1ebfu likelihood nh\u1ecf h\u01a1n m\u1ed9t th\u00ec GOP s\u1ebd nh\u1ecf h\u01a1n 0.</p> <p>\u0110\u1ec3 \u0111\u01a1n gi\u1ea3n h\u00f3a c\u00f4ng th\u1ee9c tr\u00ean c\u00f3 th\u1ec3 x\u1ea5p x\u1ec9 t\u1ed5ng \u1edf m\u1eabu s\u1ed1 b\u1eb1ng gi\u00e1 tr\u1ecb l\u1edbn nh\u1ea5t, gi\u00fap t\u00ednh to\u00e1n nhanh h\u01a1n. Ho\u1eb7c gi\u1ea3 s\u1eed t\u1ea5t c\u1ea3 c\u00e1c phone trong t\u1eadp c\u00f3 x\u00e1c su\u1ea5t ti\u00ean nghi\u1ec7m b\u1eb1ng nhau, khi \u0111\u00f3 c\u00e1c x\u00e1c su\u1ea5t n\u00e0y s\u1ebd tri\u1ec7t ti\u00eau l\u1eabn nhau. V\u1edbi c\u00e1c \u0111i\u1ec1u ch\u1ec9nh n\u00e0y, c\u00f4ng th\u1ee9c GOP c\u00f3 th\u1ec3 vi\u1ebft \u0111\u01a1n gi\u1ea3n h\u01a1n:</p> \\[ \\left( GOP(p) = \\log \\frac{p(O(p)| p)}{\\max_{q \\in Q} p(O(p) | q)} \\right) \\Bigg/ NF(p) \\] <p>C\u00f4ng th\u1ee9c GOP ng\u1ea7m m\u00f4 t\u1ea3 r\u1eb1ng sau khi c\u00e1c \u0111\u1eb7c tr\u01b0ng \u00e2m thanh \u0111\u01b0\u1ee3c \u0111\u01b0a v\u00e0o m\u00f4 h\u00ecnh GMM-HMM, m\u00f4 h\u00ecnh s\u1ebd t\u00ednh x\u00e1c su\u1ea5t c\u1ee7a t\u1eebng phone d\u1ef1a tr\u00ean c\u00e1c frame t\u01b0\u01a1ng \u1ee9ng. \u0110i\u1ec3m GOP c\u1ee7a m\u1ed9t phone \\(p\\) \u0111\u01b0\u1ee3c x\u00e1c \u0111\u1ecbnh b\u1eb1ng c\u00e1ch so s\u00e1nh x\u00e1c su\u1ea5t c\u1ee7a phone \u0111\u00f3 v\u1edbi x\u00e1c su\u1ea5t c\u1ee7a t\u1ea5t c\u1ea3 c\u00e1c phone kh\u00e1c: n\u1ebfu m\u1ed9t phone \\(q\\) kh\u00e1c c\u00f3 x\u00e1c su\u1ea5t cao h\u01a1n phone \\(p\\) th\u00ec GOP c\u1ee7a \\(p\\) s\u1ebd th\u1ea5p, ph\u1ea3n \u00e1nh r\u1eb1ng m\u00f4 h\u00ecnh kh\u00f4ng ch\u1eafc ch\u1eafn v\u1ec1 ph\u00e1t \u00e2m c\u1ee7a phone \\(p\\); ng\u01b0\u1ee3c l\u1ea1i, n\u1ebfu x\u00e1c su\u1ea5t c\u1ee7a phone \\(p\\) cao nh\u1ea5t, GOP s\u1ebd cao, cho th\u1ea5y ph\u00e1t \u00e2m g\u1ea7n chu\u1ea9n c\u1ee7a ng\u01b0\u1eddi b\u1ea3n ng\u1eef.</p>"},{"location":"research/pronunciation-scoring/experiments/report01/#deep-neural-networks","title":"Deep Neural Networks","text":"<p>Trong nh\u1eefng n\u0103m g\u1ea7n \u0111\u00e2y, s\u1ef1 ph\u00e1t tri\u1ec3n m\u1ea1nh m\u1ebd c\u1ee7a m\u1ea1ng n\u01a1-ron s\u00e2u (Deep Networks - DNNs) \u0111\u00e3 t\u1ea1o ra nh\u1eefng b\u01b0\u1edbc ti\u1ebfn l\u1edbn trong nhi\u1ec1u l\u0129nh v\u1ef1c c\u1ee7a tr\u00ed tu\u1ec7 nh\u00e2n t\u1ea1o, trong ddso c\u00f3 nh\u1eadn d\u1ea1ng ti\u1ebfng n\u00f3i t\u1ef1 \u0111\u1ed9ng (ASR - Automation Speech Recognition) . Do c\u00e1c h\u1ec7 th\u1ed1ng ch\u1ea5m \u0111i\u1ec3m ph\u00e1t \u00e2m ph\u1ea7n l\u1edbn d\u1ef1a v\u00e0o c\u00f4ng ngh\u1ec7 ASR, nh\u1eefng ti\u1ebfn b\u1ed9 n\u00e0y nhanh ch\u00f3ng \u0111\u01b0\u1ee3c \u1ee9ng d\u1ee5ng \u0111\u1ec3 c\u1ea3i thi\u1ec7n ch\u1ea5t l\u01b0\u1ee3ng \u0111\u00e1nh gi\u00e1 ph\u00e1t \u00e2m, v\u01b0\u1ee3t tr\u1ed9i so v\u1edbi c\u00e1c ph\u01b0\u01a1ng phap truy\u1ec1n th\u1ed1ng c\u1ea3 khi s\u1eed d\u1ee5ng d\u1eef li\u1ec7u b\u1ea3n ng\u1eef l\u1eabn d\u1eef li\u1ec7u ng\u01b0\u1eddi h\u1ecdc.</p> <p>M\u1ed9t trong nh\u1eefng ph\u01b0\u01a1ng ph\u00e1p c\u01a1 b\u1ea3n th\u01b0\u1eddng \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng l\u00e0m chu\u1ea9n so s\u00e1nh l\u00e0 Goodness of Pronunciation. Phi\u00ean b\u1ea3n g\u1ed1c c\u1ee7a GOP d\u1ef1a tr\u00ean m\u00f4 h\u00ecnh GMM-HMM, trong \u0111\u00f3 x\u00e1c su\u1ea5t h\u1eadu nghi\u1ec7m c\u1ee7a m\u1ed9t \u00e2m v\u1ecb \\(P(p | O(p))\\) \u0111\u01b0\u1ee3c suy ra t\u1eeb x\u00e1c su\u1ea5t \u0111i\u1ec1u ki\u1ec7n \\(p(O(p) | p)\\) th\u00f4ng qua \u0111\u1ecbnh l\u00fd Bayes. C\u00e1ch ti\u1ebfp c\u1eadn n\u00e0y tuy hi\u1ec7u qu\u1ea3 \u1edf th\u1eddi \u0111i\u1ec3m ban \u0111\u1ea7u nh\u01b0ng ph\u1ee5 thu\u1ed9c n\u1eb7ng n\u1ec1 v\u00e0o vi\u1ec7c \u01b0\u1edbc l\u01b0\u1ee3ng x\u00e1c su\u1ea5t b\u1eb1ng m\u00f4 h\u00ecnh GMM truy\u1ec1n th\u1ed1ng, v\u1ed1n c\u00f3 h\u1ea1n ch\u1ebf trong vi\u1ec7c bi\u1ec3u di\u1ec5n d\u1eef li\u1ec7u ph\u1ee9c t\u1ea1p. V\u1edbi s\u1ef1 xu\u1ea5t hi\u1ec7n c\u1ee7a DNN, ph\u01b0\u01a1ng ph\u00e1p GOP \u0111\u00e3 \u0111\u01b0\u1ee3c m\u1edf r\u1ed9ng sang d\u1ea1ng DNN-HMM, trong \u0111\u00f3 m\u00f4 h\u00ecnh n\u01a1-ron c\u00f3 th\u1ec3 d\u1ef1 \u0111o\u00e1n tr\u1ef1c ti\u1ebfp ph\u00e2n b\u1ed1 x\u00e1c su\u1ea5t h\u1eadu nghi\u1ec7m c\u1ee7a c\u00e1c tr\u1ea1ng th\u00e1i HMM d\u1ef1a tr\u00ean c\u00e1c \u0111\u1eb7c tr\u01b0ng \u00e2m h\u1ecdc \u0111\u1ea7u v\u00e0o. \u0110i\u1ec1u n\u00e0y gi\u00fap lo\u1ea1i b\u1ecf nhu c\u1ea7u s\u1eed d\u1ee5ng \u0111\u1ecbnh l\u00fd Bayes, \u0111\u1ed3ng th\u1eddi t\u1eadn d\u1ee5ng \u0111\u01b0\u1ee3c kh\u1ea3 n\u0103ng h\u1ecdc bi\u1ec3u di\u1ec5n m\u1ea1nh m\u1ebd c\u1ee7a DNN. K\u1ef9 thu\u1eadt n\u00e0y th\u01b0\u1eddng \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 DNN-GOP v\u00e0 \u0111\u00e3 tr\u1edf th\u00e0nh m\u1ed9t baseline ph\u1ed5 bi\u1ebfn trong c\u00e1c nghi\u00ean c\u1ee9u sau n\u00e0y.</p> <p>Tuy nhi\u00ean, m\u1ed9t trong nh\u1eefng th\u00e1ch th\u1ee9c l\u1edbn trong vi\u1ec7c x\u00e2y d\u1ef1ng h\u1ec7 th\u1ed1ng ch\u1ea5m \u0111i\u1ec3m ph\u00e1t \u00e2m ch\u00ednh l\u00e0 t\u00ecnh tr\u1ea1ng khan hi\u1ebfm d\u1eef li\u1ec7u. D\u1eef li\u1ec7u c\u1ee7a ng\u01b0\u1eddi h\u1ecdc (non-native data) v\u1eeba kh\u00f3 thu th\u1eadp, v\u1eeba t\u1ed1n k\u00e9m trong kh\u00e2u g\u00e1n nh\u00e3n, trong khi c\u00e1c m\u00f4 h\u00ecnh ch\u1ec9 hu\u1ea5n luy\u1ec7n tr\u00ean d\u1eef li\u1ec7u ng\u01b0\u1eddi b\u1ea3n ng\u1eef l\u1ea1i kh\u00f4ng ph\u1ea3n \u00e1nh \u0111\u1ea7y \u0111\u1ee7 nh\u1eefng l\u1ed7i ph\u00e1t \u00e2m ph\u1ed5 bi\u1ebfn trong th\u1ef1c t\u1ebf. \u0110\u1ec3 kh\u1eafc ph\u1ee5c h\u1ea1n ch\u1ebf n\u00e0y, nhi\u1ec1u nghi\u00ean c\u1ee9u g\u1ea7n \u0111\u00e2y \u0111\u00e3 khai th\u00e1c h\u1ecdc chuy\u1ec3n giao (transfer learning), t\u1ee9c l\u00e0 t\u1eadn d\u1ee5ng tri th\u1ee9c t\u1eeb c\u00e1c m\u00f4 h\u00ecnh \u0111\u00e3 \u0111\u01b0\u1ee3c hu\u1ea5n luy\u1ec7n tr\u01b0\u1edbc tr\u00ean m\u1ed9t t\u00e1c v\u1ee5 ngu\u1ed3n, r\u1ed3i tinh ch\u1ec9nh (fine-tune) cho t\u00e1c v\u1ee5 \u0111\u00edch. C\u00e1ch ti\u1ebfp c\u1eadn n\u00e0y \u0111\u1eb7c bi\u1ec7t hi\u1ec7u qu\u1ea3 trong b\u1ed1i c\u1ea3nh d\u1eef li\u1ec7u h\u1ea1n ch\u1ebf, v\u00ec cho ph\u00e9p k\u1ebf th\u1eeba c\u00e1c \u0111\u1eb7c tr\u01b0ng \u0111\u00e3 h\u1ecdc t\u1eeb t\u1eadp d\u1eef li\u1ec7u quy m\u00f4 l\u1edbn m\u00e0 kh\u00f4ng c\u1ea7n x\u00e2y d\u1ef1ng l\u1ea1i to\u00e0n b\u1ed9 m\u00f4 h\u00ecnh t\u1eeb \u0111\u1ea7u.</p> <p>Song song v\u1edbi \u0111\u00f3, c\u00e1c k\u1ef9 thu\u1eadt h\u1ecdc t\u1ef1 gi\u00e1m s\u00e1t (self-supervised learning) \u0111\u00e3 n\u1ed5i l\u00ean nh\u01b0 m\u1ed9t h\u01b0\u1edbng \u0111i \u0111\u1ea7y h\u1ee9a h\u1eb9n. Thay v\u00ec ph\u1ee5 thu\u1ed9c v\u00e0o d\u1eef li\u1ec7u c\u00f3 nh\u00e3n, c\u00e1c m\u00f4 h\u00ecnh t\u1ef1 gi\u00e1m s\u00e1t \u0111\u01b0\u1ee3c hu\u1ea5n luy\u1ec7n tr\u00ean m\u1ed9t l\u01b0\u1ee3ng d\u1eef li\u1ec7u kh\u1ed5ng l\u1ed3 kh\u00f4ng g\u00e1n nh\u00e3n, th\u00f4ng qua c\u00e1c nhi\u1ec7m v\u1ee5 ti\u1ec1n hu\u1ea5n luy\u1ec7n (pretext tasks) nh\u01b0 d\u1ef1 \u0111o\u00e1n khung \u00e2m thanh b\u1ecb che khu\u1ea5t ho\u1eb7c t\u00e1i t\u1ea1o t\u00edn hi\u1ec7u gi\u1ecdng n\u00f3i. Khi \u00e1p d\u1ee5ng cho m\u1ed9t b\u00e0i to\u00e1n c\u1ee5 th\u1ec3, nh\u1eefng m\u00f4 h\u00ecnh \u0111\u00e3 \u0111\u01b0\u1ee3c hu\u1ea5n luy\u1ec7n theo c\u00e1ch n\u00e0y ch\u1ec9 c\u1ea7n tinh ch\u1ec9nh b\u1eb1ng m\u1ed9t l\u01b0\u1ee3ng nh\u1ecf d\u1eef li\u1ec7u c\u00f3 nh\u00e3n nh\u01b0ng v\u1eabn \u0111\u1ea1t \u0111\u01b0\u1ee3c hi\u1ec7u qu\u1ea3 cao, th\u1eadm ch\u00ed v\u01b0\u1ee3t tr\u1ed9i so v\u1edbi c\u00e1c ph\u01b0\u01a1ng ph\u00e1p hu\u1ea5n luy\u1ec7n truy\u1ec1n th\u1ed1ng.</p> <p>T\u1eeb nh\u1eefng nghi\u00ean c\u1ee9u tr\u00ean c\u00f3 th\u1ec3 r\u00fat ra hai xu h\u01b0\u1edbng ch\u00ednh. Th\u1ee9 nh\u1ea5t, c\u00e1c m\u00f4 h\u00ecnh DNN-GOP \u0111\u00e3 ch\u1ee9ng minh \u01b0u th\u1ebf v\u01b0\u1ee3t tr\u1ed9i so v\u1edbi ph\u01b0\u01a1ng ph\u00e1p GMM-HMM truy\u1ec1n th\u1ed1ng trong vi\u1ec7c \u01b0\u1edbc l\u01b0\u1ee3ng x\u00e1c s\u00fa\u00e2t h\u1eadu nghi\u1ec7m ph\u1ee5c v\u1ee5 ch\u1ea5m \u0111i\u1ec3m ph\u00e1t \u00e2m. Th\u1ee9 hai, vi\u1ec7c \u00e1p d\u1ee5ng h\u1ecdc chuy\u1ec3n giao cho ph\u00e9p c\u00e1c h\u1ec7 th\u00f3ng \u0111\u1ea1t hi\u1ec7u qu\u1ea3 cao h\u01a1n trong \u0111i\u1ec1u ki\u1ec7n d\u1eef li\u1ec7u khan hi\u1ebfm, \u0111\u1ed3ng th\u1eddi gi\u1ea3m chi ph\u00ed hu\u1ea5n luy\u1ec7n. </p> <p>H\u1ec7 th\u1ed1ng h\u1ed7 tr\u1ee3 h\u1ecdc ng\u00f4n ng\u1eef b\u1eb1ng m\u00e1y t\u00ednh (Computer-Assisted Language Learing - CALL) mang l\u1ea1i nhi\u1ec1u l\u1ee3i \u00edch thi\u1ebft th\u1ef1c trong gi\u00e1o d\u1ee5c, \u0111\u1eb7c bi\u1ec7t l\u00e0 \u0111\u1ed1i v\u1edbi gi\u00e1o vi\u00ean v\u00e0 h\u1ecdc sinh. Nh\u1eefng h\u1ec7 th\u1ed1ng n\u00e0y cho ph\u00e9p cung c\u1ea5p ph\u1ea3n h\u1ed3i li\u00ean t\u1ee5c cho ng\u01b0\u1eddi h\u1ecdc m\u00e0 kh\u00f4ng c\u1ea7n s\u1ef1 gi\u00e1m s\u00e1t th\u01b0\u1eddng tr\u1ef1c c\u1ee7a gi\u00e1o vi\u00ean, h\u1ed7 tr\u1ee3 vi\u1ec7c t\u1ef1 h\u1ecdc, khuy\u1ebfn kh\u00edch s\u1eed d\u1ee5ng ng\u00f4n ng\u1eef m\u1ed9t c\u00e1ch t\u01b0\u01a1ng t\u00e1c thay v\u00ec ph\u1ee5 thu\u1ed9c v\u00e0o c\u00e1c ph\u01b0\u01a1ng ph\u00e1p h\u1ecdc truy\u1ec1n th\u1ed1ng nh\u01b0 h\u1ecdc thu\u1ed9c l\u00f2ng hay ghi ch\u00e9p. B\u00ean c\u1ea1nh \u0111\u00f3, CALL c\u0169ng g\u00f3p ph\u1ea7n \u0111\u01a1n gi\u1ea3n h\u00f3a v\u00e0 t\u1ef1 \u0111\u1ed9ng h\u00f3a c\u00e1c quy tr\u00ecnh \u0111\u00e1nh gi\u00e1 n\u0103ng l\u1ef1c ng\u00f4n ng\u1eef.</p> <p>M\u1ed9t trong nh\u1eefng th\u00e0nh ph\u1ea7n c\u1ed1t l\u00f5i v\u00e0 \u0111\u1ea7y th\u00e1c th\u1ee9c trong h\u1ec7 th\u00f4ng CALL l\u00e0 ch\u1ea5m \u0111i\u1ec3m ph\u00e1t \u00e2m (Pronuncation Scoring). \u0110\u00e2y l\u00e0 nhi\u1ec7m v\u1ee5 quan tr\u1ecdng nh\u1eb1m \u0111\u00e1nh gi\u00e1 m\u1ee9c \u0111\u1ed9 ch\u0129nh x\u00e1c trong c\u00e1c ph\u00e1t \u00e2m c\u1ee7a ng\u01b0\u1eddi h\u1ecdc so v\u1edbi chu\u1ea9n c\u1ee7a ng\u01b0\u1eddi b\u1ea3n ng\u1eef. H\u1ec7 th\u1ed1ng ch\u1ea7m \u0111i\u1ec3m ph\u00e1t \u00e2m hi\u1ec7u qu\u1ea3 kh\u00f4ng ch\u1ec9 gi\u00fap ph\u00e1t hi\u1ec7n v\u00e0 s\u1eeda l\u1ed7i k\u1ecbp th\u1eddi m\u00e0 c\u00f2n cung c\u1ea5p ph\u1ea3n h\u1ed3i mang t\u00ednh d\u00e0i h\u1ea1n v\u1ec1 n\u0103ng l\u1ef1c ph\u00e1t \u00e2m c\u1ee7a ng\u01b0\u1eddi h\u1ecdc.</p> <p>Trong nhi\u1ec1u n\u0103m qua, \u0111\u00e3 c\u00f3 r\u1ea5t nhi\u1ec1u c\u00e1c nghi\u00ean c\u1ee9u, h\u01b0\u1edbng ti\u1ebfp c\u1eadn ch\u00ednh nh\u01b0:</p> <ul> <li> <p>Ph\u01b0\u01a1ng ph\u00e1p d\u1ef1a tr\u00ean m\u00f4 h\u00ecnh nh\u1eadn d\u1ea1ng ti\u1ebfng n\u00f3i (ASR-based methods): \u0110\u00e2y l\u00e0 m\u1ed9t trong nh\u1eefng ph\u01b0\u01a1ng ph\u00e1p c\u1ed5 \u0111i\u1ec3n v\u00e0 r\u1ea5t ph\u1ed5 bi\u1ebfn, trong \u0111\u00f3 h\u1ec7 th\u1ed1ng nh\u1eadn d\u1ea1ng gi\u1ecdng n\u00f3i th\u01b0\u1eddng s\u1eed d\u1ee5ng m\u00f4 h\u00ecnh Markov \u1ea9n (Hidden Markow Model) nh\u1eb1m so s\u00e1nh ph\u00e1t \u00e2m c\u1ee7a ng\u01b0\u1eddi h\u1ecdc v\u1edbi c\u00e1c m\u00f4 h\u00ecnh \u00e2m h\u1ecdc chu\u1ea9n. M\u1ed9t trong nh\u1eefng k\u1ef9 thu\u1eadt n\u1ed5i b\u1eadt l\u00e0 thu\u1eadt to\u00e1n Goodness of Pronunciation (GOP) cho ph\u00e9p t\u00ednh \u0111i\u1ec3m ph\u00e1t \u00e2m \u1edf c\u1ea5p \u0111\u1ed9 \u00e2m v\u1ecb (phone-level).</p> </li> <li> <p>\u0110\u00e1nh gi\u00e1 d\u1ef1a tr\u00ean so s\u00e1nh v\u1edbi m\u1eabu ng\u01b0\u1eddi b\u1ea3n ng\u1eef (Template-based / Reference-based methods): C\u00e1c ph\u01b0\u01a1ng ph\u00e1p n\u00e0y so s\u00e1nh tr\u1ef1c ti\u1ebfp t\u00edn hi\u1ec7u \u00e2m thanh c\u1ee7a ng\u01b0\u1eddi h\u1ecdc v\u1edbi b\u1ea3n ghi \u00e2m t\u1eeb ng\u01b0\u1eddi b\u1ea3n ng\u1eef. Ch\u00fang th\u01b0\u1eddng y\u00eau c\u1ea7u d\u1eef li\u1ec7u hu\u1ea5n luy\u1ec7n ri\u00eang cho t\u1eebng t\u1eeb ho\u1eb7c c\u1ee5m t\u1eeb, khi\u1ebfn h\u1ec7 th\u1ed1ng tr\u1edf n\u00ean text-dependent v\u00e0 r\u1ea5t kh\u00f3 \u0111\u1ec3 c\u00f3 th\u1ec3 m\u1edf r\u1ed9ng.</p> </li> <li> <p>M\u00f4 h\u00ecnh h\u1ecdc m\u00e1y v\u00e0 h\u1ecdc s\u00e2u (Machine Learning / Deep Learning-based methods): G\u1ea7n \u0111\u00e2y, c\u00e1c m\u00f4 h\u00ecnh h\u1ecdc s\u00e2u nh\u01b0 CNN, RNN v\u00e0 \u0111\u1eb7c bi\u1ec7t l\u00e0 c\u00e1c m\u00f4 h\u00ecnh transformer-based (wav2vec, HuBERT, v.v.) \u0111\u01b0\u1edbc s\u1eed d\u1ee5ng \u0111\u1ec3 tr\u00edch xu\u1ea5t \u0111\u1eb7c tr\u01b0ng \u00e2m h\u1ecdc v\u00e0 x\u00e2y d\u1ef1ng b\u1ed9 ch\u1ea5m \u0111i\u1ec3m ph\u00e1t \u00e2m m\u00e0 kh\u00f4ng c\u1ea7n ph\u1ea3i ph\u1ee5 thu\u1ed9c ho\u00e0n to\u00e1n v\u00e0o pipeline c\u1ee7a h\u1ec7 th\u1ed1ng nh\u1eadn d\u1ea1ng truy\u1ec1n th\u1ed1ng.</p> </li> </ul> <p>Ngo\u00e0i ra, c\u00e1c nghi\u00ean c\u1ee9u kh\u00e1c c\u0169ng khai th\u00e1c tri\u1ec7t \u0111\u1ec3 nh\u1eefng y\u1ebfu t\u1ed1 \u0111\u1eb7c tr\u01b0ng c\u1ee7a \u00e2m thanh nh\u01b0 tr\u01b0\u1eddng \u0111\u1ed9, ng\u1eef \u0111i\u1ec7u, v.v, nh\u1eb1m \u0111\u00e1nh gi\u00e1 ch\u1ea5t l\u01b0\u1ee3ng ph\u00e1t \u00e2m m\u1ed9t c\u00e1ch to\u00e1n di\u1ec7n h\u01a1n. Tuy nhi\u00ean, ch\u00fang v\u1ea5n \u0111ang g\u1eb7p ph\u1ea3i r\u1ea5t nhi\u1ec1u nh\u1eefng th\u00e1ch th\u1ee9c li\u00ean quan \u0111\u1ebfn s\u1ef1 ph\u1ee5 thu\u1ed9c v\u00e0o d\u1eef li\u1ec7u, s\u1ef1 nh\u1ea5t qu\u00e1t v\u00e0 c\u00f4ng b\u1eb1ng trong \u0111\u00e1nh gi\u00e1 v\u00e0 s\u1ef1 th\u00edch nghi khi d\u1eef li\u1ec7u gi\u1ecdng n\u00f3i \u0111a d\u1ea1ng. </p>"},{"location":"research/pronunciation-scoring/experiments/report01/#2-mot-so-phuong-phap-noi-bat","title":"2. M\u1ed9t s\u1ed1 ph\u01b0\u01a1ng ph\u00e1p n\u1ed5i b\u1eadt","text":""},{"location":"research/pronunciation-scoring/experiments/report01/#21-goodness-of-pronuncation","title":"2.1 Goodness of Pronuncation","text":"<p>GOP (Goodness of Pronunciation) l\u00e0 ph\u01b0\u01a1ng ph\u00e1p l\u00e0 m\u1ed9t trong nh\u1eefng k\u1ef9 thu\u1eadt n\u1ed5i b\u1eadt, v\u1edbi m\u1ee5c ti\u00eau \u0111o l\u01b0\u1eddng m\u1ee9c \u0111\u1ed9 kh\u1edbp gi\u1eefa ph\u00e1t \u00e2m c\u1ee7a ng\u01b0\u1eddi h\u1ecdc v\u00e0 c\u00e1ch ph\u00e1t \u00e2m chu\u1ea9n c\u1ee7a ng\u01b0\u1eddi b\u1ea3n ng\u1eef, t\u00ednh t\u1ea1i m\u1ee9c \u00e2m v\u1ecb (phone-level). G\u1ec9a s\u1eed khi ch\u00fang ta ph\u00e1t \u00e2m t\u1eeb cat n\u00f3 s\u1ebd c\u00f3 hai \u00e2m v\u1ecb l\u00e0 /ka/ v\u00e0 /et/. GOP s\u1ebd ch\u1ea5m \u0111i\u1ec3m xem ng\u01b0\u1eddi d\u00f9ng \u0111\u00e3 ph\u00e1t \u00e2m /ka/ t\u1ed1t \u0111\u1ebfn \u0111\u00e2u v\u00e0 /et/ t\u1ed1t \u0111\u1ebfn \u0111\u00e2u. </p> <p>C\u00f4ng th\u1ee9c GOP</p> \\[ \\textbf{GOP} = \\frac{1}{NF_\\text{(p)}} \\cdot \\left| \\text{log} \\left( \\frac{p(O^\\text{(p)}) | p}{\\max_{q \\in \\mathbf{Q}} p(O^\\text{(p)}) | q} \\right) \\right| \\] <p>Trong \u0111\u00f3:</p> <ul> <li> <p>T\u1eed s\u1ed1 \\(p(O^\\text{(p)}) | p\\): \u0110\u00e2y l\u00e0 kh\u1ea3 n\u0103ng \u0111o\u1ea1n \u00e2m thanh \\(O(p)\\) \u0111\u01b0\u1ee3c t\u1ea1o ra b\u1edfi \u0111\u00fang \u00e2m v\u1ecb \\(p\\). Ch\u00fang cho bi\u1ebft \u00e2m thanh th\u1ef1c t\u1ebf kh\u1edbp v\u1edbi \u00e2m v\u1ecb m\u00e0 ch\u00fang ta mong \u0111\u1ee3i nghe th\u1ea5y \u0111\u1ebfn m\u1ee9c n\u00e0o.</p> </li> <li> <p>M\u1eabu s\u1ed1 \\(\\max_{q \\in \\mathbf{Q}} p(O^\\text{(p)}) | q\\): \u0110\u00e2y l\u00e0 kh\u1ea3 n\u0103ng \u0111o\u1ea1n \u00e2m thanh \\(O(p)\\) \u0111\u01b0\u1ee3c t\u1ea1o ra b\u1edfi \u00e2m v\u1ecb kh\u1edbp t\u1ed1t nh\u1ea5t trong t\u1ea5t c\u1ea3 c\u00e1c \u00e2m v\u1ecb \\(q\\). Cho bi\u1ebft \u00e2m thanh th\u1ef1c t\u1ebf gi\u1ed1ng v\u1edbi \u00e2m v\u1ecb n\u00e0o nh\u1ea5t trong t\u1ea5t c\u1ea3 c\u00e1c \u00e2m v\u1ecb, b\u1ea5t k\u1ec3 \u0111\u00fang hay sai.</p> </li> </ul> <p>N\u1ebfu t\u1ef7 l\u1ec7 \\(\\frac{p(O^\\text{(p)}) | p}{\\max_{q \\in \\mathbf{Q}} p(O^\\text{(p)}) | q}\\) ti\u1ebfn \u0111\u1ebfn g\u1ea7n 1, c\u00f3 ngh\u0129a l\u00e0 \u00e2m v\u1ecb \u0111\u00edch kh\u1edbp r\u1ea5t t\u1ed1t, v\u00e0 kh\u00f4ng c\u00f3 \u00e2m v\u1ecb n\u00e0o kh\u00e1c kh\u1edbp t\u1ed1t h\u01a1n. \u0110i\u1ec1u n\u00e0y ch\u1ee9ng t\u1ecf ng\u01b0\u1eddi \u0111\u1ecdc \u0111\u00e3 ph\u00e1t \u00e2m r\u1ea5t t\u1ed1t. Ng\u01b0\u1ee3c l\u1ea1i, c\u00f3 ngh\u0129a l\u00e0 c\u00f3 m\u1ed9t ho\u1eb7c nhi\u1ec1u \u00e2m v\u1ecb kh\u00e1c kh\u1edbp v\u1edbi \u0111o\u1ea1n \u00e2m thanh \u0111\u00f3 h\u01a1n so v\u1edbi \u00e2m v\u1ecb \u0111\u00edch, \u0111\u1ed3ng ngh\u0129a v\u1edbi ng\u01b0\u1eddi d\u00f9ng ph\u00e1t \u00e2m ch\u01b0a chu\u1ea9n. </p> <p>H\u1ec7 th\u1ed1ng Pronunciation Scoring: </p> <p>S\u01a1 \u0111\u1ed3 kh\u1ed1i c\u1ee7a c\u01a1 ch\u1ebf ch\u1ea5m \u0111i\u1ec3m d\u1ef1a tr\u00ean ph\u01b0\u01a1ng ph\u00e1p GOP \u0111\u01b0\u1ee3c th\u1ec3 hi\u1ec7n nh\u01b0 trong h\u00ecnh. C\u1ee5 th\u1ec3 s\u1ebd tr\u1ea3i qua 4 giai \u0111o\u1ea1n:</p> <p></p> <p>H\u00ecnh 1.1: Bi\u1ec3u \u0111\u1ed3 minh h\u1ecda c\u00e1c th\u00e0nh ph\u1ea7n ch\u00ednh trong h\u1ec7 th\u1ed1ng ch\u1ea5m \u0111i\u1ec3m d\u1ef1a tr\u00ean ph\u01b0\u01a1ng ph\u00e1p GOP truy\u1ec1n th\u1ed1ng. </p> <ul> <li> <p>Front-end Feature Extraction: \u0110\u00e2y l\u00e0 giai \u0111o\u1ea1n \u0111\u1ea7u ti\u00ean, d\u1eef li\u1ec7u \u00e2m thanh \u0111\u1ea7u v\u00e0o \u0111\u01b0\u1ee3c x\u1eed l\u00fd \u0111\u1ec3 tr\u00edch xu\u1ea5t c\u00e1c \u0111\u1eb7c tr\u01b0ng quan tr\u1ecdng c\u1ee7a gi\u1ecdng n\u00f3i th\u01b0\u1eddng l\u00e0 MFCC (Mel-frequency Cepstral Coefficients). \u0110\u00e2y l\u00e0 c\u00e1ch bi\u1ec3u \u0111i\u1ec5n \u00e2m thanh d\u01b0\u1edbi d\u1ea1ng s\u1ed1.</p> </li> <li> <p>Two Recognition Pass: Ti\u1ebfp theo c\u00e1c transcipts v\u00e0 \u0111\u1eb7c tr\u01b0ng \u00e2m thanh t\u01b0\u01a1ng \u1ee9ng s\u1ebd tr\u1ea3i qua hai l\u01b0\u1ee3t nh\u1eadn d\u1ea1ng:</p> <ul> <li>Forced Alignment Pass: S\u1eed d\u1ee5ng b\u1ea3n ghi \u0111\u00e3 bi\u1ebft \u0111\u1ec3 \u00e9p c\u00e1c \u0111\u1eb7c tr\u01b0ng MFCC kh\u1edbp v\u1edbi chu\u1ed7i phone \u0111\u00fang (\u0111\u00e2y ch\u00ednh l\u00e0 vi\u1ec7c t\u00ednh to\u00e1n t\u1eed s\u1ed1 c\u1ee7a c\u00f4ng th\u1ee9c GOP). V\u00ed d\u1ee5 h\u1ec7 th\u1ed1ng nh\u1eadn \u0111\u1ea7u v\u00e0o t\u00edn hi\u1ec7u \u00e2m thanh c\u1ee7a ng\u01b0\u1eddi \u0111\u1ecdc l\u00e0 cat, h\u1ec7 th\u1ed1ng s\u1ebd s\u1eed d\u1ee5ng m\u1ed9t t\u1eeb \u0111i\u1ec3n ph\u00e1t \u00e2m (pronunciation dictionary), t\u1eeb \u0111i\u1ec3n n\u00e0y ch\u1ee9a c\u00e1ch ph\u00e1t \u00e2m chu\u1ea9n theo IPA c\u1ee7a m\u1ed7i t\u1eeb trong ng\u00f4n ng\u1eef. T\u1eeb cat s\u1ebd \u0111\u01b0\u1ee3c \u00e1nh x\u1ea1 th\u00e0nh chu\u1ed7i \u00e2m v\u1ecb chu\u1ea9n l\u00e0 /k/ /ae/ /t/. Sau \u0111\u00f3 qu\u00e1 tr\u00ecnh \u00e9p khung di\u1ec5n ra, giai \u0111o\u1ea1n n\u00e0y s\u1ebd x\u00e1c \u0111\u1ecbnh th\u1eddi \u0111i\u1ec3m b\u1eaft \u0111\u1ea7u v\u00e0 k\u1ebft th\u00fac c\u1ee7a t\u1eebng \u00e2m v\u1ecb trong l\u1eddi n\u00f3i c\u1ee7a ng\u01b0\u1eddi h\u1ecdc v\u00e0 \u0111\u1ed3ng th\u1eddi g\u00e1n cho m\u1ed7i \u0111o\u1ea1n \u00e2m thanh m\u1ed9t \u00e2m v\u1ecb \\(p\\) \u0111\u00fang theo b\u1ea3n ghi chu\u1ea9n. \u0110\u1ea7u ra c\u1ee7a giai \u0111o\u1ea1n n\u00e0y s\u1ebd c\u00f3 d\u1ea1ng:</li> </ul> example.json<pre><code>[\n    { \"phone\": \"/k/\", \"start_time\": 0.05, \"end_time\": 0.18 },\n    { \"phone\": \"/\u00e6/\", \"start_time\": 0.18, \"end_time\": 0.35 },\n    { \"phone\": \"/t/\", \"start_time\": 0.35, \"end_time\": 0.48 }\n]\n</code></pre> <ul> <li>Phone Recognition Pass: S\u1eed d\u1ee5ng m\u1ed9t \"phoneme loop\" \u0111\u1ec3 nh\u1eadn d\u1ea1ng \u0111o\u1ea1n \u00e2m thanh \\(O^{\\text{(p)}}\\) m\u00e0 kh\u00f4ng c\u00f3 r\u00e0ng bu\u1ed9c v\u1ec1 t\u1eeb v\u1ef1ng. Ch\u00fang t\u00ecm ra \u00e2m v\u1ecb n\u00e0o (trong t\u1ea5t c\u1ea3 c\u00e1c \u00e2m v\u1ecb c\u00f3 th\u1ec3 c\u00f3 trong ng\u00f4n ng\u1eef) kh\u1edbp t\u1ed1t nh\u1ea5t v\u1edbi \u0111o\u1ea1n \u00e2m thanh \u0111\u00f3 (t\u00ednh to\u00e1n m\u1eabu s\u1ed1 c\u1ee7a GOP).</li> </ul> </li> <li> <p>GOP scores: T\u00ednh to\u00e1n c\u00e1c \u0111i\u1ec3m GOP ri\u00eang l\u1ebb cho t\u1eebng phone d\u1ef1a tr\u00ean c\u00e1c k\u1ebft qu\u1ea3 thu \u0111\u01b0\u1ee3c t\u1eeb hai l\u01b0\u1ee3t nh\u1eadn d\u1ea1ng.</p> </li> <li> <p>Threshold: Sau khi c\u00f3 \u0111\u01b0\u1ee3c \u0111i\u1ec3m GOP cho m\u1ed7i phone, l\u1ef1a ch\u1ecdn m\u1ed9t ng\u01b0\u1ee1ng t\u00f9y ch\u1ec9nh nh\u1eb1m ph\u00e2n lo\u1ea1i, n\u1ebfu \u0111i\u1ec3m GOP c\u1ee7a m\u1ed9t phone th\u1ea5p h\u01a1n ng\u01b0\u1ee1ng th\u00ec \u00e2m \u0111\u00f3 \u0111\u01b0\u1ee3c coi l\u00e0 ph\u00e1t \u00e2m k\u00e9m v\u00e0 ng\u01b0\u1ee3c l\u1ea1i.</p> </li> </ul> <p>H\u1ea1n ch\u1ebf c\u1ee7a ph\u01b0\u01a1ng ph\u00e1p GOP:</p> <ul> <li> <p>Ph\u1ee5 thu\u1ed9c qu\u00e1 nhi\u1ec1u v\u00e0o Forced Alignment v\u00e0 HMM (Hidden Markov Model) truy\u1ec1n th\u1ed1ng. GOP ph\u1ee5 thu\u1ed9c ho\u00e0n to\u00e0n v\u00e0o \u0111\u1ed9 ch\u00ednh x\u00e1c c\u1ee7a qu\u00e1 tr\u00ecnh \u00e9p khung \u0111\u1ec3 x\u00e1c \u0111\u1ecbnh ranh gi\u1edbi c\u1ee7a t\u1eebng \u00e2m v\u1ecb v\u00e0 t\u00ednh to\u00e1n likelihood. N\u1ebfu qu\u00e1 tr\u00ecnh c\u0103n ch\u1ec9nh n\u00e0y kh\u00f4ng ch\u00ednh x\u00e1c s\u1ebd d\u1eabn \u0111\u1ebfn \u0111i\u1ec3m GOP kh\u00f4ng \u0111\u00e1ng tin c\u1eady.</p> </li> <li> <p>Kh\u00f4ng c\u00f3 m\u00f4 h\u00ecnh ri\u00eang bi\u1ec7t cho l\u1ed7i ph\u00e1t \u00e2m: GOP truy\u1ec1n th\u1ed1ng so s\u00e1nh \u00e2m thanh \u0111\u1ea7u v\u00e0o v\u1edbi m\u00f4 h\u00ecnh c\u1ee7a \u00e2m v\u1ecb \u0111\u00fang v\u00e0 t\u1ea5t c\u1ea3 c\u00e1c \u00e2m v\u1ecb kh\u00e1c trong ng\u00f4n ng\u1eef \u0111\u00edch. Tuy nhi\u00ean ch\u00fang b\u1ecf qua v\u00e0 kh\u00f4ng quan t\u00e2m \u0111\u1ebfn c\u00e1c lo\u1ea1i l\u1ed7i ph\u00e1t \u00e2m c\u1ee5 th\u1ec3 th\u01b0\u1eddng g\u1eb7p.</p> </li> <li> <p>Kh\u00f4ng xem x\u00e9t ng\u1eef c\u1ea3nh: GOP th\u01b0\u1eddng \u0111\u00e1nh gi\u00e1 t\u1eebng \u00e2m v\u1ecb m\u1ed9t c\u00e1ch t\u01b0\u01a1ng \u0111\u1ed1i \u0111\u1ed9c l\u1eadp. Ch\u00fang \u00edt khi x\u00e9t \u0111\u1ebfn ng\u1eef c\u1ea3nh \u00e2m v\u1ecb xung quanh ho\u1eb7c ng\u1eef c\u1ea3nh t\u1eeb/c\u00e2u, \u0111i\u1ec1u n\u00e0y c\u0169ng \u1ea3nh h\u01b0\u1edfng \u0111\u1ebfn c\u00e1ch ph\u00e1t \u00e2m v\u00e0 nh\u1eadn th\u1ee9c v\u1ec1 l\u1ed7i c\u1ee7a con ng\u01b0\u1eddi.</p> </li> </ul>"},{"location":"research/pronunciation-scoring/experiments/report01/#22-deep-neural-networks-based-gop","title":"2.2 Deep Neural Networks based GOP","text":"<p>C\u00e1c h\u1ec7 th\u1ed1ng ch\u1ea5m \u0111i\u1ec3m ph\u00e1t \u00e2m th\u01b0\u1eddng \u0111\u01b0\u1ee3c hu\u1ea5n luy\u1ec7n ch\u1ec9 v\u1edbi d\u1eef li\u1ec7u gi\u1ecdng n\u00f3i c\u1ee7a ng\u01b0\u1eddi b\u1ea3n x\u1ee9. Trong khi \u0111\u00f3, gi\u1ecdng n\u00f3i c\u1ee7a ng\u01b0\u1eddi h\u1ecdc ng\u00f4n ng\u1eef (phi b\u1ea3n x\u1ee9) l\u1ea1i c\u00f3 nhi\u1ec1u kh\u00e1c bi\u1ec7t, \u0111\u1eb7c bi\u1ec7t l\u00e0 khi h\u1ecd ph\u00e1t \u00e2m sai. Nhi\u1ec1u nghi\u00ean c\u1ee9u ch\u1ec9 ra r\u1eb1ng vi\u1ec7c hu\u1ea5n luy\u1ec7n h\u1ec7 th\u1ed1ng tr\u1ef1c ti\u1ebfp b\u1eb1ng d\u1eef li\u1ec7u gi\u1ecdng n\u00f3i c\u1ee7a ng\u01b0\u1eddi h\u1ecdc phi b\u1ea3n x\u1ee9 gi\u00fap cho h\u1ec7 th\u1ed1ng t\u1ed1t h\u01a1n. Tuy nhi\u00ean vi\u1ec7c thu th\u1eadp d\u1eef li\u1ec7u v\u00e0 g\u00e1n nh\u00e3n chi ti\u1ebft d\u1eef li\u1ec7u gi\u1ecdng n\u00f3i phi b\u1ea3n x\u1ee9 l\u00e0 m\u1ed9t th\u00e1ch th\u1ee9c l\u1edbn g\u00e2y t\u1ed1n k\u00e9m v\u00e0 m\u1ea5t th\u1eddi gian. Ph\u01b0\u01a1ng ph\u00e1p n\u00e0y \u0111\u01b0\u1ee3c ti\u1ebfp c\u1eadn d\u1ef1a tr\u00ean transfer learning DNN-based GOP \u0111\u1ec3 gi\u1ea3i quy\u1ebft nh\u1eefng th\u00e1ch th\u1ee9c n\u00e0y, c\u1ee5 th\u1ec3: </p> <ul> <li>T\u1eadn d\u1ee5ng m\u00f4 h\u00ecnh \u0111\u00e3 \u0111\u01b0\u1ee3c hu\u1ea5n luy\u1ec7n cho nhi\u1ec7m v\u1ee5 nh\u1eadn d\u1ea1ng gi\u1ecdng n\u00f3i tr\u00ean m\u1ed9t l\u01b0\u1ee3ng l\u1edbn d\u1eef li\u1ec7u ng\u01b0\u1eddi b\u1ea3n x\u1ee9.</li> <li>Tinh ch\u1ec9nh m\u00f4 h\u00ecnh \u0111\u00e3 \u0111\u01b0\u1ee3c hu\u1ea5n luy\u1ec7n tr\u01b0\u1edbc v\u1edbi l\u01b0\u1ee3ng nh\u1ecf d\u1eef li\u1ec7u phi b\u1ea3n x\u1ee9 c\u00f3 nh\u00e3n.</li> </ul> <p>M\u1edf r\u1ed9ng c\u00f4ng th\u1ee9c t\u00ednh GOP v\u1edbi DNN:</p> <p>So v\u1edbi ph\u01b0\u01a1ng ph\u00e1p t\u00ednh to\u00e1n GOP truy\u1ec1n th\u1ed1ng nh\u01b0 \u0111\u01b0\u1ee3c tr\u00ecnh b\u00e0y \u1edf (1), trong \u0111\u00f3 GOP \u0111\u01b0\u1ee3c t\u00ednh d\u1ef1a tr\u00ean c\u00e1c m\u00f4 h\u00ecnh \u00e2m h\u1ecdc GMM (Gausian Mixture Models). Trong nh\u1eefng n\u0103m g\u1ea7n \u0111\u00e2y, m\u1ed9t lo\u1ea1t c\u00e1c nghi\u00ean c\u1ee9u \u0111\u00e3 ch\u1ec9 ra nh\u1eefng c\u1ea3i thi\u1ec7n \u0111\u00e1ng k\u1ec3 khi s\u1eed d\u1ee5ng c\u00e1c m\u00f4 h\u00ecnh \u00e2m h\u1ecdc d\u1ef1a tr\u00ean DNN (Deep Neural Networks). DNN c\u00f3 kh\u1ea3 n\u0103ng h\u1ecdc v\u00e0 m\u00f4 h\u00ecnh h\u00f3a c\u00e1c \u0111\u1eb7c tr\u01b0ng \u00e2m thanh ph\u1ee9c t\u1ea1p t\u1ed1t h\u01a1n nhi\u1ec1u so v\u1edbi GMM.</p> <p>Khi s\u1eed d\u1ee5ng c\u00e1c m\u00f4 h\u00ecnh \u00e2m h\u1ecdc d\u1ef1a tr\u00ean DNN, \u0111i\u1ec3m GOP c\u1ee7a m\u1ed9t \u00e2m v\u1ecb \u0111\u00edch \\(p\\) b\u1eaft \u0111\u1ea7u t\u1eeb khung th\u1eddi gian \\(\\text{T}\\) v\u00e0 c\u00f3 \u0111\u1ed9 d\u00e0i \\(\\text{D}\\) \u0111\u01b0\u1ee3c t\u00ednh nh\u01b0 sau:</p> \\[ \\textbf{GOP}_{p} = -\\frac{1}{D} \\sum^{\\text{T+D-1}}_\\text{t=T} \\log P_{t}(p|O) \\] <p>Trong \u0111\u00f3:</p> <ul> <li>\\(\\text{D}\\) l\u00e0 \u0111\u1ed9 d\u00e0i c\u1ee7a \u00e2m v\u1ecb, t\u00ednh b\u1eb1ng s\u1ed1 l\u01b0\u1ee3ng khung th\u1eddi gian \\(p\\)</li> <li>\\(\\text{T}\\) l\u00e0 khung th\u1eddi gian b\u1eaft \u0111\u1ea7u c\u1ee7a \u00e2m v\u1ecb \\(p\\)</li> <li>\\(O\\) l\u00e0 to\u00e0n b\u1ed9 chu\u1ed7i \u0111\u1eb7c tr\u01b0ng, \u0111\u01b0\u1ee3c tr\u00ednh xu\u1ea5t t\u1eeb d\u1ea1ng s\u00f3ng \u00e2m sang c\u00e1c \u0111\u1eb7c tr\u01b0ng \u0111\u1ec3 c\u00f3 th\u1ec3 t\u00ednh to\u00e1n, \u0111\u1ea1i di\u1ec7n cho t\u1ea5t c\u1ea3 c\u00e1c d\u1eef li\u1ec7u \u00e2m thanh m\u00e0 m\u00f4 h\u00ecnh c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng</li> <li>\\(\\sum^{\\text{T+D-1}}_\\text{t=T}\\) t\u1ed5ng c\u00e1c gi\u00e1 tr\u1ecb cho t\u1ea5t c\u1ea3 c\u00e1c khung th\u1eddi gian t n\u1eb1m trong kho\u1ea3ng t\u1eeb khung b\u1eaft \u0111\u1ea7u \\(\\text{T}\\) \u0111\u1ebfn khung k\u1ebft th\u00fac \\(\\text{T + D - 1}\\) c\u1ee7a \u00e2m v\u1ecb \\(p\\).</li> <li>\\(\\log P_{t}(p|O)\\) l\u00e0 x\u00e1c xu\u1ea5t h\u00e2u nghi\u1ec7m c\u1ee7a \u00e2m v\u1ecb \\(p\\) t\u1ea1i khung th\u1eddi gian \\(t\\), v\u1edbi \u0111i\u1ec1u ki\u1ec7n l\u00e0 to\u00e0n b\u1ed9 chu\u1ed7i \u0111\u1eb7c tr\u01b0ng \u00e2m h\u1ecdc \\(O\\) \u0111\u00e3 \u0111\u01b0\u1ee3c quan s\u00e1t</li> </ul> <p>S\u1ef1 kh\u00e1c bi\u1ec7t l\u1edbn gi\u1eefa vi\u1ec7c t\u00ednh to\u00e1n gi\u1eefa GOP truy\u1ec1n th\u1ed1ng v\u00e0 GOP d\u1ef1a tr\u00ean DNN l\u00e0 vi\u1ec7c chuy\u1ec3n t\u1eeb likelihood sang posterior. C\u1ee5 th\u1ec3:</p> <ul> <li> <p>\u0110\u1ed1i v\u1edbi GOP truy\u1ec1n th\u1ed1ng: \u0110o\u1ea1n \u00e2m thanh \\(O^{(p)}\\) c\u1ee7a \u00e2m v\u1ecb \\(p\\) \u0111\u01b0\u1ee3c \u0111\u01b0a v\u00e0o m\u00f4 h\u00ecnh sinh (generative model) c\u1ee7a \u00e2m v\u1ecb \\(p\\). M\u00f4 h\u00ecnh n\u00e0y s\u1ebd t\u00ednh to\u00e1n kh\u1ea3 n\u0103ng ch\u00fang sinh ra \\(O^{(p)}\\).</p> </li> <li> <p>\u0110\u1ed1i v\u1edbi GOP d\u1ef1a tr\u00ean DNN: Thay v\u00ec t\u00ednh to\u00e1n t\u1ec9 l\u1ec7 gi\u1eefa c\u00e1c likelihood, m\u00f4 h\u00ecnh DNN tr\u1ef1c ti\u1ebfp \u0111\u01b0a ra x\u00e1c su\u1ea5t h\u1eadu nghi\u1ec7m \\(P_t(p|O)\\) cho \u00e2m v\u1ecb \\(p\\) t\u1ea1i m\u1ed7i khung th\u1eddi gian \\(t\\). </p> </li> </ul> <p>C\u1ea5u tr\u00fac m\u00f4 h\u00ecnh \u0111\u1ec1 xu\u1ea5t:</p> <p>Nh\u00ecn chung ph\u01b0\u01a1ng ph\u00e1p n\u00e0y c\u0169ng t\u01b0\u01a1ng t\u1ef1 nh\u01b0 GOP basline truy\u1ec1n th\u1ed1ng, c\u1ea3 hai \u0111\u1ec1u tu\u00e2n th\u1ee7 theo nhi\u1ec1u quy tr\u00ecnh ri\u00eang l\u1ebb, t\u1eeb vi\u1ec7c x\u1eed l\u00fd d\u1eef li\u1ec7u \u00e2m thanh cho \u0111\u1ebfn \u0111\u01b0a ra \u0111i\u1ec3m s\u1ed1 ph\u00e1t \u00e2m cho t\u1eebng \u00e2m v\u1ecb.</p> <p></p> <ul> <li> <p>Giai \u0111o\u1ea1n ti\u1ec1n x\u1eed l\u00fd v\u00e0 c\u0103n ch\u1ec9nh \u00e9p bu\u1ed9c (Forced Aligner): \u0110\u1ea7u v\u00e0o l\u00e0 m\u1ed9t t\u00edn hi\u1ec7u \u00e2m thanh (waveform) m\u00e0 ng\u01b0\u1eddi h\u1ecdc ph\u00e1t ra v\u00e0 b\u1ea3n ghi (transcipt) t\u01b0\u01a1ng \u1ee9ng. Sau \u0111\u00f3 v\u1eabn s\u1eed d\u1ee5ng b\u1ed9 c\u0103n ch\u1ec9nh \u00e9p bu\u1ed9c \u0111\u1ec3 x\u00e1c \u0111\u1ecbnh t\u00ednh ch\u00ednh x\u00e1c th\u1eddi \u0111i\u1ec3m b\u1eaft \u0111\u1ea7u v\u00e0 k\u1ebft th\u00fac c\u1ee7a t\u1eebng \u00e2m v\u1ecb trong l\u1eddi n\u00f3i c\u1ee7a ng\u01b0\u1eddi h\u1ecdc.</p> </li> <li> <p>Giai \u0111o\u1ea1n t\u1ea1o \u0111i\u1ec3m c\u1ea5p khung (Frame-level score Generation): Sau khi c\u00f3 c\u00e1c \u0111o\u1ea1n \u00e2m thanh \u0111\u01b0\u1ee3c c\u0103n ch\u1ec9nh cho t\u1eebng \u00e2m v\u1ecb, c\u00e1c \u0111\u1eb7c tr\u01b0ng \u00e2m h\u1ecdc \u0111\u00e3 \u0111\u01b0\u1ee3c tr\u00edch xu\u1ea5t cho t\u1eebng khung nh\u1ecf c\u1ee7a to\u00e0n b\u1ed9 t\u00edn hi\u1ec7u \u00e2m thanh \u0111\u01b0\u1ee3c \u0111\u01b0a v\u00e0o m\u1ed9t m\u00f4 h\u00ecnh DNN, m\u00f4 h\u00ecnh n\u00e0y s\u1ebd \u0111\u01b0a ra \u0111i\u1ec3m s\u1ed1 cho m\u1ed7i \u00e2m v\u1ecb c\u00f3 th\u1ec3 c\u00f3 trong ng\u00f4n ng\u1eef t\u1ea1i khung \u0111\u00f3.</p> </li> <li> <p>L\u1ef1a ch\u1ecdn \u0111i\u1ec3m c\u1ea5p khung (Frame-level score selection): </p> <ul> <li> <p>Nh\u01b0 \u0111\u00e3 \u0111\u01b0\u1ee3c \u0111\u1ec1 c\u1eadp, m\u00f4 h\u00ecnh DNN trong c\u00e1c h\u1ec7 th\u1ed1ng c\u01a1 s\u1edf \u0111u\u1ecdc hu\u1ea5n luy\u1ec7n \u0111\u1ec3 \u0111\u01b0a ra x\u00e1c su\u1ea5t h\u1eadu nghi\u1ec7m cho t\u1eebng senone t\u1ea1i m\u1ed7i khung th\u1eddi gian (nh\u00e1nh ph\u00eda tr\u00ean c\u1ee7a kh\u1ed1i m\u00e0u x\u00e1m). \u0110\u1ec3 c\u00f3 \u0111\u01b0\u1ee3c \u0111i\u1ec3m s\u1ed1 cho m\u1ed7i \u00e2m v\u1ecb t\u1ea1i m\u1ed7i khung, c\u00e1c x\u00e1c su\u1ea5t h\u1eadu nghi\u1ec7m c\u1ee7a t\u1ea5t c\u1ea3 c\u00e1c senone thu\u1ed9c v\u1ec1 c\u00f9ng m\u1ed9t \u00e2m v\u1ecb \u0111\u00f3 s\u1ebd \u0111\u01b0\u1ee3c t\u1ed5ng h\u1ee3p l\u1ea1i. M\u1ee5c \u0111\u00edch l\u00e0 chuy\u1ec3n \u0111\u1ed5i \u0111\u1ea7u ra chi ti\u1ebft c\u1ee7a DNN (c\u1ea5p senone) v\u1ec1 c\u1ea5p \u0111\u1ed9 \u00e2m v\u1ecb (phone) \u0111\u1ec3 t\u00ednh to\u00e1n GOP.</p> </li> <li> <p>M\u00f4 h\u00ecnh \u0111\u1ec1 xu\u1ea5t (nh\u00e1nh ph\u00eda d\u01b0\u1edbi kh\u1ed1i m\u00e0u x\u00e1m), thay v\u00ec ph\u1ea3i \u0111i qua c\u00e1c senone trung gian r\u1ed3i t\u1ed5ng h\u1ee3p, m\u00f4 h\u00ecnh DNN \u0111\u01b0\u1ee3c thi\u1ebft k\u1ebf v\u00e0 hu\u1ea5n luy\u1ec7n tr\u1ef1c ti\u1ebfp \u0111\u1ec3 \u0111\u01b0a ra x\u00e1c su\u1ea5t h\u1eadu nghi\u1ec7m cho t\u1eebng \u00e2m v\u1ecb t\u1ea1i m\u1ed7i khung th\u1eddi gian. </p> </li> <li> <p>Sau khi DNN \u0111\u00e3 t\u1ea1o ra \u0111i\u1ec3m s\u1ed1 cho t\u1ea5t c\u1ea3 c\u00e1c \u00e2m v\u1ecb t\u1ea1i m\u1ed7i khung, b\u01b0\u1edbc n\u00e0y s\u1ebd ch\u1ecdn ra \u0111i\u1ec3m s\u1ed1 c\u1ee7a \u00e2m v\u1ecb \u0111\u00fang \\(p\\) t\u1ea1i t\u1eebng khung. V\u00ed d\u1ee5 n\u1ebfu Forced Aligner cho r\u1eb1ng khung \\(t\\) thu\u1ed9c v\u1ec1 \u00e2m v\u1ecb /k/ th\u00ec ta s\u1ebd l\u1ea5y gi\u00e1 tr\u1ecb P_t(/k/|O) t\u1eeb \u0111\u1ea7u ra c\u1ee7a DNN t\u1ea1i khung \u0111\u00f3.</p> </li> </ul> </li> <li> <p>Giai \u0111o\u1ea1n t\u00ednh to\u00e1n \u0111i\u1ebbm ph\u00e1t \u00e2m: \u0110\u1ed1i v\u1edbi m\u1ed7i \u00e2m v\u1ecb \\(p\\) \u0111\u00e3 \u0111\u01b0\u1ee3c x\u00e1c \u0111\u1ecbnh b\u1edfi Forced Aligner, l\u1ea5y t\u1ea5t c\u1ea3 c\u00e1c \u0111i\u1ec3m s\u1ed1 c\u1ea5p khung \u0111\u00e3 \u0111\u01b0\u1ee3c l\u1ef1a ch\u1ecdn \u1edf b\u01b0\u1edbc tr\u01b0\u1edbc. C\u00e1c \u0111i\u1ec3m s\u1ed1 n\u00e0y sau \u0111\u00f3 \u0111\u01b0\u1ee3c trung b\u00ecnh h\u00f3a tr\u00ean to\u00e0n b\u1ed9 c\u00e1c khung m\u00e0 \u00e2m v\u1ecb \u0111\u00f3 chi\u1ebfm gi\u1eef. Gi\u1ea3 s\u1eed \u00e2m v\u1ecb /k/ k\u00e9o d\u00e0i 10 khung t\u1eeb (\\(f_1\\) \u0111\u1ebfn \\(f_{10})\\), \u0111i\u1ec3m GOP c\u1ee7a /k/ s\u1ebd \u0111\u01b0\u1ee3c t\u00ednh b\u1eb1ng c\u00e1ch l\u1ea5y trung b\u00ecnh c\u1ee7a \\([P_{f1}(/k/|O),...,P_{f10}(/k/|O)]\\). </p> </li> </ul>"},{"location":"research/pronunciation-scoring/experiments/report01/#23-wav2vec","title":"2.3 wav2vec","text":"<p>M\u00f4 h\u00ecnh n\u00e0y l\u00e0 m\u1ed9t ph\u01b0\u01a1ng ph\u00e1p hi\u1ec7u qu\u1ea3 v\u00e0 hi\u1ec7n \u0111\u1ea1i nh\u1eb1m m\u1ee5c \u0111\u00edch x\u00e2y d\u1ef1ng h\u1ec7 th\u1ed1ng nh\u1eadn d\u1ea1ng ti\u1ebfng n\u00f3i th\u00f4ng qua h\u1ecdc t\u1ef1 gi\u00e1m s\u00e1t, gi\u00fap gi\u1ea3i quy\u1ebft v\u1ea5n \u0111\u1ec1 thi\u1ebfu d\u1eef li\u1ec7u c\u00f3 nh\u00e3n. Ch\u00fang h\u1ecdc c\u00e1ch m\u00e3 h\u00f3a \u00e2m thanh th\u00e0nh c\u00e1c bi\u1ec3u di\u1ec5n ti\u1ec1m \u1ea9n, sau \u0111\u00f3 che \u0111i m\u1ed9t ph\u1ea7n v\u00e0 s\u1eed d\u1ee5ng ki\u1ebfn tr\u00fac Transformer t\u1ea1o ra c\u00e1c bi\u1ec3u di\u1ec5n ng\u1eef c\u1ea3nh h\u00f3a v\u00e0 ph\u00e2n bi\u1ec7t ch\u00fang v\u1edbi c\u00e1c y\u1ebfu t\u1ed1 g\u00e2y nhi\u1ec5u, \u0111\u1ed3ng th\u1eddi h\u1ecdc \u0111\u01b0\u1ee3c c\u00e1c \u0111\u01a1n v\u1ecb ti\u1ebfng n\u00f3i r\u1eddi r\u1ea1c. Ph\u01b0\u01a1ng ph\u00e1p n\u00e0y \u0111\u1ea1t \u0111\u01b0\u1ee3c hi\u1ec7u su\u1ea5t r\u1ea5t t\u1ed1t, \u0111\u1eb7c bi\u1ec7t \u1ea5n t\u01b0\u1ee3ng \u1edf c\u00e1c tr\u01b0\u1eddng h\u1ee3p c\u00f3 r\u1ea5t \u00edt d\u1eef li\u1ec7u c\u00f3 nh\u00e3n.</p> <p>Ki\u1ebfn tr\u00fac c\u1ee7a m\u00f4 h\u00ecnh wav2vec 2.0 (H\u00ecnh 2.1) t\u1eadp trung v\u00e0o ba th\u00e0nh ph\u1ea7n ch\u00ednh: B\u1ed9 m\u00e3 h\u00f3a \u0111\u1eb7c tr\u01b0ng (feature encoder), m\u1ea1ng Transformer \u0111\u1ec3 t\u1ea1o bi\u1ec3u di\u1ec5n ng\u1eef c\u1ea3nh (contextualized representations with transformers), v\u00e0 l\u01b0\u1ee3ng t\u1eed h\u00f3a (quantization module).</p> <p></p> <p>H\u00ecnh 2.1: Ki\u1ebfn tr\u00fac th\u00e0nh ph\u1ea7n c\u01a1 b\u1ea3n c\u1ee7a m\u00f4 h\u00ecnh wav2vec</p> <p>a. B\u1ed9 m\u00e3 h\u00f3a \u0111\u1eb7c tr\u01b0ng (feature encoder)</p> <p>M\u1ee5c \u0111\u00edch c\u1ee7a qu\u00e1 tr\u00ecnh n\u00e0y l\u00e0 chuy\u1ec3n \u0111\u1ed5i to\u00e0n b\u1ed9 s\u00f3ng \u00e2m thanh th\u00f4 th\u00e0nh c\u00e1c bi\u1ec3u di\u1ec5n ti\u1ec1m \u1ea9n c\u00f3 \u1ef9 ngh\u0129a. B\u1ed9 m\u00e3 h\u00f3a n\u00e0y \u0111\u01b0\u1ee3c c\u1ea5u t\u1ea1o b\u1edfi nhi\u1ec1u kh\u1ed1i, m\u1ed7i kh\u1ed1i ch\u1ee9a c\u00e1c th\u00e0nh ph\u1ea7n nh\u01b0:</p> <ul> <li> <p>T\u00edch ch\u1eadp th\u1eddi gian (temporal convolution): \u0110\u00e2y l\u00e0 m\u1ed9t lo\u1ea1i m\u1ea1ng t\u00edch ch\u1eadp chuy\u00ean d\u00f9ng cho d\u1eef li\u1ec7u chu\u1ed7i (nh\u01b0 \u00e2m thanh). Ch\u00fang l\u1ea7n l\u01b0\u1ee3t qu\u00e9t qua d\u1eef li\u1ec7u theo th\u1eddi gian \u0111\u1ec1 tr\u00edch xu\u1ea5t c\u00e1c \u0111\u1eb7c tr\u01b0ng c\u1ee5c b\u1ed9.</p> </li> <li> <p>Chu\u1ea9n h\u00f3a l\u1edbp (layer normalization): K\u1ef9 thu\u1eadt n\u00e0y gi\u00fap \u1ed5n \u0111\u1ecbnh qu\u00e1 tr\u00ecnh hu\u1ea5n luy\u1ec7n c\u1ee7a m\u1ea1ng n\u01a1-ron b\u1eb1ng c\u00e1ch chu\u1ea9n h\u00f3a \u0111\u1ea7u ra c\u1ee7a m\u1ed7i l\u1edbp.</p> </li> <li> <p>H\u00e0m k\u00edch ho\u1ea1t GELU: H\u00e0m n\u00e0y gi\u00fap m\u1ea1ng h\u1ecdc \u0111\u01b0\u1ee3c c\u00e1c m\u1ed1i quan h\u1ec7 ph\u1ee9c t\u1ea1p trong d\u1eef li\u1ec7u.</p> </li> </ul> <p>b. Bi\u1ec3u di\u1ec5n \u0111\u01b0\u1ee3c ng\u1eef c\u1ea3nh h\u00f3a v\u1edbi Transformer (contextualized representations with transformers)</p> <p>Gi\u1ea3 s\u1eed c\u00e1c \u00e2m thanh th\u00f4 sau khi \u0111i qua feature encoder l\u00e0 c\u00e1c bi\u1ec3u di\u1ec5n ti\u1ec1m \u1ea9n \\(Z\\), ch\u00fang s\u1ebd \u0111\u01b0\u1ee3c \u0111\u01b0a v\u00e0o c\u00e1c ki\u1ebfn tr\u00fac Transformers \u0111\u1ec3 t\u1ea1o ra c\u00e1c bi\u1ec3u di\u1ec5n \\(C\\) n\u1eafm b\u1eaft \u0111\u01b0\u1ee3c ng\u1eef c\u1ea3nh c\u1ee7a to\u00e0n b\u1ed9 chu\u1ed7i. C\u00f3 m\u1ed9t s\u1ef1 kh\u00e1c bi\u1ec7t nh\u1ecf trong vi\u1ec7c nh\u00fang v\u1ecb tr\u00ed (positional embeddings), thay v\u00ec d\u00f9ng nh\u00fang v\u1ecb tr\u00ed c\u1ed1 \u0111\u1ecbnh nh\u01b0 ph\u01b0\u01a1ng ph\u00e1p truy\u1ec1n th\u1ed1ng, \u1edf giai \u0111o\u1ea1n n\u00e0y m\u1ed9t l\u1edbp t\u00edch ch\u1eadp \u0111\u01b0\u1ee3c c\u00e0i \u0111\u1eb7t \u0111\u1ec3 t\u1ea1o ra nh\u00fang v\u1ecb tr\u00ed t\u01b0\u01a1ng \u0111\u1ed1i. Hi\u1ec3u m\u1ed9t c\u00e1ch n\u00f4m na, thay v\u00ec n\u00f3i \"ph\u1ea7n t\u1eed n\u00e0y \u1edf v\u1ecb tr\u00ed th\u1ee9 10\", th\u00ec ch\u00fang s\u1ebd t\u1eadp trung v\u00e0o \"ph\u1ea7n t\u1eed n\u00e0y c\u00e1ch ph\u1ea7n t\u1eeb kia v\u1edbi kho\u1ea3ng c\u00e1ch l\u00e0 bao xa\".</p> <p>c. Module l\u01b0\u1ee3ng t\u1eed h\u00f3a (quantization module)</p> <p>Chuy\u1ec3n \u0111\u1ed5i c\u00e1c bi\u1ec3u di\u1ec5n ti\u1ebfng n\u00f3i ti\u1ec1m \u1ea9n li\u00ean t\u1ee5c \\(Z\\) th\u00e0nh m\u1ed9t t\u1eadp h\u1ee3p r\u1eddi r\u1ea1c (discrete) c\u00e1c bi\u1ec3u di\u1ec5n. C\u00e1c bi\u1ec3u di\u1ec5n r\u1eddi r\u1ea1c n\u00e0y \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng l\u00e0m m\u1ee5c ti\u00eau trong t\u00e1c v\u1ee5 h\u1ecdc t\u1ef1 gi\u00e1m s\u00e1t. Trong m\u00f4 h\u00ecnh n\u00e0y l\u01b0\u1ee3ng t\u1eed h\u00f3a t\u00edch (product quantization - PQ) \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng. \u0110\u00e2y l\u00e0 m\u1ed9t k\u1ef9 thu\u1eadt \u0111\u1ec3 l\u01b0\u1ee3ng t\u1eed h\u00f3a c\u00e1c vector nhi\u1ec1u chi\u1ec1u th\u00e0nh nhi\u1ec1u ph\u1ea7n nh\u1ecf (c\u00e1c nh\u00f3m ho\u1eb7c codebook). Gi\u1ea3 s\u1eed ta c\u00f3 m\u1ed9t vector \u0111\u1eb7c tr\u01b0ng \\(d\\) chi\u1ec1u. PQ s\u1ebd chia \\(d\\) chi\u1ec1u n\u00e0y th\u00e0nh \\(G\\) nh\u00f3m, m\u1ed7i nh\u00f3m c\u00f3 \\(\\frac{d}{G}\\) chi\u1ec1u. V\u1edbi m\u1ed7i nh\u00f3m, s\u1ebd ch\u1ee9a m\u1ed9t codebook ri\u00eang v\u00e0 m\u1ed7i codebook s\u1ebd ch\u1ee9a nhi\u1ec1u vector con.</p> <p>\u0110\u1ec3 d\u1ec5 h\u00ecnh dung h\u01a1n, n\u1ebfu ta c\u00f3 m\u1ed9t b\u1ee9c \u1ea3nh k\u1ef9 thu\u1eadt s\u1ed1, m\u00e0u s\u1eafc trong b\u1ee9c \u1ea3nh \u0111\u01b0\u1ee3c bi\u1ec3u di\u1ec5n b\u1eb1ng nhi\u1ec1u gi\u00e1 tr\u1ecb s\u1ed1 li\u00ean t\u1ee5c. N\u1ebfu mu\u1ed1n gi\u1ea3m \u0111i dung l\u01b0\u1ee3ng file ho\u1eb7c mu\u1ed1n l\u01b0u tr\u1eef ch\u00fang tr\u00ean m\u1ed9t thi\u1ebft b\u1ecb c\u00f3 b\u1ed9 nh\u1edb h\u1ea1n ch\u1ebf, th\u00ec l\u01b0\u1ee3ng t\u1eed h\u00f3a m\u00e0u s\u1eafc s\u1ebd \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng. Thay v\u00ec c\u00f3 h\u00e0ng tri\u1ec7u s\u1eafc th\u00e1i m\u00e0u li\u00ean t\u1ee5c, ta ch\u1ec9 cho ph\u00e9p \u1ea3nh s\u1eed d\u1ee5ng m\u1ed9t t\u1eadp h\u1ee3p r\u1eddi r\u1ea1c c\u00f3 th\u1ec3 l\u00e0 100 m\u00e0u chu\u1ea9n ho\u1eb7c \u00edt h\u01a1n. M\u1ed7i \u0111i\u1ec3m \u1ea3nh s\u1ebd \u0111\u01b0\u1ee3c l\u00e0m tr\u00f2n ho\u1eb7c quy v\u1ec1 m\u1ed9t m\u00e0u g\u1ea7n nh\u1ea5t trong t\u1eadp h\u1ee3p m\u00e0u gi\u1edbi h\u1ea1n \u0111\u00f3.</p> <p>Bi\u1ec3u di\u1ec5n ti\u1ebfng n\u00f3i ti\u1ec1m \u1ea9n \\(Z\\) m\u00e0 b\u1ed9 m\u00e3 h\u00f3a t\u1ea1o ra l\u00e0 c\u00e1c gi\u00e1 tr\u1ecb li\u00ean t\u1ee5c, v\u00ec v\u1eady m\u1ee5c ti\u00eau ch\u00ednh c\u1ee7a l\u01b0\u1ee3ng t\u1eed h\u00f3a l\u00e0 c\u1ed1 g\u1eafng chuy\u1ec3n \u0111\u1ed5i ch\u00fang v\u1ec1 m\u1ed9t t\u1eadp h\u1ee3p h\u1eefu h\u1ea1n r\u1eddi r\u1ea1c c\u00e1c m\u00e3 ho\u1eb7c \u0111\u01a1n v\u1ecb. N\u1ebfu t\u1eeb m\u1ed9t \u0111o\u1ea1n \u00e2m thanh \u0111\u1ea7u v\u00e0o, ta mong mu\u1ed1n ph\u00e2n lo\u1ea1i t\u1eeb m\u1ed9t chu\u1ed7i c\u00e1c \u00e2m thanh li\u00ean t\u1ee5c \u0111\u00f3 th\u00e0nh c\u00e1c \u00e2m (nh\u01b0 a, b, c) r\u00f5 r\u00e0ng, thay v\u00ec l\u00e0 m\u1ed9t d\u1ea3i \u00e2m li\u00ean t\u1ee5c kh\u00f4ng \u0111\u1ecbnh h\u00ecnh. Vi\u1ec7c n\u00e0y gi\u00fap m\u00f4 h\u00ecnh d\u1ec5 d\u00e0ng h\u1ecdc \u0111\u01b0\u1ee3c c\u00e1c \u0111\u01a1n v\u1ecb c\u01a1 b\u1ea3n c\u1ee7a ti\u1ebfng n\u00f3i.</p> <p>L\u01b0\u1ee3ng t\u1eed h\u00f3a gi\u00fap cho vi\u1ec7c x\u1eed l\u00fd d\u1eef li\u1ec7u v\u00e0 l\u01b0u tr\u0169 d\u1ec5 d\u00e0ng h\u01a1n v\u00e0 c\u00e1c bi\u1ec3u di\u1ec5n \u0111\u00e3 \u0111\u01b0\u1ee3c l\u01b0\u1ee3ng t\u1eed h\u00f3a \\(Q\\) \u0111\u01b0\u1ee3c d\u00f9ng l\u00e0m m\u1ee5c ti\u00eau (targets) cho t\u00e1c v\u1ee5 h\u1ecdc t\u1ef1 gi\u00e1m s\u00e1t. M\u00f4 h\u00ecnh ph\u1ea3i c\u1ed1 g\u1eafng d\u1ef1 \u0111o\u00e1n ho\u1eb7c t\u00e1i t\u1ea1o l\u1ea1i c\u00e1c \u0111\u01a1n v\u1ecb r\u1eddi r\u1ea1c n\u00e0y.</p> <p>Codebook c\u00f3 th\u1ec3 coi l\u00e0 m\u1ed9t t\u1eed \u0111i\u1ec3n ho\u1eb7c m\u1ed9t b\u1ed9 s\u01b0u t\u1eadp c\u00e1c m\u00e3 ho\u1eb7c m\u1eabu \u0111\u00e3 \u0111\u01b0\u1ee3c \u0111\u1ecbnh ngh\u0129a tr\u01b0\u1edbc. Ch\u00fang \u0111\u01b0\u1ee3c x\u00e2y d\u1ef1ng m\u1ed9t c\u00e1ch t\u1ef1 \u0111\u1ed9ng th\u00f4ng qua qu\u00e1 tr\u00ecnh hu\u1ea5n luy\u1ec7n t\u1ef1 gi\u00e1m s\u00e1t c\u1ee7a m\u00f4 h\u00ecnh. Trong qu\u00e1 tr\u00ecnh hu\u1ea5n luy\u1ec7n, codebook \u0111\u01b0\u1ee3c h\u00ecnh th\u00e0nh nh\u1edd s\u1ef1 h\u1ed7 tr\u1ee3 b\u1edfi c\u00e1c h\u00e0m m\u1ea5t m\u00e1t (contrastive loss, diversity loss) v\u00e0 c\u00e1c k\u1ef9 thu\u1eadt nh\u01b0 gumble softmax \u0111\u1ec3 tr\u1edf th\u00e0nh m\u1ed9t t\u1eadp h\u1ee3p c\u00e1c \u0111\u01a1n v\u1ecb t\u1ed1i \u01b0u, c\u00f3 kh\u1ea3 n\u0103ng bi\u1ec3u di\u1ec5n hi\u1ec7u qu\u1ea3 c\u00e1c \u0111\u1eb7c tr\u01b0ng c\u01a1 b\u1ea3n c\u1ee7a d\u1eef li\u1ec7u \u00e2m thanh kh\u00f4ng c\u00f3 nh\u00e3n.</p> <ul> <li> <p>Ban \u0111\u1ea7u khi m\u00f4 h\u00ecnh ch\u01b0a \u0111\u01b0\u1ee3c hu\u1ea5n luy\u1ec7n, c\u00e1c vector trong codebook \u0111\u01b0\u1ee3c kh\u1edfi t\u1ea1o ng\u1eabu nhi\u00ean. Ch\u00fang c\u00f3 th\u1ec3 l\u00e0 nh\u1eefng t\u1eadp h\u1ee3p s\u1ed1 v\u00f4 ngh\u0129a.</p> </li> <li> <p>Codebook \u0111\u01b0\u1ee3c h\u1ecdc v\u00e0 c\u1eadp nh\u1eadt c\u00f9ng v\u1edbi ph\u1ea7n c\u00f2n l\u1ea1i c\u1ee7a m\u00f4 h\u00ecnh (b\u1ed9 m\u00e3 h\u00f3a \u0111\u1eb7c tr\u01b0ng v\u00e0 transformer) th\u00f4ng qua t\u00e1c v\u1ee5 t\u1ef1 gi\u00e1m s\u00e1t. \u0110\u1ec3 c\u00f3 \u0111\u01b0\u1ee3c nh\u00e3n cho vi\u1ec7c d\u1ef1 \u0111o\u00e1n m\u00e0 kh\u00f4ng c\u1ea7n con ng\u01b0\u1eddi, c\u00e1c bi\u1ec3u di\u1ec5n ti\u1ec1m \u1ea9n \\(Z\\) (th\u01b0\u1eddng l\u00e0 c\u00e1c ph\u1ea7n kh\u00f4ng b\u1ecb che t\u1eeb c\u00e1c kho\u1ea3ng th\u1eddi gian kh\u00e1c) \u0111\u01b0\u1ee3c \u0111\u01b0a ra PQ \u0111\u1ec3 t\u1ea1o ra c\u00e1c \u0111\u01a1n v\u1ecb r\u1eddi r\u1ea1c. Ch\u00ednh c\u00e1c \u0111\u01a1n v\u1ecb n\u00e0y \u0111\u00f3ng vai tr\u00f2 l\u00e0 nh\u00e3n t\u1ef1 t\u1ea1o cho m\u00f4 h\u00ecnh.</p> </li> <li> <p>Khi m\u00f4 h\u00ecnh d\u1ef1 \u0111o\u00e1n m\u1ed9t bi\u1ec3u di\u1ec5n ng\u1eef c\u1ea3nh cho m\u1ed9t \u0111o\u1ea1n \u00e2m thanh b\u1ecb che, ch\u00fang s\u1ebd so s\u00e1nh d\u1ef1 \u0111o\u00e1n \u0111\u00f3 v\u1edbi m\u1ed9t trong c\u00e1c \u0111\u01a1n v\u1ecb r\u1eddi r\u1ea1c t\u1eeb codebook (\u0111\u00e2y l\u00e0 m\u1ee5c ti\u00eau/nh\u00e3n \u0111\u00fang cho \u0111o\u1ea1n b\u1ecb che \u0111\u00f3). N\u1ebfu d\u1ef1 \u0111o\u00e1n c\u1ee7a m\u00f4 h\u00ecnh ch\u01b0a t\u1ed1t, h\u00e0m m\u1ea5t m\u00e1t (constractive loss) s\u1ebd \u0111\u01b0a ra m\u1ee9c \u0111\u1ed9 sai l\u1ec7ch. </p> </li> </ul> <p>d. Gumble Softmax</p> <p>Vi\u1ec7c ch\u1ecdn l\u1ef1c m\u1ed9t vector r\u1eddi r\u1ea1c t\u1eeb m\u1ed9t codebook th\u01b0\u1eddng kh\u00f4ng th\u1ec3 kh\u1ea3 vi, t\u1ee9c l\u00e0 s\u1ebd kh\u00f4ng th\u1ec3 t\u00ednh to\u00e1n gradient cho qu\u00e1 tr\u00ecnh c\u1eadp nh\u1eadt tr\u1ecdng s\u1ed1 m\u1ea1ng. Gumbel softmax l\u00e0 m\u1ed9t k\u1ef9 thu\u1eadt nh\u1eb1m gi\u1ea3i quy\u1ebft v\u1ea5n \u0111\u1ec1 n\u00e0y, ch\u00fang cho ph\u00e9p ch\u1ecdn c\u00e1c vector r\u1eddi r\u1ea1c m\u1ed9t c\u00e1ch kh\u1ea3 vi ho\u00e0n to\u00e0n, \u0111i\u1ec1u n\u00e0y c\u00f3 ngh\u0129a l\u00e0 ta c\u00f3 th\u1ec3 th\u1ef1c hi\u1ec7n lan truy\u1ec1n ng\u01b0\u1ee3c qua qu\u00e1 tr\u00ecnh l\u1ef1a ch\u1ecdn r\u1eddi r\u1ea1c \u0111\u1ec1 hu\u1ea5n luy\u1ec7n to\u00e0n b\u1ed9 m\u00f4 h\u00ecnh. C\u00f4ng th\u1ee9c c\u1ee7a Gumbel softmax \u0111\u01b0\u1ee3c thi\u1ebft k\u1ebf nh\u01b0 sau:</p> \\[ P_{g,v} = \\frac{exp(l_{g,v} + n_{v}) / \\tau}{\\sum^{V}_{k=1} exp(l_{g,k} + n_{k}) / \\tau} \\] <p>C\u00f4ng th\u1ee9c n\u00e0y t\u00ednh to\u00e1n x\u00e1c su\u1ea5t \u0111\u1ec3 ch\u1ecdn m\u1ee5c nh\u1eadp th\u1ee9 \\(v\\) t\u1eeb s\u1ed5 m\u00e3 c\u1ee7a nh\u00f3m \\(g\\), \\(l_{g,v}\\) l\u00e0 c\u00e1c \u0111\u1ea7u ra ch\u01b0a chu\u1ea9n h\u00f3a c\u1ee7a m\u1ed9t l\u1edbp tuy\u1ebfn t\u00ednh. Gumbel softmax c\u00f3 s\u1eed d\u1ee5ng m\u1ed9t tham s\u1ed1 nhi\u1ec7t \u0111\u1ed9 \\(\\tau\\) gi\u00fap cho qu\u00e1 tr\u00ecnh l\u1ef1a ch\u1ecdn tr\u1edf n\u00ean m\u1ec1m m\u1ea1i h\u01a1n trong qu\u00e1 tr\u00ecnh truy\u1ec1n ti\u1ebfn, v\u00e0 s\u1eed d\u1ee5ng m\u1ed9t b\u1ed9 \u01b0\u1edbc t\u00ednh c\u00f3 t\u00ean l\u00e0 straight-through \u0111\u1ec3 \u0111\u1ea3m b\u00e1o gradient truy\u1ec1n ng\u01b0\u1ee3c ch\u00ednh x\u00e1c trong qu\u00e1 tr\u00ecnh truy\u1ec1n ng\u01b0\u1ee3c.</p> <p>e. Contrastive Loss</p> <p>\u0110\u00e2y l\u00e0 h\u00e0m m\u1ea5t m\u00e1t t\u01b0\u01a1ng ph\u1ea3n gi\u00fap m\u00f4 h\u00ecnh c\u00f3 th\u1ec3 ph\u00e2n bi\u1ec7t \u0111\u01b0\u1ee3c gi\u1eefa bi\u1ec3u di\u1ec5n ti\u1ebfng n\u00f3i ti\u1ec1m \u1ea9n \u0111\u01b0\u1ee3c l\u01b0\u1ee3ng t\u1eed h\u00f3a \u0111\u00fang (positive sample) v\u00e0 c\u00e1c bi\u1ec3u di\u1ec5n sai (negative sample) cho m\u1ed9t v\u1ecb tr\u00ed b\u1ecb che. H\u00e0m n\u00e0y \u0111\u01b0\u1ee3c \u0111\u1ecbnh ngh\u0129a b\u1eb1ng c\u00f4ng th\u1ee9c sau:</p> \\[ \\mathcal{L}_{m} = -\\text{log} \\frac{exp(sim(c_{t}, q_{t})/k)}{\\sum_{\\tilde{q} \\sim Q_{t}} exp(sim(c_{t}, \\tilde{q}) / k)} \\] <p>M\u00f4 h\u00ecnh s\u1ebd nh\u1eadn \u0111\u1ea7u ra t\u1eeb m\u1ea1ng transformer l\u00e0 \\(c_{t}\\), t\u1eadp trung v\u00e0o m\u1ed9t b\u01b0\u1edbc th\u1eddi gian \\(t\\) \u0111\u00e3 b\u1ecb che, \\(c_t\\) l\u00e0 bi\u1ec3u di\u1ec5n ng\u1eef c\u1ea3nh m\u00e0 transformer \u0111\u00e3 t\u1ea1o ra, c\u1ed1 g\u1eafng n\u1eafm b\u1eaft th\u00f4ng tin t\u1eeb to\u00e0n b\u1ed9 chu\u1ed7i. Sau \u0111\u00f3 m\u00f4 h\u00ecnh c\u1ea7n x\u00e1c \u0111\u1ecbnh \u0111\u00e2u l\u00e0 bi\u1ec3u di\u1ec5n ti\u1ebfng n\u00f3i ti\u1ec1m \u1ea9m \u0111\u01b0\u1ee3c l\u01b0\u1ee3ng t\u1eed h\u00f3a \u0111\u00fang \\(q_{t}\\) cho b\u01b0\u1edbc th\u1eddi gian \\(t\\), \\(q_{t}\\) \u0111\u01b0\u1ee3c t\u1ea1o ra t\u1eeb bi\u1ec3u di\u1ec5n ti\u1ec1m \u1ea9n g\u1ed1c (kh\u00f4ng b\u1ecb che) t\u1ea1i v\u1ecb tr\u00ed \\(t\\), sau khi \u0111i qua module l\u01b0\u1ee3ng t\u1eed h\u00f3a. \u0110\u1ec3 l\u00e0m \u0111\u01b0\u1ee3c \u0111i\u1ec1u n\u00e0y, m\u00f4 h\u00ecnh \u0111\u01b0\u1ee3c \u0111\u01b0a ra m\u1ed9t t\u1eadp h\u1ee3p \\(K+1\\) \u1ee9ng c\u1eed vi\u00ean cho \\(\\tilde{q}\\). T\u1eadp h\u1ee3p n\u00e0y bao g\u1ed3m:</p> <ul> <li>\\(q_{t}\\) bi\u1ec3u di\u1ec5n \u0111\u00fang</li> <li>\\(K\\) l\u00e0 ph\u1ea7n t\u1eed g\u00e2y nhi\u1ec5u, c\u00e1c bi\u1ec3u di\u1ec5n n\u00e0y \u0111\u01b0\u1ee3c l\u1ea5y m\u1eabu ng\u1eabu nhi\u00ean t\u1eeb c\u00e1c b\u01b0\u1edbc th\u1eddi gian b\u1ecb che kh\u00e1c trong c\u00f9ng m\u1ed9t file \u00e2m thanh. </li> </ul> <p>f. Diversity Loss</p> <p>C\u00f4ng th\u1ee9c c\u1ee7a Diversity Loss (h\u00e0m m\u1ea5t m\u00e1t \u0111a d\u1ea1ng) \u0111\u01b0\u1ee3c bi\u1ec3u di\u1ec5n nh\u01b0 sau:</p> \\[ \\mathcal{L}_{d} = \\frac{1}{GV} \\sum^{G}_{g=1} - H(\\overline{p}_{g}) == \\frac{1}{GV} \\sum^{G}_{g=1} \\sum^V_{v=1} \\overline{p}_{g,v} \\log \\overline{p}_{g,v} \\] <p>Trong \u0111\u00f3:</p> <ul> <li>\\(H(\\overline{p}_{g})\\) l\u00e0 k\u00fd hi\u1ec7u cho entropy ph\u00e2n ph\u1ed1i c\u1ee7a \\(\\overline{p}_{g}\\).</li> <li>\\(\\sum^V_{v=1} \\overline{p}_{g,v} \\log \\overline{p}_{g,v}\\) l\u00e0 c\u00f4ng th\u1ee9c t\u00ednh to\u00e1n entropy.</li> <li>\\(\\frac{1}{GV}\\) l\u00e0 h\u1ec7 s\u1ed1 chu\u1ea9n h\u00f3a, trung b\u00ecnh h\u00f3a h\u00e0m m\u1ea5t m\u00e1t tr\u00ean t\u1ea5t c\u1ea3 \\(G\\) codebook v\u00e0 \\(V\\) vector trong m\u1ed7i codebook.</li> </ul> <p>H\u00e0m m\u1ea5t m\u00e1t \u0111a d\u1ea1ng n\u00e0y \u0111\u01b0\u1ee3c \u00e1p d\u1ee5ng khuy\u1ebfn kh\u00edch m\u00f4 h\u00ecnh s\u1eed d\u1ee5ng t\u1ea5t c\u1ea3 ho\u1eb7c ph\u1ea7n l\u1edbn c\u00e1c vector trong c\u00e1c codebook m\u1ed9t c\u00e1ch \u0111\u1ed3ng \u0111\u1ec1u, thay v\u00ec ch\u1ec9 t\u1eadp trung v\u00e0o m\u1ed9t v\u00e0i vector \u0111\u1eb7c tr\u01b0ng ph\u1ed5 bi\u1ebfn. N\u1ebfu kh\u00f4ng c\u00f3 h\u00e0m m\u1ea5t m\u00e1t n\u00e0y, c\u00f3 th\u1ec3 m\u1ed9t s\u1ed1 vector trong codebook kh\u00f4ng bao gi\u1edd \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng. \u0110i\u1ec1u n\u00e0y s\u1ebd v\u00f4 t\u00ecnh l\u00e0m l\u00e3ng ph\u00ed kh\u1ea3 n\u0103ng bi\u1ec3u di\u1ec5n c\u1ee7a codebook v\u00e0 h\u1ea1n ch\u1ebft t\u00ednh \u0111a d\u1ea1ng c\u1ee7a c\u00e1c \u0111\u01a1n v\u1ecb m\u00e0 m\u00f4 h\u00ecnh h\u1ecdc \u0111\u01b0\u1ee3c.</p>"},{"location":"research/pronunciation-scoring/experiments/report01/#24-mot-so-phuong-phap-khac","title":"2.4 M\u1ed9t s\u1ed1 ph\u01b0\u01a1ng ph\u00e1p kh\u00e1c","text":"No. Methods Desciption #1 3MH  [paper] M\u00f4 h\u00ecnh \u0111a t\u1ea7ng (multi-head) h\u1ecdc \u0111\u1ed3ng th\u1eddi nhi\u1ec1u kh\u00eda c\u1ea1nh nh\u01b0 accuracy, stress, fluency \u1edf m\u1ee9c t\u1eeb - t\u0103ng kh\u1ea3 n\u0103ng \u0111\u00e1nh gi\u00e1 t\u1eeb to\u00e0n di\u1ec7n h\u01a1n #2 GOPT-PAII  [paper] M\u00f4 h\u00ecnh Transformer \u0111\u00e1nh gi\u00e1 ph\u00e1t \u00e2m theo nhi\u1ec1u kh\u00eda c\u1ea1nh \u0111\u1ed3ng th\u1eddi (accuracy, fluency, completeness, prosody\u2026) v\u00e0 nhi\u1ec1u m\u1ee9c (phoneme, word, utterance) #3 HierCB + ConPCO  [paper] \u00c1p d\u1ee5ng contrastive learning k\u1ebft h\u1ee3p ordinal regression \u0111\u1ec3 t\u1ea1o embedding \u00e2m v\u1ecb ph\u00e2n bi\u1ec7t v\u00e0 duy tr\u00ec th\u1ee9 t\u1ef1 \u0111\u00e1nh gi\u00e1, gi\u00fap ch\u1ea5m \u0111i\u1ec3m ph\u00e1t \u00e2m ch\u00ednh x\u00e1c h\u01a1n #4 SpeechBlender + LSTM  [paper] D\u00f9ng k\u1ef9 thu\u1eadt data augmentation \u0111\u1eb7c bi\u1ec7t (SpeechBlender) \u0111\u1ec3 m\u00f4 ph\u1ecfng l\u1ed7i ph\u00e1t \u00e2m, hu\u1ea5n luy\u1ec7n LSTM nh\u1eadn bi\u1ebft ph\u00e1t \u00e2m sai hi\u1ec7u qu\u1ea3 ngay c\u1ea3 khi thi\u1ebfu d\u1eef li\u1ec7u th\u1ef1c #5 HiPAMA\u2013LibriSpeech [paper] M\u00f4 h\u00ecnh ph\u00e2n c\u1ea5p (phoneme \u2192 word \u2192 utterance) s\u1eed d\u1ee5ng multi-aspect attention, k\u1ebft h\u1ee3p nhi\u1ec1u kh\u00eda c\u1ea1nh (accuracy, fluency, completeness\u2026) theo t\u1eebng c\u1ea5p \u0111\u1ed9 ng\u00f4n ng\u1eef"},{"location":"research/pronunciation-scoring/experiments/report02/","title":"Tri\u1ec3n khai m\u00f4 h\u00ecnh c\u01a1 b\u1ea3n, \u0111\u00e1nh gi\u00e1 v\u00e0 ph\u00e2n t\u00edch l\u1ed7i","text":"<p>M\u00f4 t\u1ea3</p> <ul> <li> <p>Nhi\u1ec7m v\u1ee5 n\u00e0y thu\u1ed9c Phase01 - Nghi\u00ean c\u1ee9u t\u1ed5ng quan v\u00e0 chu\u1ea9n b\u1ecb d\u1eef li\u1ec7u</p> </li> <li> <p>L\u1ef1a ch\u1ecdn, thu th\u1eadp v\u00e0 ti\u1ec1n x\u1eed l\u00fd b\u1ed9 d\u1eef li\u1ec7u ph\u00f9 h\u1ee3p cho b\u00e0i to\u00e1n PS theo chu\u1ea9n IPA (1)</p> <ol> <li>IPA l\u00e0 m\u1ed9t h\u1ec7 th\u1ed1ng k\u00fd hi\u1ec7u ng\u1eef \u00e2m h\u1ecdc qu\u1ed1c t\u1ebf, d\u00f9ng \u0111\u1ec3 ghi l\u1ea1i c\u00e1ch ph\u00e1t \u00e2m c\u1ee7a c\u00e1c \u00e2m thanh trong ng\u00f4n ng\u1eef n\u00f3i \u2014 m\u1ed9t c\u00e1ch ch\u00ednh x\u00e1c, nh\u1ea5t qu\u00e1n v\u00e0 kh\u00f4ng ph\u1ee5 thu\u1ed9c v\u00e0o ch\u00ednh t\u1ea3 c\u1ee7a b\u1ea5t k\u1ef3 ng\u00f4n ng\u1eef n\u00e0o.</li> </ol> </li> <li> <p>L\u1ef1a ch\u1ecdn m\u00f4 h\u00ecnh AI ph\u00f9 h\u1ee3p, tinh ch\u1ec9nh (fine-tune) m\u00f4 h\u00ecnh tr\u00ean b\u1ed9 d\u1eef li\u1ec7u \u0111\u00e3 \u0111\u01b0\u1ee3c x\u1eed l\u00fd v\u1edbi hai m\u1ee5c lu\u1ed3ng ch\u00ednh:</p> <ol> <li>M\u00f4 h\u00ecnh \u0111\u01b0a ra \u0111\u01b0\u1ee3c \u0111i\u1ec3m \u0111\u00e1nh gi\u00e1 t\u1ed5ng th\u1ec3 tr\u00ean m\u1ed9t \u0111o\u1ea1n \u00e2m thanh \u0111\u1ea7u v\u00e0o c\u1ee7a ng\u01b0\u1eddi h\u1ecdc.</li> <li>M\u00f4 h\u00ecnh li\u1ec7t k\u00ea chi ti\u1ebft v\u00e0 \u0111\u00e1nh gi\u00e1 \u0111\u00fang sai cho to\u00e0n b\u1ed9 c\u00e1c \u00e2m v\u1ecb (phone-level) khi ng\u01b0\u1eddi h\u1ecdc ph\u00e1t \u00e2m.</li> </ol> </li> <li> <p>\u0110\u00e1nh gi\u00e1 m\u00f4 h\u00ecnh, ph\u00e2n t\u00edch l\u1ed7i c\u01a1 b\u1ea3n v\u00e0 d\u1ef1ng API</p> </li> </ul> <p>B\u1ea5m v\u00e0o (1) tr\u00ean \u0111\u1ea7u m\u1ed7i t\u1eeb kh\u00f3a \u0111\u1ec3 xem th\u00eam th\u00f4ng tin ch\u00fa th\u00edch.</p> <ol> <li>\"Ch\u00fa th\u00edch \u0111\u01b0\u1ee3c vi\u1ebft \u1edf \u0111\u00e2y\"</li> </ol>"},{"location":"research/pronunciation-scoring/experiments/report02/#1-bo-du-lieu","title":"1. B\u1ed9 d\u1eef li\u1ec7u","text":"<p>S\u1eed d\u1ee5ng b\u1ed9 d\u1eef li\u1ec7u l2-arctic l\u00e0m b\u1ed9 d\u1eef li\u1ec7u ch\u00ednh \u0111\u1ec3 tri\u1ec3n khai th\u1ef1c nghi\u1ec7m v\u00e0 \u0111\u00e1nh gi\u00e1 c\u01a1 b\u1ea3n cho m\u00f4 h\u00ecnh. \u0110\u00e2y l\u00e0 m\u1ed9t t\u1eadp d\u1eef li\u1ec7u ti\u1ebfng Anh kh\u00f4ng ph\u1ea3i ng\u01b0\u1eddi b\u1ea3n \u0111\u1ecba (non-native English speech corpus), \u0111\u01b0\u1ee3c thi\u1ebft k\u1ebf ph\u1ee5c v\u1ee5 cho nghi\u00ean c\u1ee9u \u1edf m\u1ed9t s\u1ed1 l\u0129nh v\u1ef1c nh\u01b0 chuy\u1ec3n \u0111\u1ed5i gi\u1ecdng n\u00f3i (voice conversion), ph\u00e1t hi\u1ec7n l\u1ed7i ph\u00e1t \u00e2m (mispronunication scoring detection), v.v. </p>"},{"location":"research/pronunciation-scoring/experiments/report02/#11-mo-ta-chi-tiet","title":"1.1 M\u00f4 t\u1ea3 chi ti\u1ebft","text":"<p>Th\u00e0nh ph\u1ea7n ch\u00ednh c\u1ee7a t\u1eadp d\u1eef li\u1ec7u bao g\u1ed3m \u00e2m thanh c\u1ee7a 24 ng\u01b0\u1eddi n\u00f3i ti\u1ebfng Anh kh\u00f4ng ph\u1ea3i l\u00e0 b\u1ea3n x\u1ee9, v\u00e0 h\u1ecd \u0111\u1ebfn t\u1eeb \u0111a d\u1ea1ng c\u00e1c qu\u1ed1c gia kh\u00e1c nhau nh\u01b0 Hindi, H\u00e0n Qu\u1ed1c, Trung Qu\u1ed1c, T\u00e2y Ban Nha, \u1ea2 R\u1eadp v\u00e0 c\u1ea3 Vi\u1ec7t Nam. D\u1eef li\u1ec7u \u00e2m thanh \u0111\u01b0\u1ee3c thu th\u1eadp tr\u00ean c\u1ea3 nam v\u00e0 n\u1eef cho t\u1eebng qu\u1ed1c gia. Thu \u00e2m kho\u1ea3ng 1 gi\u1edd c\u00e1c c\u00e2u ti\u1ebfng Anh \u0111\u01b0\u1ee3c l\u1ea5y t\u1eeb m\u1ed9t t\u1eadp c\u00e1c c\u00e2u chu\u1ea9n CMU ARCTIC prompts tr\u00ean m\u1ed7i ng\u01b0\u1eddi n\u00f3i. M\u1ed7i \u0111o\u1ea1n thu t\u00e2m \u0111\u1ec1u c\u00f3 b\u1ea3n phi\u00ean \u00e2m ch\u00ednh t\u1ea3 \u0111i k\u00e8m (transciption) v\u00e0 phi\u00ean \u00e2m ng\u1eef \u00e2m (forced-aligned phonetic transciption) theo chu\u1ea9n ARPAbet. Ngo\u00e0i ra c\u00f2n \u0111\u01b0\u1ee3c ch\u00fa th\u00edch th\u1ee7 c\u00f4ng l\u1ed7i ph\u00e1t \u00e2m nh\u01b0 l\u1ed7i thay th\u1ebf (substitution), l\u1ed7i b\u1ecf s\u00f3t (detection), l\u1ed7i th\u00eam th\u1eeba (addition). </p>"},{"location":"research/pronunciation-scoring/experiments/report02/#12-cau-truc-bo-du-lieu","title":"1.2 C\u1ea5u tr\u00fac b\u1ed9 d\u1eef li\u1ec7u","text":"<pre><code>l2arctic_v5/\n|\n|-- ABA/ #(1)!\n|  |-- wav/ #(2)!             \n|  |  |-- arctic_a0001.wav\n|  |  |-- arctic_a0002.wav\n|  |  |-- ...\n|  |-- transcripts/ #(3)!  \n|  |  |-- arctic_a0001.txt\n|  |  |-- arctic_a0002.txt\n|  |  |-- ...\n|  |-- TextGrid/ #(4)!\n|  |  |-- arctic_a0001.TextGrid\n|  |  |-- arctic_a0002.TextGrid\n|  |  |-- ...\n|  |-- annotations/ #(5)!\n|     |-- arctic_a0001.TextGrid\n|     |-- arctic_a0002.TextGrid\n|     |-- ...\n|\n|-- SKA/\n|-- BWC/\n|-- ...\n</code></pre> <ol> <li>Folder ch\u1ee9a d\u1eef li\u1ec7u \u00e2m thanh c\u1ee7a t\u1ea5t c\u1ea3 ng\u01b0\u1eddi n\u00f3i trong c\u00f9ng m\u1ed9t qu\u1ed1c gia.</li> <li>Folder ch\u1ee9a c\u00e1c \u0111o\u1ea1n thanh c\u1ee7a ng\u01b0\u1eddi n\u00f3i</li> <li>Folder bao g\u1ed3m c\u00e1c v\u0103n b\u1ea3n ch\u00fa th\u00edch t\u01b0\u01a1ng \u1ee9ng v\u1edbi file \u00e2m thanh</li> <li>Folder ch\u00fa th\u00edch c\u0103n ch\u1ec9nh sau khi tr\u1ea3i qua qu\u00e1 tr\u00ecnh \u00e9p khung</li> <li>Folder g\u00e1n nh\u00e3n th\u1ee7 c\u00f4ng c\u00e1c l\u1ed7i ph\u00e1t \u00e2m cho \u0111o\u1ea1n \u00e2m thanh</li> </ol> <p>Trong \u0111\u00f3:</p> <ul> <li><code>ABA:</code> Folder ch\u1ee9a d\u1eef li\u1ec7u \u00e2m thanh c\u1ee7a t\u1ea5t c\u1ea3 ng\u01b0\u1eddi n\u00f3i trong c\u00f9ng m\u1ed9t qu\u1ed1c gia.</li> <li><code>wav:</code> Folder ch\u1ee9a c\u00e1c \u0111o\u1ea1n thanh c\u1ee7a ng\u01b0\u1eddi n\u00f3i</li> <li><code>transcipts:</code> Folder bao g\u1ed3m c\u00e1c v\u0103n b\u1ea3n ch\u00fa th\u00edch t\u01b0\u01a1ng \u1ee9ng v\u1edbi file \u00e2m thanh</li> <li><code>TextGrid:</code> Folder ch\u00fa th\u00edch c\u0103n ch\u1ec9nh sau khi tr\u1ea3i qua qu\u00e1 tr\u00ecnh \u00e9p khung</li> <li><code>annotations:</code> Folder g\u00e1n nh\u00e3n th\u1ee7 c\u00f4ng c\u00e1c l\u1ed7i ph\u00e1t \u00e2m cho \u0111o\u1ea1n \u00e2m thanh</li> </ul> <p>M\u1ed7i m\u1ed9t \u0111o\u1ea1n \u00e2m thanh \u0111\u1ec1u \u0111\u01b0\u1ee3c \u0111\u01b0a v\u00e0o m\u1ed9t c\u00f4ng c\u1ee5 c\u0103n ch\u1ec9nh d\u1ef1a tr\u00ean transcipts t\u01b0\u01a1ng \u1ee9ng. C\u00e1c th\u00f4ng tin n\u00e0y \u0111\u01b0\u1ee3c l\u01b0u tr\u1eef d\u01b0\u1edbi d\u1ea1ng <code>.TextGrid</code>(1).</p> <ol> <li>L\u00e0 m\u1ed9t \u0111\u1ecbnh d\u1ea1ng t\u1ec7p v\u0103n b\u1ea3n \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong ph\u1ea7m m\u1ec1m Praat \u0111\u1ec3 g\u00e1n nh\u00e3n th\u1eddi gian cho \u00e2m thanh. Ch\u00fang l\u01b0u tr\u1eef th\u00f4ng t\u00ecn nh\u01b0 t\u1eeb, \u00e2m ti\u1ebft, nh\u00e3n \u00e2m v\u1ecb... t\u01b0\u01a1ng \u1ee9ng v\u1edbi c\u00e1c \u0111o\u1ea1n th\u1eddi gian trong file \u00e2m thanh. </li> </ol> <p>C\u1ea5u tr\u00fac ch\u00ednh c\u1ee7a m\u1ed9t file <code>.TextGrid</code> c\u01a1 b\u1ea3n \u0111\u01b0\u1ee3c hi\u1ec3n th\u1ecb nh\u01b0 trong <code>example.TextGrid</code>, ch\u1ee9a m\u1ed9t s\u1ed1 th\u00f4ng tin quan tr\u1ecdng:</p> <ul> <li> <p><code>xmin</code>, <code>xmax</code>: th\u1eddi gian b\u1eaft \u0111\u1ea7u v\u00e0 k\u1ebft th\u00fac c\u1ee7a m\u1ed9t file \u00e2m thanh.</p> </li> <li> <p><code>tier</code>: l\u00e0 c\u00e1c t\u1ea7ng d\u1eef li\u1ec7u ch\u00ednh nh\u01b0 <code>name=\"words\"</code>, <code>name=\"phones\"</code>. </p> </li> <li> <p>T\u1ea1i m\u1ed7i t\u1ea7ng, m\u1ed7i \u0111o\u1ea1n \u00e2m thanh \u0111\u1ec1u \u0111\u01b0\u1ee3c g\u00e1n nh\u00e3n t\u01b0\u01a1ng \u1ee9ng v\u1edbi t\u1eeb/\u00e2m v\u1ecb t\u1ea1i th\u1eddi \u0111i\u1ec3m \u0111\u00f3. </p> </li> </ul> example.TextGrid<pre><code>File type = \"ooTextFile\"\nObject class = \"TextGrid\"\n\nxmin = 0 \nxmax = 2.39 \ntiers? &lt;exists&gt; \nsize = 3 \nitem []: \n    item [1]:\n        class = \"IntervalTier\" \n        name = \"words\" \n        xmin = 0 \n        xmax = 2.39 \n        intervals: size = 10 \n        intervals [1]:\n            xmin = 0 \n            xmax = 0.05 \n            text = \"\" \n        intervals [2]:\n            xmin = 0.05 \n            xmax = 0.42 \n            text = \"will\" \n        intervals [3]:\n            xmin = 0.42 \n            xmax = 0.64 \n            text = \"we\" \n        ...\n\n    item [2]:\n        class = \"IntervalTier\" \n        name = \"phones\" \n        xmin = 0 \n        xmax = 2.39 \n        intervals: size = 22 \n        intervals [1]:\n            xmin = 0 \n            xmax = 0.05 \n            text = \"sil\" \n        intervals [2]:\n            xmin = 0.05 \n            xmax = 0.28 \n            text = \"W\" \n        intervals [3]:\n            xmin = 0.9 \n            xmax = 1.07 \n            text = \"ER0,AH0,s\" \n        ...\n</code></pre> <p>Th\u00f4ng tin quan tr\u1ecdng nh\u1ea5t c\u1ee7a t\u1eadp d\u1eef li\u1ec7u n\u00e0y, \u0111\u00f3 l\u00e0 nh\u1eefng labels \u0111\u01b0\u1ee3c g\u00e1n nh\u00e3n th\u1ee7 c\u1ed9ng ph\u1ee5c v\u1ee5 cho b\u00e0i to\u00e1n mispronunciation detect \u1edf m\u1ee9c phone-level. \u1ede t\u1ea7ng <code>phones</code>, m\u1ed7i \u0111o\u1ea1n \u00e2m thanh t\u01b0\u01a1ng \u1ee9ng s\u1ebd \u0111\u01b0\u1ee3c \u0111i k\u00e8m v\u1edbi th\u00f4ng tin g\u00e1n nh\u00e3n. Ch\u00fang \u0111\u01b0\u1ee3c g\u00e1n nh\u00e3n theo m\u1ed9t s\u1ed1 \u0111\u1ecbnh d\u1ea1ng c\u1ee5 th\u1ec3 nh\u01b0 sau, v\u00ed d\u1ee5: </p> <ul> <li>\u00c2m v\u1ecb <code>text = \"ERO\"</code> s\u1ebd gi\u1eef nguy\u00ean n\u1ebfu ng\u01b0\u1eddi d\u00f9ng ph\u00e1t \u00e2m \u0111\u00fang.</li> <li>N\u1ebfu ph\u00e1t hi\u1ec7n l\u1ed7i ph\u00e1t \u00e2m sai nh\u00e3n s\u1ebd \u0111\u01b0\u1ee3c \u0111\u1ed5i th\u00e0nh <code>text = \"ER0,AH0,s\"</code>.<ul> <li><code>ERO</code> (correct phoneme label) l\u00e0 \u00e2m \u0111\u00fang l\u1ebd ra ng\u01b0\u1eddi \u0111\u1ecdc ph\u1ea3i ph\u00e1t \u00e2m.</li> <li><code>AHO</code> (perceived phoneme lable) l\u00e0 \u00e2m th\u1ef1c t\u1ebf m\u00e0 ng\u01b0\u1eddi n\u00f3i \u0111\u00e3 ph\u00e1t \u00e2m. B\u00ean c\u1ea1nh \u0111\u00f3 <code>err</code> s\u1ebd \u0111\u01b0\u1ee3c d\u00f9ng n\u1ebfu ng\u01b0\u1eddi d\u00f9ng ph\u00e1t \u00e2m kh\u00f4ng r\u00f5. </li> <li><code>s</code> (substitution) \u0111\u00e1nh \u0111\u1ea5u l\u00e0 l\u1ed7i thay th\u1ebf, ngo\u00e0i ra c\u00f2n c\u00f3 <code>a</code> (addition) l\u1ed7i th\u00eam \u00e2m v\u00e0 <code>d</code> (detection) l\u1ed7i b\u1ecf \u00e2m.</li> </ul> </li> </ul>"},{"location":"research/pronunciation-scoring/experiments/report02/#13-tien-xu-ly-chuan-bi-du-lieu","title":"1.3 Ti\u1ec1n x\u1eed l\u00fd &amp; Chu\u1ea9n b\u1ecb d\u1eef li\u1ec7u","text":"<p>\u0110\u1ec3 \u0111\u1ea3m b\u1ea3o d\u1eef li\u1ec7u ph\u00f9 h\u1ee3p v\u1edbi m\u00f4 h\u00ecnh v\u00e0 m\u1ee5c ti\u00eau c\u1ee7a b\u00e0i to\u00e1n m\u00e0 ch\u00fang ta mong mu\u1ed1n. B\u1ed9 d\u1eef li\u1ec7u L2-ARCTIC s\u1ebd \u0111\u01b0\u1ee3c thi\u1ebft k\u1ebf m\u1ed9t c\u00e1ch c\u1ee5 th\u1ec3 h\u01a1n ph\u1ee5c v\u1ee5 cho b\u00e0i to\u00e1n mispronunciation detect. D\u1ec5 d\u00e0ng quan s\u00e1t th\u1ea5y t\u1ea5t c\u1ea3 c\u00e1c file <code>.TextGrid</code> trong b\u1ed9 d\u1eef li\u1ec7u n\u00e0y \u0111\u00e3 ch\u1ee9a nh\u1eefng th\u00f4ng tin r\u1ea5t chi ti\u1ebft v\u1ec1 th\u1eddi gian b\u1eaft \u0111\u1ea7u v\u00e0 k\u1ebft th\u00fac c\u1ee7a t\u1eebng t\u1eeb, t\u1eebng \u00e2m v\u1ecb trong m\u1ed9t file <code>.wav</code> \u00e2m thanh. Tuy nhi\u00ean, c\u00e1c m\u00f4 h\u00ecnh y\u00eau c\u1ea7u \u0111\u1ea7u v\u00e0o ph\u1ea3i l\u00e0 c\u00e1c \u0111\u1eb7c tr\u01b0ng \u00e2m h\u1ecdc, gi\u00fap m\u00f4 h\u00ecnh bi\u1ebft \u0111\u01b0\u1ee3c vector \u0111\u1eb7c tr\u01b0ng \u00e2m h\u1ecdc n\u00e0y thu\u1ed9c v\u1ec1 \u00e2m v\u1ecb n\u00e0o v\u00e0 nh\u00e3n c\u1ee7a ch\u00fang ra sao. Nh\u01b0 \u0111\u00e3 \u0111\u1ec1 c\u1eadp \u1edf n\u1ed9i dung 1.2, c\u00f3 b\u1ed1n \u0111\u1ecbnh d\u1ea1ng \u0111\u00e1nh nh\u00e3n c\u01a1 b\u1ea3n cho t\u1eebng \u00e2m v\u1ecb, trong \u0111\u00f3 c\u00f3 m\u1ed9t \u0111\u1ecbnh d\u1ea1ng d\u00e0nh cho ph\u00e1t \u00e2m \u0111\u00fang v\u00e0 ba \u0111\u1ecbnh d\u1ea1ng cho ph\u00e1t \u00e2m sai. N\u1ebfu ng\u01b0\u1eddi h\u1ecdc ph\u00e1t \u00e2m \u0111\u00fang ta c\u00f3 th\u1ec3 coi l\u00e0 nh\u00e3n 0, n\u1ebfu ph\u00e1t \u00e2m sai nh\u00e3n s\u1ebd \u0111\u01b0\u1ee3c g\u00e1n theo 3 l\u1ed7i ch\u00ednh <code>s</code> (1 - l\u1ed7i thay th\u1ebf), <code>a</code> (2 - l\u1ed7i th\u00eam \u00e2m) v\u00e0 <code>d</code> (3 - l\u1ed7i b\u1ecf \u00e2m). Do v\u1eady, ch\u00fang ta c\u1ea7n ph\u1ea3i \u0111\u1ecbnh ngh\u0129a l\u1ea1i b\u1ed9 d\u1eef li\u1ec7u \u0111\u1ec3 \u0111\u1ea3m b\u1ea3o \u0111\u1ea7u v\u00e0o c\u00f3 \u0111\u1ea7y \u0111\u1ee7 nh\u1eefng y\u1ebfu t\u1ed1 tr\u00ean.</p> <p>Tr\u01b0\u1edbc ti\u00ean, h\u00e3y h\u00ecnh dung m\u1ed9t output m\u00e0 ta mong mu\u1ed1n m\u00f4 h\u00ecnh tr\u1ea3 v\u1ec1 m\u1ed7i khi nh\u1eadn \u0111\u01b0\u1ee3c m\u1ed9t file \u00e2m thanh b\u1ea5t k\u00ec. Gi\u1ea3 s\u1eed, v\u1edbi m\u1ed9t file \u00e2m thanh c\u00f3 t\u00ean <code>test0001.wav</code> v\u1edbi transcipts l\u00e0 <code>scoring</code>, m\u00f4 h\u00ecnh s\u1ebd tr\u1ea3 v\u1ec1 k\u1ebft qu\u1ea3 nh\u01b0 sau:</p> test001.json<pre><code>{\n    \"file\": \"test001.wav\",\n    \"transcipts\": \"scoring\",\n    \"x_min\": 0,\n    \"x_max\": 1.2,\n    \"total_score\": 0.7,\n    \"type\": \"IPA\",\n    \"phones\": {\n        \"s\": 2,\n        \"k\": 1,\n        \"\u0254\u02d0\": 0,\n        \"r\": 1,\n        \"i\": 1,\n        \"\u014b\": 3\n    }\n}\n</code></pre> <p>T\u1eeb k\u1ebft qu\u1ea3 n\u00e0y, d\u1ec5 d\u00e0ng c\u00f3 th\u1ec3 gi\u00fap ng\u01b0\u1eddi h\u1ecdc bi\u1ebft \u0111\u01b0\u1ee3c <code>total_score</code> - ng\u01b0\u1eddi h\u1ecdc ph\u00e1t \u00e2m \u0111\u00fang bao nhi\u00eau ph\u1ea7n tr\u0103m so v\u1edbi ng\u01b0\u1eddi b\u1ea3n \u0111\u1ecba, v\u00e0 li\u1ec7t k\u00ea m\u1ed9t <code>phones</code> - danh s\u00e1ch bao g\u1ed3m c\u00e1c \u00e2m v\u1ecb v\u00e0 nh\u00e3n t\u01b0\u01a1ng \u1ee9ng m\u00e0 m\u00f4 h\u00ecnh d\u1ef1 \u0111o\u00e1n ra. \u0110\u1ec3 \u0111\u1ea3m b\u1ea3o m\u00f4 h\u00ecnh h\u1ecdc \u0111\u01b0\u1ee3c m\u1ed1i li\u00ean h\u1ec7 gi\u1eefa c\u00e1c \u0111\u1eb7c tr\u01b0ng \u00e2m h\u1ecdc v\u00e0 c\u00e1c \u00e2m v\u1ecb t\u01b0\u01a1ng \u1ee9ng c\u0169ng nh\u01b0 l\u1ed7i ph\u00e1t \u00e2m, quy tr\u00ecnh ti\u1ec1n x\u1eed l\u00fd d\u1eef li\u1ec7u s\u1ebd bao g\u1ed3m c\u00e1c b\u01b0\u1edbc ch\u00ednh nh\u01b0 sau:</p> <p>B\u01b0\u1edbc 1: Tr\u00edch xu\u1ea5t \u0111\u1eb7c tr\u01b0ng \u00e2m h\u1ecdc</p> <ul> <li> <p>M\u1ed7i file \u00e2m thanh <code>.wav</code> \u0111\u01b0\u1ee3c \u0111\u01b0a qua m\u00f4 h\u00ecnh wav2vec 2.0 (\u0111\u00e2y l\u00e0 m\u00f4 h\u00ecnh t\u00f4i ch\u01b0a l\u1ef1a ch\u1ecdn cho qu\u00e1 tr\u00ecnh n\u00e0y), c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng c\u00e1c m\u00f4 h\u00ecnh \u00e2m h\u1ecdc t\u01b0\u01a1ng \u0111\u01b0\u01a1ng kh\u00e1c \u0111\u1ec3 tr\u00edch xu\u1ea5t \u0111\u1eb7c tr\u01b0ng.</p> </li> <li> <p>K\u1ebft qu\u1ea3 \u0111\u1ea7u ra sau khi tr\u00edch xu\u1ea5t l\u00e0 m\u1ed9t tensor c\u00f3 k\u00edch th\u01b0\u1edbc th\u01b0\u1eddng c\u00f3 d\u1ea1ng <code>[1, T, D]</code> v\u1edbi <code>T</code> l\u00e0 s\u1ed1 l\u01b0\u1ee3ng khung \u0111\u1eb7c tr\u01b0ng (frame) v\u00e0 <code>D</code> l\u00e0 chi\u1ec1u c\u1ee7a vector \u0111\u1eb7c tr\u01b0ng. M\u1ed7i khung \u00e2m thanh t\u01b0\u01a1ng \u1ee9ng v\u1edbi m\u1ed9t \u0111o\u1ea1n th\u1eddi gian c\u1ed1 \u0111\u1ecbnh (th\u01b0\u1eddng k\u00e9o d\u00e0i kho\u1ea3ng 20ms/frame, ph\u1ee5 thu\u1ed9c v\u00e0o t\u1eebng m\u00f4 h\u00ecnh).</p> </li> </ul> <p>B\u01b0\u1edbc 2: L\u1ea5y th\u00f4ng tin nh\u00e3n t\u1eeb file <code>.TextGrid</code></p> <ul> <li> <p>L\u1ea5y to\u00e0n b\u1ed9 c\u00e1c th\u00f4ng tin nh\u01b0 c\u00e1c kho\u00e0ng th\u1eddi gian (<code>xmin</code>, <code>xmax</code>) c\u1ee7a t\u1eebng \u00e2m v\u1ecb trong tier <code>phones</code> trong c\u00e1c file <code>.TextGrid</code> t\u01b0\u01a1ng \u1ee9ng.</p> </li> <li> <p>T\u1ea1i m\u1ed7i \u00e2m v\u1ecb ti\u1ebfn h\u00e0nh x\u1eed l\u00fd nh\u00e3n theo b\u1ed1n \u0111\u1ecbnh d\u1ea1ng \u0111\u00e3 \u0111\u01b0\u1ee3c ph\u00e2n t\u00edch \u1edf ph\u1ea7n tr\u01b0\u1edbc (v\u00ed d\u1ee5 <code>text = \"AH1\", \"T\", \"S\"</code>) s\u1ebd g\u00e1n l\u00e0 1, t\u01b0\u01a1ng t\u1ef1 v\u1edbi c\u00e1c m\u1eabu kh\u00e1c v\u00e0 nh\u00e3n kh\u00e1c.</p> </li> <li> <p>T\u00ednh to\u00e1n <code>total_score</code> c\u1ee7a to\u00e0n c\u00e2u \u0111\u1ec3 m\u00f4 t\u1ea3 m\u1ee9c \u0111\u1ed9 ch\u00ednh x\u00e1c trong ph\u00e1t \u00e2m c\u1ee7a ng\u01b0\u1eddi h\u1ecdc. C\u00f4ng th\u1ee9c t\u00ednh nh\u01b0 sau:</p> </li> </ul> \\[ \\text{total_score} = \\frac{A}{N} \\] <ul> <li>Trong \u0111\u00f3 \\(A\\) l\u00e0 s\u1ed1 l\u01b0\u1ee3ng \u00e2m v\u1ecb ph\u00e1t \u00e2m \u0111\u00fang (nh\u00e3n 0) v\u00e0 \\(N\\) l\u00e0 t\u1ed5ng s\u1ed1 \u00e2m v\u1ecb c\u00f3 trong c\u00e2u theo transcipts. </li> </ul> <p>B\u01b0\u1edbc 3: \u0110\u1ed1i chi\u1ebfu th\u1eddi gian v\u1edbi ch\u1ec9 s\u1ed1 frame</p> <ul> <li>\u0110\u1ec3 th\u1ef1c hi\u1ec7n vi\u1ec7c g\u00e1n nh\u00e3n ch\u00ednh x\u00e1c cho t\u1eebng \u0111o\u1ea1n \u0111\u1eb7c tr\u01b0ng, c\u1ea7n \u00e1nh x\u1ea1 m\u1ed7i <code>xmin</code>, <code>xmax</code> sang ch\u1ec9 s\u1ed1 frame t\u01b0\u01a1ng \u1ee9ng trong tensor \u0111\u1eb7c tr\u01b0ng c\u00f3 \u0111\u01b0\u1ee3c trong b\u01b0\u1edbc 1. B\u1eb1ng c\u00e1ch s\u1eed d\u1ee5ng c\u00f4ng th\u1ee9c sau, c\u00f3 th\u1ec3 d\u1ec5 d\u00e0ng x\u00e1c \u0111\u1ecbnh \u0111\u01b0\u1ee3c ch\u1ec9 s\u1ed1 frame:</li> </ul> \\[\\text{start_frame} = [\\frac{x_\\min}{\\text{stride}}]; \\quad \\text{end_frame} = [\\frac{x_\\max}{\\text{stride}}]\\] <ul> <li>Trong \u0111\u00f3 tham s\u1ed1 <code>stride</code> l\u00e0 kho\u1ea3ng th\u1eddi gian gi\u1eefa hai khung li\u00ean ti\u1ebfp (\u0111\u1ed1i v\u1edbi m\u00f4 h\u00ecnh wav2vec 2.0 l\u00e0 0.02 gi\u00e2y).</li> </ul> <p>B\u01b0\u1edbc 4: G\u00e1n nh\u00e3n cho m\u1ed7i \u0111o\u1ea1n \u0111\u1eb7c tr\u01b0ng</p> <ul> <li> <p>Sau khi t\u00e1ch \u0111\u01b0\u1ee3c m\u1ed7i \u0111o\u1ea1n (<code>start_frame</code>, <code>end_frame</code>), ti\u1ebfn h\u00e0nh c\u1eaft \u0111o\u1ea1n \u0111\u1eb7c tr\u01b0ng t\u01b0\u01a1ng \u1ee9ng v\u1edbi ch\u1ec9 s\u1ed1 n\u00e0y t\u1eeb tensor \u0111\u1eb7c tr\u01b0ng g\u1ed1c sau khi tr\u00edch xu\u1ea5t v\u00e0 g\u00e1n nh\u00e3n theo quy t\u1eafc (\u0111\u00e3 \u0111\u01b0\u1ee3c x\u1eed l\u00fd trong b\u01b0\u1edbc 2).</p> </li> <li> <p>V\u00ec c\u00e1c <code>phones</code> trong b\u1ed9 d\u1eef li\u1ec7u L2-ARCTIC \u0111\u01b0\u1ee3c ch\u00fa th\u00edch theo chu\u1ea9n ARPAbet, m\u00e0 b\u00e0i to\u00e1n ta mong mu\u1ed1n m\u00f4 h\u00ecnh h\u1ecdc \u0111\u01b0\u1ee3c ph\u00e1t \u00e2m theo chu\u1ea9n IPA, ch\u00ednh v\u00ec v\u1eady c\u00e1c k\u00ed t\u1ef1 \u00e2m v\u1ecb s\u1ebd \u0111\u01b0\u1ee3c chuy\u1ec3n \u0111\u1ed5i sang chu\u1ea9n n\u00e0y.</p> </li> </ul>"},{"location":"research/pronunciation-scoring/experiments/report02/#2-anh-gia-hieu-suat-mo-hinh","title":"2. \u0110\u00e1nh gi\u00e1 hi\u1ec7u su\u1ea5t m\u00f4 h\u00ecnh","text":"<p>\u0110\u00e1nh gi\u00e1 hi\u1ec7u su\u1ea5t m\u00f4 h\u00ecnh d\u1ef1a tr\u00ean th\u01b0\u1edbc \u0111o ph\u00e2n l\u1ecdai c\u01a1 b\u1ea3n. \u0110\u00e1nh gi\u00e1 c\u00e1c m\u00f4 h\u00ecnh d\u1ef1a tr\u00ean b\u1ed9 d\u1eef li\u1ec7u l2arctic, s\u1eed d\u1ee5ng F1-score.</p> Model Description F1-score MLP 3 t\u1ea7ng fully-connected 0.78 BiLSTM 2 t\u1ea7ng BiLSTM + pooling/attention 0.83 GOP-based T\u00ednh GOP t\u1eeb ASR (likelihood/posterior) sau \u0111\u00f3 classifier tr\u00ean GOP v\u00e0 k\u1ebft h\u1ee3p feature 0.71 Mini-Transformer 4 l\u1edbp Transformer encoder 0.82 <p>\u0110\u00e1nh gi\u00e1 hi\u1ec7u su\u1ea5t tr\u00ean b\u1ed9 d\u1eef li\u1ec7u kh\u00e1c. So s\u00e1nh kh\u1ea3 n\u0103ng kh\u00e1i qu\u00e1t h\u00f3a c\u1ee7a m\u00f4 h\u00ecnh tr\u00ean mi\u1ec1n d\u1eef li\u1ec7u ti\u1ebfng n\u00f3i kh\u00e1c. </p> Model Dataset F1-score MLP l2arctic 0.78 Speechocean762 0.65 EpaDB 0.61 BiLSTM l2arctic 0.83 Speechocean762 0.72 EpaDB 0.68 GOP-based l2arctic 0.75 Speechocean762 0.60 EpaDB 0.54 Mini-Transformer l2arctic 0.85 Speechocean762 0.65 EpaDB 0.75"}]}