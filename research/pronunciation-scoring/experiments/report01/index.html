
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../../../../octicons/book-24">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.20">
    
    
      
        <title>Tổng quan về Pronunciation Scoring - PS - OpenNotesHub</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.e53b48f4.min.css">
      
        
        <link rel="stylesheet" href="../../../../assets/stylesheets/palette.06af60db.min.css">
      
      
  
  
    
      
      
    
  
    
      
      
    
  
    
      
      
    
  
    
      
      
    
  
    
      
      
    
  
    
      
      
    
  
    
      
      
    
  
    
      
      
    
  
    
      
      
    
  
    
      
      
    
  
    
      
      
    
  
    
      
      
    
  
  
  <style>:root{--md-admonition-icon--note:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M1%207.775V2.75C1%201.784%201.784%201%202.75%201h5.025c.464%200%20.91.184%201.238.513l6.25%206.25a1.75%201.75%200%200%201%200%202.474l-5.026%205.026a1.75%201.75%200%200%201-2.474%200l-6.25-6.25A1.75%201.75%200%200%201%201%207.775m1.5%200c0%20.066.026.13.073.177l6.25%206.25a.25.25%200%200%200%20.354%200l5.025-5.025a.25.25%200%200%200%200-.354l-6.25-6.25a.25.25%200%200%200-.177-.073H2.75a.25.25%200%200%200-.25.25ZM6%205a1%201%200%201%201%200%202%201%201%200%200%201%200-2%22/%3E%3C/svg%3E');--md-admonition-icon--abstract:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M2.5%201.75v11.5c0%20.138.112.25.25.25h3.17a.75.75%200%200%201%200%201.5H2.75A1.75%201.75%200%200%201%201%2013.25V1.75C1%20.784%201.784%200%202.75%200h8.5C12.216%200%2013%20.784%2013%201.75v7.736a.75.75%200%200%201-1.5%200V1.75a.25.25%200%200%200-.25-.25h-8.5a.25.25%200%200%200-.25.25m13.274%209.537zl-4.557%204.45a.75.75%200%200%201-1.055-.008l-1.943-1.95a.75.75%200%200%201%201.062-1.058l1.419%201.425%204.026-3.932a.75.75%200%201%201%201.048%201.074M4.75%204h4.5a.75.75%200%200%201%200%201.5h-4.5a.75.75%200%200%201%200-1.5M4%207.75A.75.75%200%200%201%204.75%207h2a.75.75%200%200%201%200%201.5h-2A.75.75%200%200%201%204%207.75%22/%3E%3C/svg%3E');--md-admonition-icon--info:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M0%208a8%208%200%201%201%2016%200A8%208%200%200%201%200%208m8-6.5a6.5%206.5%200%201%200%200%2013%206.5%206.5%200%200%200%200-13M6.5%207.75A.75.75%200%200%201%207.25%207h1a.75.75%200%200%201%20.75.75v2.75h.25a.75.75%200%200%201%200%201.5h-2a.75.75%200%200%201%200-1.5h.25v-2h-.25a.75.75%200%200%201-.75-.75M8%206a1%201%200%201%201%200-2%201%201%200%200%201%200%202%22/%3E%3C/svg%3E');--md-admonition-icon--tip:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M3.499.75a.75.75%200%200%201%201.5%200v.996C5.9%202.903%206.793%203.65%207.662%204.376l.24.202c-.036-.694.055-1.422.426-2.163C9.1.873%2010.794-.045%2012.622.26%2014.408.558%2016%201.94%2016%204.25c0%201.278-.954%202.575-2.44%202.734l.146.508.065.22c.203.701.412%201.455.476%202.226.142%201.707-.4%203.03-1.487%203.898C11.714%2014.671%2010.27%2015%208.75%2015h-6a.75.75%200%200%201%200-1.5h1.376a4.5%204.5%200%200%201-.563-1.191%203.84%203.84%200%200%201-.05-2.063%204.65%204.65%200%200%201-2.025-.293.75.75%200%200%201%20.525-1.406c1.357.507%202.376-.006%202.698-.318l.009-.01a.747.747%200%200%201%201.06%200%20.75.75%200%200%201-.012%201.074c-.912.92-.992%201.835-.768%202.586.221.74.745%201.337%201.196%201.621H8.75c1.343%200%202.398-.296%203.074-.836.635-.507%201.036-1.31.928-2.602-.05-.603-.216-1.224-.422-1.93l-.064-.221c-.12-.407-.246-.84-.353-1.29a2.4%202.4%200%200%201-.507-.441%203.1%203.1%200%200%201-.633-1.248.75.75%200%200%201%201.455-.364c.046.185.144.436.31.627.146.168.353.305.712.305.738%200%201.25-.615%201.25-1.25%200-1.47-.95-2.315-2.123-2.51-1.172-.196-2.227.387-2.706%201.345-.46.92-.27%201.774.019%203.062l.042.19.01.05c.348.443.666.949.94%201.553a.75.75%200%201%201-1.365.62c-.553-1.217-1.32-1.94-2.3-2.768L6.7%205.527c-.814-.68-1.75-1.462-2.692-2.619a3.7%203.7%200%200%200-1.023.88c-.406.495-.663%201.036-.722%201.508.116.122.306.21.591.239.388.038.797-.06%201.032-.19a.75.75%200%200%201%20.728%201.31c-.515.287-1.23.439-1.906.373-.682-.067-1.473-.38-1.879-1.193L.75%205.677V5.5c0-.984.48-1.94%201.077-2.664.46-.559%201.05-1.055%201.673-1.353z%22/%3E%3C/svg%3E');--md-admonition-icon--success:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M13.78%204.22a.75.75%200%200%201%200%201.06l-7.25%207.25a.75.75%200%200%201-1.06%200L2.22%209.28a.75.75%200%200%201%20.018-1.042.75.75%200%200%201%201.042-.018L6%2010.94l6.72-6.72a.75.75%200%200%201%201.06%200%22/%3E%3C/svg%3E');--md-admonition-icon--question:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M0%208a8%208%200%201%201%2016%200A8%208%200%200%201%200%208m8-6.5a6.5%206.5%200%201%200%200%2013%206.5%206.5%200%200%200%200-13M6.92%206.085h.001a.749.749%200%201%201-1.342-.67c.169-.339.436-.701.849-.977C6.845%204.16%207.369%204%208%204a2.76%202.76%200%200%201%201.637.525c.503.377.863.965.863%201.725%200%20.448-.115.83-.329%201.15-.205.307-.47.513-.692.662-.109.072-.22.138-.313.195l-.006.004a6%206%200%200%200-.26.16%201%201%200%200%200-.276.245.75.75%200%200%201-1.248-.832c.184-.264.42-.489.692-.661q.154-.1.313-.195l.007-.004c.1-.061.182-.11.258-.161a1%201%200%200%200%20.277-.245C8.96%206.514%209%206.427%209%206.25a.61.61%200%200%200-.262-.525A1.27%201.27%200%200%200%208%205.5c-.369%200-.595.09-.74.187a1%201%200%200%200-.34.398M9%2011a1%201%200%201%201-2%200%201%201%200%200%201%202%200%22/%3E%3C/svg%3E');--md-admonition-icon--warning:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M6.457%201.047c.659-1.234%202.427-1.234%203.086%200l6.082%2011.378A1.75%201.75%200%200%201%2014.082%2015H1.918a1.75%201.75%200%200%201-1.543-2.575Zm1.763.707a.25.25%200%200%200-.44%200L1.698%2013.132a.25.25%200%200%200%20.22.368h12.164a.25.25%200%200%200%20.22-.368Zm.53%203.996v2.5a.75.75%200%200%201-1.5%200v-2.5a.75.75%200%200%201%201.5%200M9%2011a1%201%200%201%201-2%200%201%201%200%200%201%202%200%22/%3E%3C/svg%3E');--md-admonition-icon--failure:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M2.344%202.343za8%208%200%200%201%2011.314%2011.314A8.002%208.002%200%200%201%20.234%2010.089a8%208%200%200%201%202.11-7.746m1.06%2010.253a6.5%206.5%200%201%200%209.108-9.275%206.5%206.5%200%200%200-9.108%209.275M6.03%204.97%208%206.94l1.97-1.97a.749.749%200%200%201%201.275.326.75.75%200%200%201-.215.734L9.06%208l1.97%201.97a.749.749%200%200%201-.326%201.275.75.75%200%200%201-.734-.215L8%209.06l-1.97%201.97a.749.749%200%200%201-1.275-.326.75.75%200%200%201%20.215-.734L6.94%208%204.97%206.03a.75.75%200%200%201%20.018-1.042.75.75%200%200%201%201.042-.018%22/%3E%3C/svg%3E');--md-admonition-icon--danger:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M9.504.43a1.516%201.516%200%200%201%202.437%201.713L10.415%205.5h2.123c1.57%200%202.346%201.909%201.22%203.004l-7.34%207.142a1.25%201.25%200%200%201-.871.354h-.302a1.25%201.25%200%200%201-1.157-1.723L5.633%2010.5H3.462c-1.57%200-2.346-1.909-1.22-3.004zm1.047%201.074L3.286%208.571A.25.25%200%200%200%203.462%209H6.75a.75.75%200%200%201%20.694%201.034l-1.713%204.188%206.982-6.793A.25.25%200%200%200%2012.538%207H9.25a.75.75%200%200%201-.683-1.06l2.008-4.418.003-.006-.004-.009-.006-.006-.008-.001q-.005%200-.009.004%22/%3E%3C/svg%3E');--md-admonition-icon--bug:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M4.72.22a.75.75%200%200%201%201.06%200l1%20.999a3.5%203.5%200%200%201%202.441%200l.999-1a.748.748%200%200%201%201.265.332.75.75%200%200%201-.205.729l-.775.776c.616.63.995%201.493.995%202.444v.327q0%20.15-.025.292c.408.14.764.392%201.029.722l1.968-.787a.75.75%200%200%201%20.556%201.392L13%207.258V9h2.25a.75.75%200%200%201%200%201.5H13v.5q-.002.615-.141%201.186l2.17.868a.75.75%200%200%201-.557%201.392l-2.184-.873A5%205%200%200%201%208%2016a5%205%200%200%201-4.288-2.427l-2.183.873a.75.75%200%200%201-.558-1.392l2.17-.868A5%205%200%200%201%203%2011v-.5H.75a.75.75%200%200%201%200-1.5H3V7.258L.971%206.446a.75.75%200%200%201%20.558-1.392l1.967.787c.265-.33.62-.583%201.03-.722a1.7%201.7%200%200%201-.026-.292V4.5c0-.951.38-1.814.995-2.444L4.72%201.28a.75.75%200%200%201%200-1.06m.53%206.28a.75.75%200%200%200-.75.75V11a3.5%203.5%200%201%200%207%200V7.25a.75.75%200%200%200-.75-.75ZM6.173%205h3.654A.17.17%200%200%200%2010%204.827V4.5a2%202%200%201%200-4%200v.327c0%20.096.077.173.173.173%22/%3E%3C/svg%3E');--md-admonition-icon--example:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M5%205.782V2.5h-.25a.75.75%200%200%201%200-1.5h6.5a.75.75%200%200%201%200%201.5H11v3.282l3.666%205.76C15.619%2013.04%2014.543%2015%2012.767%2015H3.233c-1.776%200-2.852-1.96-1.899-3.458Zm-2.4%206.565a.75.75%200%200%200%20.633%201.153h9.534a.75.75%200%200%200%20.633-1.153L12.225%2010.5h-8.45ZM9.5%202.5h-3V6c0%20.143-.04.283-.117.403L4.73%209h6.54L9.617%206.403A.75.75%200%200%201%209.5%206Z%22/%3E%3C/svg%3E');--md-admonition-icon--quote:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M1.75%202.5h10.5a.75.75%200%200%201%200%201.5H1.75a.75.75%200%200%201%200-1.5m4%205h8.5a.75.75%200%200%201%200%201.5h-8.5a.75.75%200%200%201%200-1.5m0%205h8.5a.75.75%200%200%201%200%201.5h-8.5a.75.75%200%200%201%200-1.5M2.5%207.75v6a.75.75%200%200%201-1.5%200v-6a.75.75%200%200%201%201.5%200%22/%3E%3C/svg%3E');}</style>



    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="blue-grey" data-md-color-accent="red">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#nen-tang-va-phuong-phap-xu-ly-tieng-noi-cho-anh-gia-phat-am" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../.." title="OpenNotesHub" class="md-header__button md-logo" aria-label="OpenNotesHub" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M0 1.75A.75.75 0 0 1 .75 1h4.253c1.227 0 2.317.59 3 1.501A3.74 3.74 0 0 1 11.006 1h4.245a.75.75 0 0 1 .75.75v10.5a.75.75 0 0 1-.75.75h-4.507a2.25 2.25 0 0 0-1.591.659l-.622.621a.75.75 0 0 1-1.06 0l-.622-.621A2.25 2.25 0 0 0 5.258 13H.75a.75.75 0 0 1-.75-.75Zm7.251 10.324.004-5.073-.002-2.253A2.25 2.25 0 0 0 5.003 2.5H1.5v9h3.757a3.75 3.75 0 0 1 1.994.574M8.755 4.75l-.004 7.322a3.75 3.75 0 0 1 1.992-.572H14.5v-9h-3.495a2.25 2.25 0 0 0-2.25 2.25"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            OpenNotesHub
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Tổng quan về Pronunciation Scoring - PS
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/nthaihoc/open-notes-hub" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    nthaihoc/open-notes-hub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../" class="md-tabs__link">
          
  
  
    
  
  Research Logs

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../courses/" class="md-tabs__link">
          
  
  
    
  
  Course Notes

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../knowledge-base/" class="md-tabs__link">
          
  
  
    
  
  Knowledge Base

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="OpenNotesHub" class="md-nav__button md-logo" aria-label="OpenNotesHub" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M0 1.75A.75.75 0 0 1 .75 1h4.253c1.227 0 2.317.59 3 1.501A3.74 3.74 0 0 1 11.006 1h4.245a.75.75 0 0 1 .75.75v10.5a.75.75 0 0 1-.75.75h-4.507a2.25 2.25 0 0 0-1.591.659l-.622.621a.75.75 0 0 1-1.06 0l-.622-.621A2.25 2.25 0 0 0 5.258 13H.75a.75.75 0 0 1-.75-.75Zm7.251 10.324.004-5.073-.002-2.253A2.25 2.25 0 0 0 5.003 2.5H1.5v9h3.757a3.75 3.75 0 0 1 1.994.574M8.755 4.75l-.004 7.322a3.75 3.75 0 0 1 1.992-.572H14.5v-9h-3.495a2.25 2.25 0 0 0-2.25 2.25"/></svg>

    </a>
    OpenNotesHub
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/nthaihoc/open-notes-hub" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    nthaihoc/open-notes-hub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Research Logs
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2" id="__nav_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Research Logs
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../cervical-cancer-cytology/" class="md-nav__link ">
              
  
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 14h-4v4h-4v-4H6v-4h4V6h4v4h4m1-7H5c-1.11 0-2 .89-2 2v14a2 2 0 0 0 2 2h14a2 2 0 0 0 2-2V5a2 2 0 0 0-2-2"/></svg>
  
  <span class="md-ellipsis">
    Cervical Cancer Cytology
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            Cervical Cancer Cytology
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cervical-cancer-cytology/experiments/exp-01-ensemble_learning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Experiment 01. Data Aggeration Training Evaluation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cervical-cancer-cytology/experiments/exp-02-self_supervised_learning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Experiment 02. Self Supervised Learning
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../../courses/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Course Notes
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3" id="__nav_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Course Notes
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../courses/applied-machine-learning/" class="md-nav__link">
        
  
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m5 12 2-4V7H4v1h2l-2 4m5 0 2-4V7H8v1h2l-2 4m5 0 2-4V7h-3v1h2l-2 4m9-10c-1.1 0-2 .9-2 2 0 .7.4 1.4 1 1.7V17h-3v-2c.6 0 1-.4 1-1V5c0-.6-.4-1-1-1h-3.8c-.8-1.2-2.2-2-3.7-2s-2.9.8-3.7 2H2c-.6 0-1 .4-1 1v9c0 .6.4 1 1 1v7h15v-3h3c1.1 0 2-.9 2-2V5.7c.6-.3 1-1 1-1.7 0-1.1-.9-2-2-2m-8 17H6v-2h7zm3-6H3V6h13z"/></svg>
  
  <span class="md-ellipsis">
    Applied Machine Learning
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_3" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../../courses/large-language-models/" class="md-nav__link ">
              
  
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 2H4a2 2 0 0 0-2 2v18l4-4h14a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2"/></svg>
  
  <span class="md-ellipsis">
    Large Language Models
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_3" id="__nav_3_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_3">
            <span class="md-nav__icon md-icon"></span>
            Large Language Models
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../courses/large-language-models/lesson-03-attention_mechanisms_knowledge_base.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Lesson 03. Attention Mechanisms
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../../knowledge-base/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Knowledge Base
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4" id="__nav_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Knowledge Base
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_2" >
        
          
          <label class="md-nav__link" for="__nav_4_2" id="__nav_4_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    FastAPI Tutorials
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_2">
            <span class="md-nav__icon md-icon"></span>
            FastAPI Tutorials
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../knowledge-base/fastapi-tutorials/README.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    FastAPI Tutorials
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../knowledge-base/fastapi-tutorials/lesson-01-fastapi_overview_and_project_setup.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Lesson 01. FastAPI Overview and Project Setup
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  

<nav class="md-nav md-nav--secondary" aria-label="Table of Contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of Contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#bai-toan-anh-gia-phat-am" class="md-nav__link">
    <span class="md-ellipsis">
      Bài toán đánh giá phát âm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cac-nghien-cuu-lien-quan" class="md-nav__link">
    <span class="md-ellipsis">
      Các nghiên cứu liên quan
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Các nghiên cứu liên quan">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#goodness-of-pronunciation" class="md-nav__link">
    <span class="md-ellipsis">
      Goodness of Pronunciation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deep-neural-networks" class="md-nav__link">
    <span class="md-ellipsis">
      Deep Neural Networks
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-mot-so-phuong-phap-noi-bat" class="md-nav__link">
    <span class="md-ellipsis">
      2. Một số phương pháp nổi bật
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. Một số phương pháp nổi bật">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21-goodness-of-pronuncation" class="md-nav__link">
    <span class="md-ellipsis">
      2.1 Goodness of Pronuncation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22-deep-neural-networks-based-gop" class="md-nav__link">
    <span class="md-ellipsis">
      2.2 Deep Neural Networks based GOP
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#23-wav2vec" class="md-nav__link">
    <span class="md-ellipsis">
      2.3 wav2vec
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#24-mot-so-phuong-phap-khac" class="md-nav__link">
    <span class="md-ellipsis">
      2.4 Một số phương pháp khác
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="nen-tang-va-phuong-phap-xu-ly-tieng-noi-cho-anh-gia-phat-am">Nền tảng và phương pháp xử lý tiếng nói cho đánh giá phát âm</h1>
<hr />
<div class="admonition danger">
<p class="admonition-title">Mô tả</p>
<p>Phần này sẽ đề cập đến những nền tảng cơ bản của Trí tuệ nhân tạo trong xử lý tiếng nói, đặc biệt là trong các bài toán đánh giá và chấm điể phát âm. Một số nội dung sẽ được đề cập đến:</p>
<ul>
<li>Giới thiệu tổng quan về hệ thống hỗ trợ học ngôn ngữ.</li>
<li>Cơ sở lý thuyết của xử lý tiếng nói.</li>
<li>Trình bày, khảo sát các công trình nghiên cứu liên quan.</li>
<li>Tổng quan về bài toán chấm điểm phát âm.</li>
</ul>
</div>
<h2 id="bai-toan-anh-gia-phat-am">Bài toán đánh giá phát âm</h2>
<hr />
<p>Trong bối cảnh toàn cầu hóa, việc học ngoại ngữ trở nên quan trọng hơn bao giờ hết. Sự phát triển của công nghệ thông tin đa thúc đẩy sự phổ biến của các hệ thống học ngoại ngữ có sự hỗ trợ của máy tính (Computer Assisted Language Learning - CALL), cho phép người học rèn luyện và tiến bộ ngay cả khi không có giáo viên trực tiếp hướng dẫn. Trong số đó, các hệ thống luyện phát âm có sự hỗ trợ của máy tính (Computer Aided Pronunciation Training - CAPT) nổi bật nhờ khả năng hỗ trợ cải thiện phát âm - một kỹ năng vốn khó luyện tập nếu thiếu giảng viên cá nhân.</p>
<p>Các hệ thống CAPT có thể đánh giá chất lượng phát âm ở nhiều cấp độ khác nhau: cụm từ, từ hoặc âm vị. Trong đó, chấm điểm phát âm ở mức âm vị là chi tiết và thách thức nhất, bởi lượng dữ liệu dùng để đánh giá mỗi đơn vị âm thanh là rất nhỏ. Tuy nhiên, mức độ này lại đặc biệt hữu ích cho người học mới, vì chúng cung cấp thông tin chi tiết hơn và chỉ ra lỗi phát âm cụ thể ở từng âm vị, trong khi đánh giá ở mức cụm từ chỉ phản ánh tổng quan.</p>
<h2 id="cac-nghien-cuu-lien-quan">Các nghiên cứu liên quan</h2>
<h3 id="goodness-of-pronunciation">Goodness of Pronunciation</h3>
<p>Một trong những hệ thống đánh giá phát âm ở mức phone sớm nhất được gọi là Goodness of Pronunciation (GOP), dựa trên các mô hình Automatic Speech Recognition (ASR), vốn được sử dụng để tự động chuyển đổi lời nói thành văn bản. Khi phương pháp GOP lần đầu được đề xuất, các mô hình ASR chủ yếu dựa trên Hidden Markov Models (HMM), trong đó mỗi phone được huấn luyện với Gaussian Mixture Models (GMM) làm hàm mật độ xác suất để mô tả sự kiện âm thanh.</p>
<p>Phương pháp GOP đánh giá chất lượng phát âm của một phone cụ thể <span class="arithmatex">\(p\)</span> bằng logarit của xác suất hậu nghiệm <span class="arithmatex">\(P(p | O(p))\)</span>, tức là xác xuất người nói phát âm đúng phone <span class="arithmatex">\(p\)</span> dựa trên quan sát đoạn âm thanh <span class="arithmatex">\(O(p)\)</span>, sau đó chuẩn hóa theo độ dài (số frame) của phone.</p>
<div class="arithmatex">\[GOP(p) = \log \frac{P(p | O(p))}{NF(p)}\]</div>
<p>Áp dụng định lý Bayes, điểm số này có thể được ước lượng thông qua xác suất khả năng xảy ra <span class="arithmatex">\(p(O(p) | p)\)</span> được tính từ mô hình GMM-HMM đã nêu. Khi đó, công thức GOP trở thành:</p>
<div class="arithmatex">\[
GOP(p) = \left( \log \frac{p(O(p)|p) \cdot P(p)}{\sum_{q\in Q} p(O(p)|q) \cdot P(q)} \right) \Bigg/ NF(p)
\]</div>
<p>Trong đó:</p>
<ul>
<li><span class="arithmatex">\(Q\)</span> là tập hợp tất cả các phone</li>
<li><span class="arithmatex">\(NF(p)\)</span> là số frame mà phone <span class="arithmatex">\(p\)</span> chiếm</li>
<li><span class="arithmatex">\(p(O(p) | p)\)</span> ở tử số được xác định bằng cách căn chỉnh transcription đã biết với bản ghi âm thông qua thuật toán Viterbi, sử dụng mô hình GMM-HMM</li>
<li><span class="arithmatex">\(p(O(p) | q)\)</span> ở mẫu số cũng được tính từ mô hình GMM-HMM, nhưng không bị ràng buộc bởi transcription nào cả</li>
</ul>
<p>Có thể hiểu, điểm GOP như một thước đo mức độ tự tin của mô hình ASR khi dự đoán một phone. Phone nào được phát âm càng gần với chuẩn của người bản ngữ thì xác suất của phone đó càng cao, do đó GOP cũng càng lớn. Vì GOP là log-likelihood nên nếu likelihood bằng 1 thì GOP sẽ bằng 0, nếu likelihood nhỏ hơn một thì GOP sẽ nhỏ hơn 0.</p>
<p>Để đơn giản hóa công thức trên có thể xấp xỉ tổng ở mẫu số bằng giá trị lớn nhất, giúp tính toán nhanh hơn. Hoặc giả sử tất cả các phone trong tập có xác suất tiên nghiệm bằng nhau, khi đó các xác suất này sẽ triệt tiêu lẫn nhau. Với các điều chỉnh này, công thức GOP có thể viết đơn giản hơn:</p>
<div class="arithmatex">\[
\left( GOP(p) = \log \frac{p(O(p)| p)}{\max_{q \in Q} p(O(p) | q)} \right) \Bigg/ NF(p)
\]</div>
<p>Công thức GOP ngầm mô tả rằng sau khi các đặc trưng âm thanh được đưa vào mô hình GMM-HMM, mô hình sẽ tính xác suất của từng phone dựa trên các frame tương ứng. Điểm GOP của một phone <span class="arithmatex">\(p\)</span> được xác định bằng cách so sánh xác suất của phone đó với xác suất của tất cả các phone khác: nếu một phone <span class="arithmatex">\(q\)</span> khác có xác suất cao hơn phone <span class="arithmatex">\(p\)</span> thì GOP của <span class="arithmatex">\(p\)</span> sẽ thấp, phản ánh rằng mô hình không chắc chắn về phát âm của phone <span class="arithmatex">\(p\)</span>; ngược lại, nếu xác suất của phone <span class="arithmatex">\(p\)</span> cao nhất, GOP sẽ cao, cho thấy phát âm gần chuẩn của người bản ngữ.</p>
<h3 id="deep-neural-networks">Deep Neural Networks</h3>
<p>Trong những năm gần đây, sự phát triển mạnh mẽ của mạng nơ-ron sâu (Deep Networks - DNNs) đã tạo ra những bước tiến lớn trong nhiều lĩnh vực của trí tuệ nhân tạo, trong ddso có nhận dạng tiếng nói tự động (ASR - Automation Speech Recognition)
. Do các hệ thống chấm điểm phát âm phần lớn dựa vào công nghệ ASR, những tiến bộ này nhanh chóng được ứng dụng để cải thiện chất lượng đánh giá phát âm, vượt trội so với các phương phap truyền thống cả khi sử dụng dữ liệu bản ngữ lẫn dữ liệu người học.</p>
<p>Một trong những phương pháp cơ bản thường được sử dụng làm chuẩn so sánh là Goodness of Pronunciation. Phiên bản gốc của GOP dựa trên mô hình GMM-HMM, trong đó xác suất hậu nghiệm của một âm vị <span class="arithmatex">\(P(p | O(p))\)</span> được suy ra từ xác suất điều kiện <span class="arithmatex">\(p(O(p) | p)\)</span> thông qua định lý Bayes. Cách tiếp cận này tuy hiệu quả ở thời điểm ban đầu nhưng phụ thuộc nặng nề vào việc ước lượng xác suất bằng mô hình GMM truyền thống, vốn có hạn chế trong việc biểu diễn dữ liệu phức tạp. Với sự xuất hiện của DNN, phương pháp GOP đã được mở rộng sang dạng DNN-HMM, trong đó mô hình nơ-ron có thể dự đoán trực tiếp phân bố xác suất hậu nghiệm của các trạng thái HMM dựa trên các đặc trưng âm học đầu vào. Điều này giúp loại bỏ nhu cầu sử dụng định lý Bayes, đồng thời tận dụng được khả năng học biểu diễn mạnh mẽ của DNN. Kỹ thuật này thường được gọi là DNN-GOP và đã trở thành một baseline phổ biến trong các nghiên cứu sau này.</p>
<p>Tuy nhiên, một trong những thách thức lớn trong việc xây dựng hệ thống chấm điểm phát âm chính là tình trạng khan hiếm dữ liệu. Dữ liệu của người học (non-native data) vừa khó thu thập, vừa tốn kém trong khâu gán nhãn, trong khi các mô hình chỉ huấn luyện trên dữ liệu người bản ngữ lại không phản ánh đầy đủ những lỗi phát âm phổ biến trong thực tế. Để khắc phục hạn chế này, nhiều nghiên cứu gần đây đã khai thác học chuyển giao (transfer learning), tức là tận dụng tri thức từ các mô hình đã được huấn luyện trước trên một tác vụ nguồn, rồi tinh chỉnh (fine-tune) cho tác vụ đích. Cách tiếp cận này đặc biệt hiệu quả trong bối cảnh dữ liệu hạn chế, vì cho phép kế thừa các đặc trưng đã học từ tập dữ liệu quy mô lớn mà không cần xây dựng lại toàn bộ mô hình từ đầu.</p>
<p>Song song với đó, các kỹ thuật học tự giám sát (self-supervised learning) đã nổi lên như một hướng đi đầy hứa hẹn. Thay vì phụ thuộc vào dữ liệu có nhãn, các mô hình tự giám sát được huấn luyện trên một lượng dữ liệu khổng lồ không gán nhãn, thông qua các nhiệm vụ tiền huấn luyện (pretext tasks) như dự đoán khung âm thanh bị che khuất hoặc tái tạo tín hiệu giọng nói. Khi áp dụng cho một bài toán cụ thể, những mô hình đã được huấn luyện theo cách này chỉ cần tinh chỉnh bằng một lượng nhỏ dữ liệu có nhãn nhưng vẫn đạt được hiệu quả cao, thậm chí vượt trội so với các phương pháp huấn luyện truyền thống.</p>
<p>Từ những nghiên cứu trên có thể rút ra hai xu hướng chính. Thứ nhất, các mô hình DNN-GOP đã chứng minh ưu thế vượt trội so với phương pháp GMM-HMM truyền thống trong việc ước lượng xác súât hậu nghiệm phục vụ chấm điểm phát âm. Thứ hai, việc áp dụng học chuyển giao cho phép các hệ thóng đạt hiệu quả cao hơn trong điều kiện dữ liệu khan hiếm, đồng thời giảm chi phí huấn luyện. </p>
<p>Hệ thống hỗ trợ học ngôn ngữ bằng máy tính (Computer-Assisted Language Learing - CALL) mang lại nhiều lợi ích thiết thực trong giáo dục, đặc biệt là đối với giáo viên và học sinh. Những hệ thống này cho phép cung cấp phản hồi liên tục cho người học mà không cần sự giám sát thường trực của giáo viên, hỗ trợ việc tự học, khuyến khích sử dụng ngôn ngữ một cách tương tác thay vì phụ thuộc vào các phương pháp học truyền thống như học thuộc lòng hay ghi chép. Bên cạnh đó, CALL cũng góp phần đơn giản hóa và tự động hóa các quy trình đánh giá năng lực ngôn ngữ.</p>
<p>Một trong những thành phần cốt lõi và đầy thác thức trong hệ thông CALL là chấm điểm phát âm (Pronuncation Scoring). Đây là nhiệm vụ quan trọng nhằm đánh giá mức độ chĩnh xác trong các phát âm của người học so với chuẩn của người bản ngữ. Hệ thống chầm điểm phát âm hiệu quả không chỉ giúp phát hiện và sửa lỗi kịp thời mà còn cung cấp phản hồi mang tính dài hạn về năng lực phát âm của người học.</p>
<p>Trong nhiều năm qua, đã có rất nhiều các nghiên cứu, hướng tiếp cận chính như:</p>
<ul>
<li>
<p>Phương pháp dựa trên mô hình nhận dạng tiếng nói (ASR-based methods): Đây là một trong những phương pháp cổ điển và rất phổ biến, trong đó hệ thống nhận dạng giọng nói thường sử dụng mô hình Markov ẩn (Hidden Markow Model) nhằm so sánh phát âm của người học với các mô hình âm học chuẩn. Một trong những kỹ thuật nổi bật là thuật toán Goodness of Pronunciation (GOP) cho phép tính điểm phát âm ở cấp độ âm vị (phone-level).</p>
</li>
<li>
<p>Đánh giá dựa trên so sánh với mẫu người bản ngữ (Template-based / Reference-based methods): Các phương pháp này so sánh trực tiếp tín hiệu âm thanh của người học với bản ghi âm từ người bản ngữ. Chúng thường yêu cầu dữ liệu huấn luyện riêng cho từng từ hoặc cụm từ, khiến hệ thống trở nên text-dependent và rất khó để có thể mở rộng.</p>
</li>
<li>
<p>Mô hình học máy và học sâu (Machine Learning / Deep Learning-based methods): Gần đây, các mô hình học sâu như CNN, RNN và đặc biệt là các mô hình transformer-based (wav2vec, HuBERT, v.v.) đước sử dụng để trích xuất đặc trưng âm học và xây dựng bộ chấm điểm phát âm mà không cần phải phụ thuộc hoàn toán vào pipeline của hệ thống nhận dạng truyền thống.</p>
</li>
</ul>
<p>Ngoài ra, các nghiên cứu khác cũng khai thác triệt để những yếu tố đặc trưng của âm thanh như trường độ, ngữ điệu, v.v, nhằm đánh giá chất lượng phát âm một cách toán diện hơn. Tuy nhiên, chúng vấn đang gặp phải rất nhiều những thách thức liên quan đến sự phụ thuộc vào dữ liệu, sự nhất quát và công bằng trong đánh giá và sự thích nghi khi dữ liệu giọng nói đa dạng. </p>
<h2 id="2-mot-so-phuong-phap-noi-bat">2. Một số phương pháp nổi bật</h2>
<hr />
<h3 id="21-goodness-of-pronuncation"><strong>2.1 Goodness of Pronuncation</strong></h3>
<p><a href="http://svr-www.eng.cam.ac.uk/~sjy/papers/wiyo00.pdf"><strong>GOP (Goodness of Pronunciation)</strong></a> là phương pháp là một trong những kỹ thuật nổi bật, với mục tiêu đo lường mức độ khớp giữa phát âm của người học và cách phát âm chuẩn của người bản ngữ, tính tại mức âm vị (phone-level). Gỉa sử khi chúng ta phát âm từ <strong>cat</strong> nó sẽ có hai âm vị là <strong>/ka/</strong> và <strong>/et/</strong>. GOP sẽ chấm điểm xem người dùng đã phát âm <strong>/ka/</strong> tốt đến đâu và <strong>/et/</strong> tốt đến đâu. </p>
<div class="admonition info">
<p class="admonition-title"><strong>Công thức GOP</strong></p>
<div class="arithmatex">\[
\textbf{GOP} = \frac{1}{NF_\text{(p)}} \cdot \left| \text{log} \left( \frac{p(O^\text{(p)}) | p}{\max_{q \in \mathbf{Q}} p(O^\text{(p)}) | q} \right) \right|
\]</div>
<p><ins>Trong đó:</ins></p>
<ul>
<li>
<p>Tử số <span class="arithmatex">\(p(O^\text{(p)}) | p\)</span>: Đây là khả năng đoạn âm thanh <span class="arithmatex">\(O(p)\)</span> được tạo ra bởi đúng âm vị <span class="arithmatex">\(p\)</span>. Chúng cho biết âm thanh thực tế khớp với âm vị mà chúng ta mong đợi nghe thấy đến mức nào.</p>
</li>
<li>
<p>Mẫu số <span class="arithmatex">\(\max_{q \in \mathbf{Q}} p(O^\text{(p)}) | q\)</span>: Đây là khả năng đoạn âm thanh <span class="arithmatex">\(O(p)\)</span> được tạo ra bởi âm vị khớp tốt nhất trong tất cả các âm vị <span class="arithmatex">\(q\)</span>. Cho biết âm thanh thực tế giống với âm vị nào nhất trong tất cả các âm vị, bất kể đúng hay sai.</p>
</li>
</ul>
</div>
<p>Nếu tỷ lệ <span class="arithmatex">\(\frac{p(O^\text{(p)}) | p}{\max_{q \in \mathbf{Q}} p(O^\text{(p)}) | q}\)</span> tiến đến gần 1, có nghĩa là âm vị đích khớp rất tốt, và không có âm vị nào khác khớp tốt hơn. Điều này chứng tỏ người đọc đã phát âm rất tốt. Ngược lại, có nghĩa là có một hoặc nhiều âm vị khác khớp với đoạn âm thanh đó hơn so với âm vị đích, đồng nghĩa với người dùng phát âm chưa chuẩn. </p>
<p><strong>Hệ thống Pronunciation Scoring:</strong> </p>
<p>Sơ đồ khối của cơ chế chấm điểm dựa trên phương pháp GOP được thể hiện như trong hình. Cụ thể sẽ trải qua 4 giai đoạn:</p>
<figure>
<p><img alt="" src="../images/gop_system_baseline.png" /></p>
<figcaption>
<p>Hình 1.1: Biểu đồ minh họa các thành phần chính trong hệ thống chấm điểm dựa trên phương pháp GOP truyền thống. </p>
</figcaption>
</figure>
<ul>
<li>
<p>Front-end Feature Extraction: Đây là giai đoạn đầu tiên, dữ liệu âm thanh đầu vào được xử lý để trích xuất các đặc trưng quan trọng của giọng nói thường là MFCC (Mel-frequency Cepstral Coefficients). Đây là cách biểu điễn âm thanh dưới dạng số.</p>
</li>
<li>
<p>Two Recognition Pass: Tiếp theo các transcipts và đặc trưng âm thanh tương ứng sẽ trải qua hai lượt nhận dạng:</p>
<ul>
<li>Forced Alignment Pass: Sử dụng bản ghi đã biết để ép các đặc trưng MFCC khớp với chuỗi phone đúng (đây chính là việc tính toán tử số của công thức GOP). Ví dụ hệ thống nhận đầu vào tín hiệu âm thanh của người đọc là <strong>cat</strong>, hệ thống sẽ sử dụng một từ điển phát âm (pronunciation dictionary), từ điển này chứa cách phát âm chuẩn theo IPA của mỗi từ trong ngôn ngữ. Từ <strong>cat</strong> sẽ được ánh xạ thành chuỗi âm vị chuẩn là <strong>/k/ /ae/ /t/</strong>. Sau đó quá trình ép khung diễn ra, giai đoạn này sẽ xác định thời điểm bắt đầu và kết thúc của từng âm vị trong lời nói của người học và đồng thời gán cho mỗi đoạn âm thanh một âm vị <span class="arithmatex">\(p\)</span> đúng theo bản ghi chuẩn. Đầu ra của giai đoạn này sẽ có dạng:</li>
</ul>
<div class="language-yaml highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">example.json</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1">1</a></span>
<span class="normal"><a href="#__codelineno-0-2">2</a></span>
<span class="normal"><a href="#__codelineno-0-3">3</a></span>
<span class="normal"><a href="#__codelineno-0-4">4</a></span>
<span class="normal"><a href="#__codelineno-0-5">5</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="p p-Indicator">[</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="w">    </span><span class="p p-Indicator">{</span><span class="w"> </span><span class="s">&quot;phone&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="s">&quot;/k/&quot;</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="s">&quot;start_time&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="nv">0.05</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="s">&quot;end_time&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="nv">0.18</span><span class="w"> </span><span class="p p-Indicator">},</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="w">    </span><span class="p p-Indicator">{</span><span class="w"> </span><span class="s">&quot;phone&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="s">&quot;/æ/&quot;</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="s">&quot;start_time&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="nv">0.18</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="s">&quot;end_time&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="nv">0.35</span><span class="w"> </span><span class="p p-Indicator">},</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="w">    </span><span class="p p-Indicator">{</span><span class="w"> </span><span class="s">&quot;phone&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="s">&quot;/t/&quot;</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="s">&quot;start_time&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="nv">0.35</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="s">&quot;end_time&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="nv">0.48</span><span class="w"> </span><span class="p p-Indicator">}</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="p p-Indicator">]</span>
</span></code></pre></div></td></tr></table></div>
<ul>
<li>Phone Recognition Pass: Sử dụng một "phoneme loop" để nhận dạng đoạn âm thanh <span class="arithmatex">\(O^{\text{(p)}}\)</span> mà không có ràng buộc về từ vựng. Chúng tìm ra âm vị nào (trong tất cả các âm vị có thể có trong ngôn ngữ) khớp tốt nhất với đoạn âm thanh đó (tính toán mẫu số của GOP).</li>
</ul>
</li>
<li>
<p>GOP scores: Tính toán các điểm GOP riêng lẻ cho từng phone dựa trên các kết quả thu được từ hai lượt nhận dạng.</p>
</li>
<li>
<p>Threshold: Sau khi có được điểm GOP cho mỗi phone, lựa chọn một ngưỡng tùy chỉnh nhằm phân loại, nếu điểm GOP của một phone thấp hơn ngưỡng thì âm đó được coi là phát âm kém và ngược lại.</p>
</li>
</ul>
<p><strong>Hạn chế của phương pháp GOP:</strong></p>
<ul>
<li>
<p>Phụ thuộc quá nhiều vào Forced Alignment và HMM (Hidden Markov Model) truyền thống. GOP phụ thuộc hoàn toàn vào độ chính xác của quá trình ép khung để xác định ranh giới của từng âm vị và tính toán likelihood. Nếu quá trình căn chỉnh này không chính xác sẽ dẫn đến điểm GOP không đáng tin cậy.</p>
</li>
<li>
<p>Không có mô hình riêng biệt cho lỗi phát âm: GOP truyền thống so sánh âm thanh đầu vào với mô hình của âm vị đúng và tất cả các âm vị khác trong ngôn ngữ đích. Tuy nhiên chúng bỏ qua và không quan tâm đến các loại lỗi phát âm cụ thể thường gặp.</p>
</li>
<li>
<p>Không xem xét ngữ cảnh: GOP thường đánh giá từng âm vị một cách tương đối độc lập. Chúng ít khi xét đến ngữ cảnh âm vị xung quanh hoặc ngữ cảnh từ/câu, điều này cũng ảnh hưởng đến cách phát âm và nhận thức về lỗi của con người.</p>
</li>
</ul>
<h3 id="22-deep-neural-networks-based-gop"><strong>2.2 Deep Neural Networks based GOP</strong></h3>
<p>Các hệ thống chấm điểm phát âm thường được huấn luyện chỉ với dữ liệu giọng nói của người bản xứ. Trong khi đó, giọng nói của người học ngôn ngữ (phi bản xứ) lại có nhiều khác biệt, đặc biệt là khi họ phát âm sai. Nhiều nghiên cứu chỉ ra rằng việc huấn luyện hệ thống trực tiếp bằng dữ liệu giọng nói của người học phi bản xứ giúp cho hệ thống tốt hơn. Tuy nhiên việc thu thập dữ liệu và gán nhãn chi tiết dữ liệu giọng nói phi bản xứ là một thách thức lớn gây tốn kém và mất thời gian. Phương pháp này được tiếp cận dựa trên transfer learning <a href="https://arxiv.org/pdf/2111.00976"><strong>DNN-based GOP</strong></a> để giải quyết những thách thức này, cụ thể: </p>
<ul>
<li>Tận dụng mô hình đã được huấn luyện cho nhiệm vụ nhận dạng giọng nói trên một lượng lớn dữ liệu người bản xứ.</li>
<li>Tinh chỉnh mô hình đã được huấn luyện trước với lượng nhỏ dữ liệu phi bản xứ có nhãn.</li>
</ul>
<p><strong>Mở rộng công thức tính GOP với DNN:</strong></p>
<p>So với phương pháp tính toán GOP truyền thống như được trình bày ở <a href="#1-goodness-of-pronunciation"><strong>(1)</strong></a>, trong đó GOP được tính dựa trên các mô hình âm học GMM (Gausian Mixture Models). Trong những năm gần đây, một loạt các nghiên cứu đã chỉ ra những cải thiện đáng kể khi sử dụng các mô hình âm học dựa trên DNN (Deep Neural Networks). DNN có khả năng học và mô hình hóa các đặc trưng âm thanh phức tạp tốt hơn nhiều so với GMM.</p>
<p>Khi sử dụng các mô hình âm học dựa trên DNN, điểm GOP của một âm vị đích <span class="arithmatex">\(p\)</span> bắt đầu từ khung thời gian <span class="arithmatex">\(\text{T}\)</span> và có độ dài <span class="arithmatex">\(\text{D}\)</span> được tính như sau:</p>
<div class="arithmatex">\[
\textbf{GOP}_{p} = -\frac{1}{D} \sum^{\text{T+D-1}}_\text{t=T} \log P_{t}(p|O)
\]</div>
<p>Trong đó:</p>
<ul>
<li><span class="arithmatex">\(\text{D}\)</span> là độ dài của âm vị, tính bằng số lượng khung thời gian <span class="arithmatex">\(p\)</span></li>
<li><span class="arithmatex">\(\text{T}\)</span> là khung thời gian bắt đầu của âm vị <span class="arithmatex">\(p\)</span></li>
<li><span class="arithmatex">\(O\)</span> là toàn bộ chuỗi đặc trưng, được trính xuất từ dạng sóng âm sang các đặc trưng để có thể tính toán, đại diện cho tất cả các dữ liệu âm thanh mà mô hình có thể sử dụng</li>
<li><span class="arithmatex">\(\sum^{\text{T+D-1}}_\text{t=T}\)</span> tổng các giá trị cho tất cả các khung thời gian t nằm trong khoảng từ khung bắt đầu <span class="arithmatex">\(\text{T}\)</span> đến khung kết thúc <span class="arithmatex">\(\text{T + D - 1}\)</span> của âm vị <span class="arithmatex">\(p\)</span>.</li>
<li><span class="arithmatex">\(\log P_{t}(p|O)\)</span> là xác xuất hâu nghiệm của âm vị <span class="arithmatex">\(p\)</span> tại khung thời gian <span class="arithmatex">\(t\)</span>, với điều kiện là toàn bộ chuỗi đặc trưng âm học <span class="arithmatex">\(O\)</span> đã được quan sát</li>
</ul>
<p>Sự khác biệt lớn giữa việc tính toán giữa GOP truyền thống và GOP dựa trên DNN là việc chuyển từ likelihood sang posterior. Cụ thể:</p>
<ul>
<li>
<p>Đối với GOP truyền thống: Đoạn âm thanh <span class="arithmatex">\(O^{(p)}\)</span> của âm vị <span class="arithmatex">\(p\)</span> được đưa vào mô hình sinh (generative model) của âm vị <span class="arithmatex">\(p\)</span>. Mô hình này sẽ tính toán khả năng chúng sinh ra <span class="arithmatex">\(O^{(p)}\)</span>.</p>
</li>
<li>
<p>Đối với GOP dựa trên DNN: Thay vì tính toán tỉ lệ giữa các likelihood, mô hình DNN trực tiếp đưa ra xác suất hậu nghiệm <span class="arithmatex">\(P_t(p|O)\)</span> cho âm vị <span class="arithmatex">\(p\)</span> tại mỗi khung thời gian <span class="arithmatex">\(t\)</span>. </p>
</li>
</ul>
<p><strong>Cấu trúc mô hình đề xuất:</strong></p>
<p>Nhìn chung phương pháp này cũng tương tự như GOP basline truyền thống, cả hai đều tuân thủ theo nhiều quy trình riêng lẻ, từ việc xử lý dữ liệu âm thanh cho đến đưa ra điểm số phát âm cho từng âm vị.</p>
<p><img alt="" src="../images/gop_dnn_system.png" /></p>
<ul>
<li>
<p>Giai đoạn tiền xử lý và căn chỉnh ép buộc (Forced Aligner): Đầu vào là một tín hiệu âm thanh (waveform) mà người học phát ra và bản ghi (transcipt) tương ứng. Sau đó vẫn sử dụng bộ căn chỉnh ép buộc để xác định tính chính xác thời điểm bắt đầu và kết thúc của từng âm vị trong lời nói của người học.</p>
</li>
<li>
<p>Giai đoạn tạo điểm cấp khung (Frame-level score Generation): Sau khi có các đoạn âm thanh được căn chỉnh cho từng âm vị, các đặc trưng âm học đã được trích xuất cho từng khung nhỏ của toàn bộ tín hiệu âm thanh được đưa vào một mô hình DNN, mô hình này sẽ đưa ra điểm số cho mỗi âm vị có thể có trong ngôn ngữ tại khung đó.</p>
</li>
<li>
<p>Lựa chọn điểm cấp khung (Frame-level score selection): </p>
<ul>
<li>
<p>Như đã được đề cập, mô hình DNN trong các hệ thống cơ sở đuọc huấn luyện để đưa ra xác suất hậu nghiệm cho từng senone tại mỗi khung thời gian (nhánh phía trên của khối màu xám). Để có được điểm số cho mỗi âm vị tại mỗi khung, các xác suất hậu nghiệm của tất cả các senone thuộc về cùng một âm vị đó sẽ được tổng hợp lại. Mục đích là chuyển đổi đầu ra chi tiết của DNN (cấp senone) về cấp độ âm vị (phone) để tính toán GOP.</p>
</li>
<li>
<p>Mô hình đề xuất (nhánh phía dưới khối màu xám), thay vì phải đi qua các senone trung gian rồi tổng hợp, mô hình DNN được thiết kế và huấn luyện trực tiếp để đưa ra xác suất hậu nghiệm cho từng âm vị tại mỗi khung thời gian. </p>
</li>
<li>
<p>Sau khi DNN đã tạo ra điểm số cho tất cả các âm vị tại mỗi khung, bước này sẽ chọn ra điểm số của âm vị đúng <span class="arithmatex">\(p\)</span> tại từng khung. Ví dụ nếu Forced Aligner cho rằng khung <span class="arithmatex">\(t\)</span> thuộc về âm vị <strong>/k/</strong> thì ta sẽ lấy giá trị P_t(<strong>/k/</strong>|O) từ đầu ra của DNN tại khung đó.</p>
</li>
</ul>
</li>
<li>
<p>Giai đoạn tính toán điẻm phát âm: Đối với mỗi âm vị <span class="arithmatex">\(p\)</span> đã được xác định bởi Forced Aligner, lấy tất cả các điểm số cấp khung đã được lựa chọn ở bước trước. Các điểm số này sau đó được trung bình hóa trên toàn bộ các khung mà âm vị đó chiếm giữ. Giả sử âm vị <strong>/k/</strong> kéo dài 10 khung từ (<span class="arithmatex">\(f_1\)</span> đến <span class="arithmatex">\(f_{10})\)</span>, điểm GOP của <strong>/k/</strong> sẽ được tính bằng cách lấy trung bình của <span class="arithmatex">\([P_{f1}(/k/|O),...,P_{f10}(/k/|O)]\)</span>. </p>
</li>
</ul>
<h3 id="23-wav2vec"><strong>2.3 wav2vec</strong></h3>
<p>Mô hình này là một phương pháp hiệu quả và hiện đại nhằm mục đích xây dựng hệ thống nhận dạng tiếng nói thông qua học tự giám sát, giúp giải quyết vấn đề thiếu dữ liệu có nhãn. Chúng học cách mã hóa âm thanh thành các biểu diễn tiềm ẩn, sau đó che đi một phần và sử dụng kiến trúc Transformer tạo ra các biểu diễn ngữ cảnh hóa và phân biệt chúng với các yếu tố gây nhiễu, đồng thời học được các đơn vị tiếng nói rời rạc. Phương pháp này đạt được hiệu suất rất tốt, đặc biệt ấn tượng ở các trường hợp có rất ít dữ liệu có nhãn.</p>
<p>Kiến trúc của mô hình <strong><a href="https://arxiv.org/pdf/2006.11477">wav2vec 2.0</a></strong> (<strong>Hình 2.1</strong>) tập trung vào ba thành phần chính: Bộ mã hóa đặc trưng (feature encoder), mạng Transformer để tạo biểu diễn ngữ cảnh (contextualized representations with transformers), và lượng tử hóa (quantization module).</p>
<figure>
<p><img alt="" src="../images/framework_wav2vec.png" /></p>
<figcaption>
<p><strong>Hình 2.1: Kiến trúc thành phần cơ bản của mô hình wav2vec</strong></p>
</figcaption>
</figure>
<p><strong>a. Bộ mã hóa đặc trưng (feature encoder)</strong></p>
<p>Mục đích của quá trình này là chuyển đổi toàn bộ sóng âm thanh thô thành các biểu diễn tiềm ẩn có ỹ nghĩa. Bộ mã hóa này được cấu tạo bởi nhiều khối, mỗi khối chứa các thành phần như:</p>
<ul>
<li>
<p>Tích chập thời gian (temporal convolution): Đây là một loại mạng tích chập chuyên dùng cho dữ liệu chuỗi (như âm thanh). Chúng lần lượt quét qua dữ liệu theo thời gian đề trích xuất các đặc trưng cục bộ.</p>
</li>
<li>
<p>Chuẩn hóa lớp (layer normalization): Kỹ thuật này giúp ổn định quá trình huấn luyện của mạng nơ-ron bằng cách chuẩn hóa đầu ra của mỗi lớp.</p>
</li>
<li>
<p>Hàm kích hoạt GELU: Hàm này giúp mạng học được các mối quan hệ phức tạp trong dữ liệu.</p>
</li>
</ul>
<p><strong>b. Biểu diễn được ngữ cảnh hóa với Transformer (contextualized representations with transformers)</strong></p>
<p>Giả sử các âm thanh thô sau khi đi qua feature encoder là các biểu diễn tiềm ẩn <span class="arithmatex">\(Z\)</span>, chúng sẽ được đưa vào các kiến trúc Transformers để tạo ra các biểu diễn <span class="arithmatex">\(C\)</span> nắm bắt được ngữ cảnh của toàn bộ chuỗi. Có một sự khác biệt nhỏ trong việc nhúng vị trí (positional embeddings), thay vì dùng nhúng vị trí cố định như phương pháp truyền thống, ở giai đoạn này một lớp tích chập được cài đặt để tạo ra nhúng vị trí tương đối. Hiểu một cách nôm na, thay vì nói "phần tử này ở vị trí thứ 10", thì chúng sẽ tập trung vào "phần tử này cách phần từ kia với khoảng cách là bao xa".</p>
<p><strong>c. Module lượng tử hóa (quantization module)</strong></p>
<p>Chuyển đổi các biểu diễn tiếng nói tiềm ẩn liên tục <span class="arithmatex">\(Z\)</span> thành một tập hợp rời rạc (discrete) các biểu diễn. Các biểu diễn rời rạc này được sử dụng làm mục tiêu trong tác vụ học tự giám sát. Trong mô hình này lượng tử hóa tích (product quantization - PQ) được sử dụng. Đây là một kỹ thuật để lượng tử hóa các vector nhiều chiều thành nhiều phần nhỏ (các nhóm hoặc codebook). Giả sử ta có một vector đặc trưng <span class="arithmatex">\(d\)</span> chiều. PQ sẽ chia <span class="arithmatex">\(d\)</span> chiều này thành <span class="arithmatex">\(G\)</span> nhóm, mỗi nhóm có <span class="arithmatex">\(\frac{d}{G}\)</span> chiều. Với mỗi nhóm, sẽ chứa một codebook riêng và mỗi codebook sẽ chứa nhiều vector con.</p>
<p>Để dễ hình dung hơn, nếu ta có một bức ảnh kỹ thuật số, màu sắc trong bức ảnh được biểu diễn bằng nhiều giá trị số liên tục. Nếu muốn giảm đi dung lượng file hoặc muốn lưu trữ chúng trên một thiết bị có bộ nhớ hạn chế, thì lượng tử hóa màu sắc sẽ được sử dụng. Thay vì có hàng triệu sắc thái màu liên tục, ta chỉ cho phép ảnh sử dụng một tập hợp rời rạc có thể là 100 màu chuẩn hoặc ít hơn. Mỗi điểm ảnh sẽ được làm tròn hoặc quy về một màu gần nhất trong tập hợp màu giới hạn đó.</p>
<p>Biểu diễn tiếng nói tiềm ẩn <span class="arithmatex">\(Z\)</span> mà bộ mã hóa tạo ra là các giá trị liên tục, vì vậy mục tiêu chính của lượng tử hóa là cố gắng chuyển đổi chúng về một tập hợp hữu hạn rời rạc các mã hoặc đơn vị. Nếu từ một đoạn âm thanh đầu vào, ta mong muốn phân loại từ một chuỗi các âm thanh liên tục đó thành các âm (như a, b, c) rõ ràng, thay vì là một dải âm liên tục không định hình. Việc này giúp mô hình dễ dàng học được các đơn vị cơ bản của tiếng nói.</p>
<p>Lượng tử hóa giúp cho việc xử lý dữ liệu và lưu trũ dễ dàng hơn và các biểu diễn đã được lượng tử hóa <span class="arithmatex">\(Q\)</span> được dùng làm mục tiêu (targets) cho tác vụ học tự giám sát. Mô hình phải cố gắng dự đoán hoặc tái tạo lại các đơn vị rời rạc này.</p>
<p>Codebook có thể coi là một tử điển hoặc một bộ sưu tập các mã hoặc mẫu đã được định nghĩa trước. Chúng được xây dựng một cách tự động thông qua quá trình huấn luyện tự giám sát của mô hình. Trong quá trình huấn luyện, codebook được hình thành nhờ sự hỗ trợ bởi các hàm mất mát (contrastive loss, diversity loss) và các kỹ thuật như gumble softmax để trở thành một tập hợp các đơn vị tối ưu, có khả năng biểu diễn hiệu quả các đặc trưng cơ bản của dữ liệu âm thanh không có nhãn.</p>
<ul>
<li>
<p>Ban đầu khi mô hình chưa được huấn luyện, các vector trong codebook được khởi tạo ngẫu nhiên. Chúng có thể là những tập hợp số vô nghĩa.</p>
</li>
<li>
<p>Codebook được học và cập nhật cùng với phần còn lại của mô hình (bộ mã hóa đặc trưng và transformer) thông qua tác vụ tự giám sát. Để có được nhãn cho việc dự đoán mà không cần con người, các biểu diễn tiềm ẩn <span class="arithmatex">\(Z\)</span> (thường là các phần không bị che từ các khoảng thời gian khác) được đưa ra PQ để tạo ra các đơn vị rời rạc. Chính các đơn vị này đóng vai trò là nhãn tự tạo cho mô hình.</p>
</li>
<li>
<p>Khi mô hình dự đoán một biểu diễn ngữ cảnh cho một đoạn âm thanh bị che, chúng sẽ so sánh dự đoán đó với một trong các đơn vị rời rạc từ codebook (đây là mục tiêu/nhãn đúng cho đoạn bị che đó). Nếu dự đoán của mô hình chưa tốt, hàm mất mát (constractive loss) sẽ đưa ra mức độ sai lệch. </p>
</li>
</ul>
<p><strong>d. Gumble Softmax</strong></p>
<p>Việc chọn lực một vector rời rạc từ một codebook thường không thể khả vi, tức là sẽ không thể tính toán gradient cho quá trình cập nhật trọng số mạng. Gumbel softmax là một kỹ thuật nhằm giải quyết vấn đề này, chúng cho phép chọn các vector rời rạc một cách khả vi hoàn toàn, điều này có nghĩa là ta có thể thực hiện lan truyền ngược qua quá trình lựa chọn rời rạc đề huấn luyện toàn bộ mô hình. Công thức của Gumbel softmax được thiết kế như sau:</p>
<div class="arithmatex">\[
P_{g,v} = \frac{exp(l_{g,v} + n_{v}) / \tau}{\sum^{V}_{k=1} exp(l_{g,k} + n_{k}) / \tau}
\]</div>
<p>Công thức này tính toán xác suất để chọn mục nhập thứ <span class="arithmatex">\(v\)</span> từ sổ mã của nhóm <span class="arithmatex">\(g\)</span>, <span class="arithmatex">\(l_{g,v}\)</span> là các đầu ra chưa chuẩn hóa của một lớp tuyến tính. Gumbel softmax có sử dụng một tham số nhiệt độ <span class="arithmatex">\(\tau\)</span> giúp cho quá trình lựa chọn trở nên mềm mại hơn trong quá trình truyền tiến, và sử dụng một bộ ước tính có tên là straight-through để đảm báo gradient truyền ngược chính xác trong quá trình truyền ngược.</p>
<p><strong>e. Contrastive Loss</strong></p>
<p>Đây là hàm mất mát tương phản giúp mô hình có thể phân biệt được giữa biểu diễn tiếng nói tiềm ẩn được lượng tử hóa đúng (positive sample) và các biểu diễn sai (negative sample) cho một vị trí bị che. Hàm này được định nghĩa bằng công thức sau:</p>
<div class="arithmatex">\[
\mathcal{L}_{m} = -\text{log} \frac{exp(sim(c_{t}, q_{t})/k)}{\sum_{\tilde{q} \sim Q_{t}} exp(sim(c_{t}, \tilde{q}) / k)}
\]</div>
<p>Mô hình sẽ nhận đầu ra từ mạng transformer là <span class="arithmatex">\(c_{t}\)</span>, tập trung vào một bước thời gian <span class="arithmatex">\(t\)</span> đã bị che, <span class="arithmatex">\(c_t\)</span> là biểu diễn ngữ cảnh mà transformer đã tạo ra, cố gắng nắm bắt thông tin từ toàn bộ chuỗi. Sau đó mô hình cần xác định đâu là biểu diễn tiếng nói tiềm ẩm được lượng tử hóa đúng <span class="arithmatex">\(q_{t}\)</span> cho bước thời gian <span class="arithmatex">\(t\)</span>, <span class="arithmatex">\(q_{t}\)</span> được tạo ra từ biểu diễn tiềm ẩn gốc (không bị che) tại vị trí <span class="arithmatex">\(t\)</span>, sau khi đi qua module lượng tử hóa. Để làm được điều này, mô hình được đưa ra một tập hợp <span class="arithmatex">\(K+1\)</span> ứng cử viên cho <span class="arithmatex">\(\tilde{q}\)</span>. Tập hợp này bao gồm:</p>
<ul>
<li><span class="arithmatex">\(q_{t}\)</span> biểu diễn đúng</li>
<li><span class="arithmatex">\(K\)</span> là phần tử gây nhiễu, các biểu diễn này được lấy mẫu ngẫu nhiên từ các bước thời gian bị che khác trong cùng một file âm thanh. </li>
</ul>
<p><strong>f. Diversity Loss</strong></p>
<p>Công thức của Diversity Loss (hàm mất mát đa dạng) được biểu diễn như sau:</p>
<div class="arithmatex">\[
\mathcal{L}_{d} = \frac{1}{GV} \sum^{G}_{g=1} - H(\overline{p}_{g}) == \frac{1}{GV} \sum^{G}_{g=1} \sum^V_{v=1} \overline{p}_{g,v} \log \overline{p}_{g,v}
\]</div>
<p>Trong đó:</p>
<ul>
<li><span class="arithmatex">\(H(\overline{p}_{g})\)</span> là ký hiệu cho entropy phân phối của <span class="arithmatex">\(\overline{p}_{g}\)</span>.</li>
<li><span class="arithmatex">\(\sum^V_{v=1} \overline{p}_{g,v} \log \overline{p}_{g,v}\)</span> là công thức tính toán entropy.</li>
<li><span class="arithmatex">\(\frac{1}{GV}\)</span> là hệ số chuẩn hóa, trung bình hóa hàm mất mát trên tất cả <span class="arithmatex">\(G\)</span> codebook và <span class="arithmatex">\(V\)</span> vector trong mỗi codebook.</li>
</ul>
<p>Hàm mất mát đa dạng này được áp dụng khuyến khích mô hình sử dụng tất cả hoặc phần lớn các vector trong các codebook một cách đồng đều, thay vì chỉ tập trung vào một vài vector đặc trưng phổ biến. Nếu không có hàm mất mát này, có thể một số vector trong codebook không bao giờ được sử dụng. Điều này sẽ vô tình làm lãng phí khả năng biểu diễn của codebook và hạn chết tính đa dạng của các đơn vị mà mô hình học được.</p>
<h3 id="24-mot-so-phuong-phap-khac"><strong>2.4 Một số phương pháp khác</strong></h3>
<table>
<thead>
<tr>
<th style="text-align: center;">No.</th>
<th style="text-align: center;">Methods</th>
<th style="text-align: left;">Desciption</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">#1</td>
<td style="text-align: center;">3MH <br> [<a href="https://arxiv.org/pdf/2305.18146v4">paper</a>]</td>
<td style="text-align: left;">Mô hình đa tầng (multi-head) học đồng thời nhiều khía cạnh như accuracy, stress, fluency ở mức từ - tăng khả năng đánh giá từ toàn diện hơn</td>
</tr>
<tr>
<td style="text-align: center;">#2</td>
<td style="text-align: center;">GOPT-PAII <br> [<a href="https://arxiv.org/pdf/2205.03432v1">paper</a>]</td>
<td style="text-align: left;">Mô hình Transformer đánh giá phát âm theo nhiều khía cạnh đồng thời (accuracy, fluency, completeness, prosody…) và nhiều mức (phoneme, word, utterance)</td>
</tr>
<tr>
<td style="text-align: center;">#3</td>
<td style="text-align: center;">HierCB + ConPCO <br> [<a href="">paper</a>]</td>
<td style="text-align: left;">Áp dụng contrastive learning kết hợp ordinal regression để tạo embedding âm vị phân biệt và duy trì thứ tự đánh giá, giúp chấm điểm phát âm chính xác hơn</td>
</tr>
<tr>
<td style="text-align: center;">#4</td>
<td style="text-align: center;">SpeechBlender + LSTM <br> [<a href="https://arxiv.org/pdf/2211.00923v3">paper</a>]</td>
<td style="text-align: left;">Dùng kỹ thuật data augmentation đặc biệt (SpeechBlender) để mô phỏng lỗi phát âm, huấn luyện LSTM nhận biết phát âm sai hiệu quả ngay cả khi thiếu dữ liệu thực</td>
</tr>
<tr>
<td style="text-align: center;">#5</td>
<td style="text-align: center;">HiPAMA–LibriSpeech [<a href="https://arxiv.org/pdf/2211.08102v2">paper</a>]</td>
<td style="text-align: left;">Mô hình phân cấp (phoneme → word → utterance) sử dụng multi-aspect attention, kết hợp nhiều khía cạnh (accuracy, fluency, completeness…) theo từng cấp độ ngôn ngữ</td>
</tr>
</tbody>
</table>
<hr />







  
  






                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      ©️ 2025 by Thai Hoc Nguyen
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
    <a href="https://ictu.edu.vn" target="_blank" rel="noopener" title="Thai Nguyen University of Information and Technology Communication" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 3 1 9l11 6 9-4.91V17h2V9M5 13.18v4L12 21l7-3.82v-4L12 17z"/></svg>
    </a>
  
    
    
    
    
    <a href="https://iast.ictu.edu.vn" target="_blank" rel="noopener" title="Institute of Applied Science Technology" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 15h-2v2h2m0-6h-2v2h2m2 6h-8v-2h2v-2h-2v-2h2v-2h-2V9h8M10 7H8V5h2m0 6H8V9h2m0 6H8v-2h2m0 6H8v-2h2M6 7H4V5h2m0 6H4V9h2m0 6H4v-2h2m0 6H4v-2h2m6-10V3H2v18h20V7z"/></svg>
    </a>
  
    
    
    
    
    <a href="https://nthaihoc.github.io/about-me" target="_blank" rel="noopener" title="Profile" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M16.36 14c.08-.66.14-1.32.14-2s-.06-1.34-.14-2h3.38c.16.64.26 1.31.26 2s-.1 1.36-.26 2m-5.15 5.56c.6-1.11 1.06-2.31 1.38-3.56h2.95a8.03 8.03 0 0 1-4.33 3.56M14.34 14H9.66c-.1-.66-.16-1.32-.16-2s.06-1.35.16-2h4.68c.09.65.16 1.32.16 2s-.07 1.34-.16 2M12 19.96c-.83-1.2-1.5-2.53-1.91-3.96h3.82c-.41 1.43-1.08 2.76-1.91 3.96M8 8H5.08A7.92 7.92 0 0 1 9.4 4.44C8.8 5.55 8.35 6.75 8 8m-2.92 8H8c.35 1.25.8 2.45 1.4 3.56A8 8 0 0 1 5.08 16m-.82-2C4.1 13.36 4 12.69 4 12s.1-1.36.26-2h3.38c-.08.66-.14 1.32-.14 2s.06 1.34.14 2M12 4.03c.83 1.2 1.5 2.54 1.91 3.97h-3.82c.41-1.43 1.08-2.77 1.91-3.97M18.92 8h-2.95a15.7 15.7 0 0 0-1.38-3.56c1.84.63 3.37 1.9 4.33 3.56M12 2C6.47 2 2 6.5 2 12a10 10 0 0 0 10 10 10 10 0 0 0 10-10A10 10 0 0 0 12 2"/></svg>
    </a>
  
    
    
    
    
    <a href="mailto:thaihoc.ictu@gmail.com" target="_blank" rel="noopener" title="Email" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M2 6v14h18v2H2c-1.105 0-2-.89-2-2V6zm22-2c0-1.1-.9-2-2-2H6c-1.1 0-2 .9-2 2v12c0 1.1.9 2 2 2h16c1.1 0 2-.9 2-2zm-2 0-8 5-8-5zm0 12H6V6l8 5 8-5z"/></svg>
    </a>
  
    
    
    
    
    <a href="https://github.com/nthaihoc?tab=repositories" target="_blank" rel="noopener" title="Github" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 2A10 10 0 0 0 2 12c0 4.42 2.87 8.17 6.84 9.5.5.08.66-.23.66-.5v-1.69c-2.77.6-3.36-1.34-3.36-1.34-.46-1.16-1.11-1.47-1.11-1.47-.91-.62.07-.6.07-.6 1 .07 1.53 1.03 1.53 1.03.87 1.52 2.34 1.07 2.91.83.09-.65.35-1.09.63-1.34-2.22-.25-4.55-1.11-4.55-4.92 0-1.11.38-2 1.03-2.71-.1-.25-.45-1.29.1-2.64 0 0 .84-.27 2.75 1.02.79-.22 1.65-.33 2.5-.33s1.71.11 2.5.33c1.91-1.29 2.75-1.02 2.75-1.02.55 1.35.2 2.39.1 2.64.65.71 1.03 1.6 1.03 2.71 0 3.82-2.34 4.66-4.57 4.91.36.31.69.92.69 1.85V21c0 .27.16.59.67.5C19.14 20.16 22 16.42 22 12A10 10 0 0 0 12 2"/></svg>
    </a>
  
    
    
    
    
    <a href="https://www.facebook.com/nthaihoc.02" target="_blank" rel="noopener" title="Facebook" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 2.04c-5.5 0-10 4.49-10 10.02 0 5 3.66 9.15 8.44 9.9v-7H7.9v-2.9h2.54V9.85c0-2.51 1.49-3.89 3.78-3.89 1.09 0 2.23.19 2.23.19v2.47h-1.26c-1.24 0-1.63.77-1.63 1.56v1.88h2.78l-.45 2.9h-2.33v7a10 10 0 0 0 8.44-9.9c0-5.53-4.5-10.02-10-10.02"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../../../..", "features": ["content.code.annotate", "content.footnote.tooltips", "navigation.tabs", "navigation.instant", "navigation.indexes", "navigation.path", "toc.follow", "search.suggest", "navigation.top", "navigation.footer", "navigation.instant.preview", "navigation.tracking"], "search": "../../../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
        <script src="../../../../javascripts/mathjax.js"></script>
      
        <script src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>